<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2020)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2020.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Tue, 16 Jun 2020 01:23:55 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Week 1 &amp; 2: Coding Officially Begins!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_1804_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;h3 id="hey-sid-did-the-coding-period-officially-begin"&gt;&lt;em&gt;Hey Sid, did the coding period officially begin?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;The community bonding period ended by the end of last month and the coding period officially began, I started to work on basic structure of the package and setting up the (not so user-friendly, PS: from astronomer’s perspective) interface for the image reduction methods.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="hey-what-did-you-build-in-these-two-weeks"&gt;&lt;em&gt;Hey, what did you build in these two weeks?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;I have set up the basic methods required for processing of astronomical images, let me explain it to you one by one:&lt;/p&gt;

&lt;p&gt;The first method implemented was &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_bias&lt;/code&gt;, this de-biases the image with the help of a bias frame, it has a mutating version as well which de-biases the image in place.&lt;/p&gt;

&lt;p&gt;Next comes &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_overscan&lt;/code&gt;, every CCD plate has some region which is unexposed to light and this is called overscan region. For pre-processing average of this region has to be obtained (there are models as well, that can fit into this region PS: model part has to be implemented later) and then subtracted from the whole image. It also has a mutating variant clubbed together.&lt;/p&gt;

&lt;p&gt;Next in line was &lt;code class="language-plaintext highlighter-rouge"&gt;flat_correct&lt;/code&gt;, this method removes the effect of variations in pixel to pixel sensitivity of detectors and by distortions in the optical path. The interesting point I learned while implementing this is fused broadcasting, believe me Julia keeps on blowing my mind with its speed and succinct syntaxes.&lt;/p&gt;

&lt;p&gt;Next, I implemented some basic functionalities for modifying the image sizes i.e. &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt;. They are not much different but they are different, let me explain! Trimming is instructing the computer to remove some parts from the image, whereas cropping is instructing the computer to keep a certain part in the image (Yes, that’s the difference!). Sound’s pretty similar, right? The implementations were not that similar, &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt; was a bit tricky as compared to &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; (check out the source code to find the difference). These functions are inherently non-mutating type, but I have also implemented a version of &lt;code class="language-plaintext highlighter-rouge"&gt;crop&lt;/code&gt; as &lt;code class="language-plaintext highlighter-rouge"&gt;cropview&lt;/code&gt;, this returns the &lt;code class="language-plaintext highlighter-rouge"&gt;view&lt;/code&gt; of the passed array. Mutating the &lt;code class="language-plaintext highlighter-rouge"&gt;view&lt;/code&gt; will mutate the initial frame passed, an analogous version for &lt;code class="language-plaintext highlighter-rouge"&gt;trim&lt;/code&gt; here is &lt;code class="language-plaintext highlighter-rouge"&gt;trimview&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next in line was the function &lt;code class="language-plaintext highlighter-rouge"&gt;combine&lt;/code&gt;, it basically takes a variable number of frames, stacks them together, and then finally combines them using medians (users can also have their custom combining functions).&lt;/p&gt;

&lt;p&gt;Okay, this one is last, &lt;code class="language-plaintext highlighter-rouge"&gt;subtract_dark&lt;/code&gt;, a way to reduce image noise in photographs shot with long exposure times, at high ISO sensor sensitivity, or at high temperatures. It takes advantage of the fact that two components of image noise, dark current and fixed-pattern noise, are the same from shot to shot. This function also has a mutating version clubbed along with it.&lt;/p&gt;

&lt;h3 id="hmmm-interesting-whats-next"&gt;&lt;em&gt;Hmmm, interesting… What’s next?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Wait, it’s not yet over! I have also implemented these functions to interface directly with &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files and &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt; (an element of the &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files), putting it simply, a user can load the data (stored in &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; format) directly from the disk and then can play with all these functions!&lt;/p&gt;

&lt;h3 id="okay-cool-so-whats-next-do-you-still-have-something-in-the-pipeline"&gt;&lt;em&gt;Okay, cool! So what’s next? Do you still have something in the pipeline?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes, the combine function still needs to be interfaced with &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files, and once done, I will go for a release of the package. The next steps would be user-friendly processing pipelines, iterator reductions, and lot’s of documentation to be packed up together with the package.&lt;/p&gt;

&lt;p&gt;Stay tuned to know more!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_1804_siddharthlal25/</guid><pubDate>Mon, 15 Jun 2020 17:04:56 GMT</pubDate></item><item><title>GSOC 2020: The Coding period commences!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0923_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TYpSW6DKJusjkp7EMXIhyA.png"&gt;&lt;figcaption&gt;Sunrise in Gujarat, near Vadodara city&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So we got started with the coding period, I had a couple of community meetings with my mentors and few full community meetings where I discussed what I was working upon and what was needed to be done.&lt;/p&gt;
&lt;p&gt;Major work in this fortnight was on refactoring&lt;strong&gt; &lt;/strong&gt;&lt;em&gt;Dataretriever Clients &lt;/em&gt;QueryResponse tables Pull request, &lt;a href="https://github.com/sunpy/sunpy/pull/4213"&gt;PR #&lt;strong&gt;4213&lt;/strong&gt;&lt;/a&gt;. This enabled the simple clients to show more metadata information like SatelliteNumber , Detector, Level, etc. in their response tables. All this information was extracted from the URL corresponding to the desired files using the parser.&lt;/p&gt;
&lt;p&gt;What did it change? Earlier the things looked like this:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0923_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/7f467616b2076a3bc10e61d6de755ee3/href"&gt;https://medium.com/media/7f467616b2076a3bc10e61d6de755ee3/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;And now:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0923_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/c9f17aab04a6eac7d1ddd745b2d2f0bf/href"&gt;https://medium.com/media/c9f17aab04a6eac7d1ddd745b2d2f0bf/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Those np.nan Wavelength values annoyed me the most and now we not only be having the correct wavelengths, but other details too reflected in the response table. All the columns which were not relevant to the client were removed.&lt;/p&gt;
&lt;p&gt;Was that all about it? No. We need to find better ways of implementing the same feature. Earlier I used a _get_metadata_for_url method to extract all details from the URL, which was separately implemented for all clients. After getting the suggestions from my mentors, I implemented it in a better way; extracting all info in the scraper itself. After completing all tests, we discovered that there can be an even better way of doing this; by removing the client-specific _get_url_for_timerange() method itself! I used the registered attrs for achieving the same. All attrs were iterated to get the list of all possible directories, and then the only thing scraper has to do was pattern matching.&lt;/p&gt;
&lt;p&gt;The idea was to closely link scraper and GenericClient to have minimum client-specific code in their class implementations. I’ll push the changes as I complete all failing tests due to the change and add documentation for the API.&lt;/p&gt;
&lt;p&gt;All the 4 Ground Clients PRs were closed, after a discussion with the SunPy and VSO community. I updated my&lt;a href="https://github.com/sunpy/sunpy/pull/5055"&gt; Gong Synoptic Client Pull Request&lt;/a&gt; and got so far all reviews resolved. This would enable SunPy to access the Magnetogram Synoptic Map archives from NSO-GONG. Originally the issue was opened in &lt;a href="https://github.com/dstansby/pfsspy"&gt;pfsspy&lt;/a&gt;&lt;strong&gt;. &lt;/strong&gt;I also worked on a fix to the wrong goes Satellite Number issue in &lt;a href="https://github.com/sunpy/sunpy/pull/4288"&gt;PR #&lt;strong&gt;4288&lt;/strong&gt;&lt;/a&gt; recently. Using **kwargs in _get_overlap_urls method fixed the bug.&lt;/p&gt;
&lt;p&gt;There were other PRs too made and updated in this period which were merged before SunPy’s 2.0 release. I reduced the time for a goes_suvi client test from 8–10 secs to 1.5–2 secs on my system, in &lt;a href="https://github.com/sunpy/sunpy/pull/4131"&gt;PR #&lt;strong&gt;4099&lt;/strong&gt;&lt;/a&gt;. I had to explore why scraper took so much time for the test. Another one &lt;a href="https://github.com/sunpy/sunpy/pull/4132"&gt;PR #&lt;strong&gt;4132&lt;/strong&gt;&lt;/a&gt; was a way to prevent a future bug in scraper’s filelist method; so now it checks if the &lt;em&gt;&amp;lt;a href&amp;gt; &lt;/em&gt;in any webpage is None or not.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/sunpy/sunpy/pull/4011"&gt;PR #&lt;strong&gt;4011&lt;/strong&gt;&lt;/a&gt; was also updated which will restore the ability to post search filter the responses from VSO. I also went through the JSOC codebase and fido_factory.py to understand the complexities of implementation of&lt;em&gt; Fido post-search filter&lt;/em&gt; in SunPy. It is the next target in my Project. Just as a glimpse, this is how the VSO will look after post search filtering. I have added an extra concatenation routine by overloading + operator.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0923_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/ef282104564e47da6f9bef13c237313e/href"&gt;https://medium.com/media/ef282104564e47da6f9bef13c237313e/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;I’m enjoying my summer now, wherever I face diffculties I talk with my mentors to get it resolved. I faced some issues in connectivity due to the thunderstorms out there in my city, but now everything is back to normal. The weather is pleasant now so I can engage more!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*g_aP_bLgp1XI6ACBOrN69A.png"&gt;&lt;figcaption&gt;Before Thuderstorms in Vadodara!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Looking forward to making more PRs in the next fortnight!&lt;/p&gt;
&lt;p&gt;CARPE NOCTEM!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b2eee33f274e" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0923_abhijeetmanhas/</guid><pubDate>Mon, 15 Jun 2020 08:23:54 GMT</pubDate></item><item><title>Chapter 1: Apricity</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/</link><dc:creator>Raahul Singh</dc:creator><description>&lt;div&gt;&lt;h5&gt;An endeavour to better understand our Sun’s choleric disposition&lt;/h5&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/781/1*tAMsUBRSvq7pUUyMNRAEuQ.jpeg"&gt;&lt;figcaption&gt;&lt;strong&gt;The Bhagirathi Massif&lt;/strong&gt;. The mountain is named after &lt;a href="https://en.wikipedia.org/wiki/Bhagiratha"&gt;Bhagiratha&lt;/a&gt;, the legendary king of the Ikshvaku dynasty who brought the River Ganges, to Earth from the heavens. It symbolizes the flow of divine knowledge, or the knowledge of liberation (Ganga), into human consciousness (earth) by the grace of God (Shiva) and the austere efforts of enlightened masters (Bhagiratha).&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;&lt;strong&gt;ॐ भूर् भुवः स्वः।&lt;/strong&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;strong&gt;तत्सवितुर्वरेण्यं भर्गो॑ देवस्य धीमहि।&lt;/strong&gt;&lt;/blockquote&gt;&lt;blockquote&gt;&lt;strong&gt;धियो यो नः प्रचोदयात् ॥&lt;/strong&gt;&lt;/blockquote&gt;&lt;p&gt;There is some beauty in the fact that the essence of my undertaking needs not more than 24 letters of explanation.&lt;/p&gt;
&lt;p&gt;What I have written above in the &lt;a href="https://en.wikipedia.org/wiki/Devanagari"&gt;Devanagari&lt;/a&gt; script is one of the most important and highly revered Vedic hymns, the Gayatri Mantra. As translated by &lt;a href="https://en.wikipedia.org/wiki/S._Radhakrishnan"&gt;Dr S. Radhakrishnan,&lt;/a&gt; it states,&lt;/p&gt;
&lt;blockquote&gt;“We meditate on the effulgent glory of the divine Light; may he inspire our understanding.’’&lt;/blockquote&gt;&lt;p&gt;The goal of my project is to study solar flares. The effulgent glory, the flares, that the divine Light, our Sun, produces. I shall meditate on them over the summer and better my understanding and appreciation of the mechanisms that govern them.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I shall also dare to predict them.&lt;/p&gt;
&lt;p&gt;And there you have it,&lt;br&gt;
&lt;strong&gt;Solar Weather Forecasting using linear algebra.&lt;/strong&gt;&lt;/p&gt;
&lt;h4&gt;&lt;em&gt;The Dataset&lt;/em&gt;&lt;/h4&gt;&lt;p&gt;When thinking about flares, you may imagine something like this :&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*YC4dFQkU03gCMsuZI36RfA.jpeg"&gt;&lt;figcaption&gt;On August 31, 2012, a long prominence/filament of solar material that had been hovering in the Sun’s atmosphere, the corona, erupted out into space at 4:36 p.m. EDT. Seen here from the &lt;a href="https://en.wikipedia.org/wiki/Solar_Dynamics_Observatory"&gt;Solar Dynamics Observatory&lt;/a&gt;, the flare caused auroras to be seen on Earth on September 3.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Flares indeed are mesmerizing. &lt;br&gt;
To analyze the properties of flares, we must understand what flares are.&lt;/p&gt;
&lt;p&gt;A &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#FLARE"&gt;solar flare&lt;/a&gt; occurs when magnetic energy that has built up in the &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#SOLAR_ATMOSPHERE"&gt;solar atmosphere&lt;/a&gt; is suddenly released. &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#ELECTROMAGNETIC_RADIATION"&gt;Radiation&lt;/a&gt; is emitted across virtually the entire &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#ELECTROMAGNETIC_SPECTRUM"&gt;electromagnetic spectrum&lt;/a&gt;, from radio waves at the long &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#WAVELENGTH"&gt;wavelength&lt;/a&gt; end, through &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#OPTICAL"&gt;optical&lt;/a&gt; emission to &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#X_RAY"&gt;x-rays&lt;/a&gt; and &lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#GAMMA_RAY"&gt;gamma rays&lt;/a&gt; at the short wavelength end. The amount of energy released is the equivalent of millions of 100-&lt;a href="https://hesperia.gsfc.nasa.gov/sftheory/glossary.htm#MEGATON"&gt;megaton&lt;/a&gt; hydrogen bombs exploding at the same time!&lt;/p&gt;
&lt;p&gt;These flares emanate from active regions (ARs) in which high magnetic non-potentiality resides in a wide variety of forms.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Active regions&lt;/strong&gt; on the Sun are places where the Sun’s magnetic field is disturbed. These &lt;strong&gt;regions&lt;/strong&gt; frequently spawn various types of &lt;strong&gt;solar&lt;/strong&gt; &lt;strong&gt;activity&lt;/strong&gt;, including explosive “&lt;strong&gt;solar&lt;/strong&gt; &lt;strong&gt;storms&lt;/strong&gt;” such as &lt;strong&gt;solar&lt;/strong&gt; &lt;strong&gt;flares&lt;/strong&gt; and coronal mass ejections (&lt;strong&gt;CME&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;What you see below, is a full disk Line of Sight (LOS) Magnetogram, which is an image of the sun’s magnetic field in the line of sight of the observer.&lt;/p&gt;
&lt;p&gt;The data used in this project comes from &lt;a href="https://www.sunspotter.org/"&gt;Sunspotter,&lt;/a&gt; which is a dataset of such magnetograms with some measured properties for each Active Region.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*oegoLxwR316N4RUuqfKoVw.png"&gt;&lt;figcaption&gt;A full disk Magnetogram&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/360/1*MNeHF04MLtDXL_0U0D15uw.jpeg"&gt;&lt;figcaption&gt;An Active Region&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/360/1*zH_kdPqd0HymM1j94CRjMg.jpeg"&gt;&lt;figcaption&gt;Another Active Region&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;a href="https://www.sunspotter.org/"&gt;Sunspotter&lt;/a&gt; is a citizen science project that asked volunteers to classify solar active regions by their complexity — as it’s believed complexity has a direct relationship with their activity. With more than 25,000 volunteers and millions of classifications produced, we’ve got a &lt;a href="https://zenodo.org/record/1478972#.XI4YPqHgqr8"&gt;very nice dataset&lt;/a&gt;. The images used come from the &lt;a href="http://soi.stanford.edu/science/obs_prog.html"&gt;MDI instrument&lt;/a&gt;, which is onboard of &lt;a href="https://en.wikipedia.org/wiki/Solar_and_Heliospheric_Observatory"&gt;SOHO&lt;/a&gt; — the NASA-ESA mission that’s been observing the sun for more than two decades.&lt;/p&gt;
&lt;p&gt;All of the Active Region observations have a corresponding image, like the ones you see here.&lt;/p&gt;
&lt;p&gt;The dataset is composed of five files:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;&lt;strong&gt;lookup_timesfits.csv&lt;/strong&gt;: lists the filenames and the date of the data acquisition.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;lookup_properties.csv&lt;/strong&gt;: lists the properties of the active region observed in each frame to be classified.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;classifications.csv&lt;/strong&gt;: lists each classification made by the volunteers.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;rankings.csv&lt;/strong&gt;: lists the final ranking on complexity.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The score provided on the rankings file follows the &lt;a href="https://en.wikipedia.org/wiki/Elo_rating_system"&gt;Elo rating system&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I have &lt;a href="https://github.com/Raahul-Singh/pythia/pull/26"&gt;recreated the ELO rating algorithm in python&lt;/a&gt;, to reassign complexity score to the Active Regions. This gives us better control over the range of values, which in turn can be tuned to match the sensitivity of the forecasting model.&lt;/p&gt;
&lt;h4&gt;Apollo’s chosen one&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/345/1*OQvcPJAalRluEumfTTZwcA.jpeg"&gt;&lt;figcaption&gt;&lt;em&gt;Priestess of Delphi&lt;/em&gt; (1891) by &lt;a href="https://en.wikipedia.org/wiki/John_Collier_(Pre-Raphaelite_painter)"&gt;John Collier&lt;/a&gt;, showing the Pythia sitting on a tripod with vapour rising from a crack in the earth beneath her&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Apollo, the Greek god of the Sun, was also the god of prophecies. It is said that when Apollo wished to speak to the mortals, he would speak through his chief priestess, the Oracle of Delphi. She, who alone could understand Apollo’s whims and fancies. The High priestess, &lt;a href="https://en.wikipedia.org/wiki/Pythia"&gt;&lt;strong&gt;&lt;em&gt;Pythia&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;In reverence, I have thus decided to name the repository that holds the code for this project, &lt;a href="https://github.com/Raahul-Singh/pythia"&gt;&lt;strong&gt;Pythia&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pythia&lt;/strong&gt;, &lt;strong&gt;for Solar Active Region Data Analysis.&lt;/strong&gt;&lt;br&gt;
Although we have just started, there is a lot you can do with Pythia already.&lt;/p&gt;
&lt;p&gt;To install Pythia, for now, run the following command:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/43055aa62917cd54a819f498174ce0f5/href"&gt;https://medium.com/media/43055aa62917cd54a819f498174ce0f5/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Some of the functionalities that Pythia offers, as of writing this post are:&lt;/p&gt;
&lt;p&gt;Using Pythia, you can get the measured properties of any AR in the Sunspotter dataset. This is done using &lt;a href="https://docs.sunpy.org/en/stable/guide/acquiring_data/hek.html"&gt;SunPy’s HEK &lt;/a&gt;module. This is the function description.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/339c9dc8054c807970ce6a1823d0e284/href"&gt;https://medium.com/media/339c9dc8054c807970ce6a1823d0e284/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;You can also download the full disk MDI magnetograms. This uses &lt;a href="https://docs.sunpy.org/en/stable/guide/acquiring_data/fido.html"&gt;SunPy’s FIDO&lt;/a&gt; module to get the magnetogram as a FITS file. The following function returns an &lt;a href="https://docs.sunpy.org/en/stable/guide/data_types/maps.html"&gt;MDI map&lt;/a&gt; for a given observation date. Should the observation date not be in the Sunspotter dataset CSV files currently loaded in the Sunspotter object, the observation date nearest to the given observation date is used.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/c19b389e053b71b99ada4301c317e5b1/href"&gt;https://medium.com/media/c19b389e053b71b99ada4301c317e5b1/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Should you wish for all the maps in a given range, you can use:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/501b65fb40960a2b1af47fbaa1d36962/href"&gt;https://medium.com/media/501b65fb40960a2b1af47fbaa1d36962/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Finally, if you wish to plot all the ARs on a full disk magnetogram for which we have data, for any observation date,&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/83603bbd1bd1805d5c0885e08143e66b/href"&gt;https://medium.com/media/83603bbd1bd1805d5c0885e08143e66b/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Which, when used for observation date &lt;strong&gt;2002–03–18 09:39:01 &lt;/strong&gt;gets you the following plot. I have magnified it to highlight the fact that Active Regions come in all shapes and sizes.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TyCM1QtLG2yYXXiToq6eZQ.png"&gt;&lt;figcaption&gt;ARs Plotted on an MDI map&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;What I have given is a brief introduction of the project, along with some code examples. Pythia is in active development and there are modules whichI have not mentioned here. I encourage my readers to install Pythia and play around with the code!&lt;/p&gt;
&lt;p&gt;If you find any bugs or would like me to add any features, feel free to &lt;a href="https://github.com/Raahul-Singh/pythia/issues"&gt;open an issue on the main repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;My next post will be all about the Exploratory Data Analysis of the Sunspotter data, where we shall delve deep into the Sunspotter dataset.&lt;/p&gt;
&lt;p&gt;Till then,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;Divina Luceit Vos!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;:)&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=aef3bd172dab" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200615_0026_raahul-singh/</guid><pubDate>Sun, 14 Jun 2020 23:26:29 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 1.1</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200614_0634_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;The official coding period of GSoC 2020 has begun on June 2nd (HKT) and the glue-solar work is currently underway according to plan as discussed with mentors &lt;strong&gt;Stuart Mumford&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;and&lt;strong&gt;&lt;em&gt; &lt;/em&gt;Nabil Freij &lt;/strong&gt;during the community bonding period that precedes the coding period. The tasks proposed that we would like to see implemented this summer include but not limited to the following:&lt;/p&gt;
&lt;p&gt;1. Modify the existing glue 1D Profile viewer to provide sliders for extra dimensions (currently collapses)&lt;br&gt;
2. Clean up UX / UI (icon) for the pixel extraction tool (perhaps also upstreaming from glue-solar to glue)&lt;br&gt;
&lt;!-- TEASER_END --&gt;
3. WCS info for derived datasets (i.e. raster + SJI time linking)&lt;br&gt;
4. Loaders for specific instruments: NDData (in glue), NDCube (for NDCube 2.0 with extra coords), SST, IRIS, EIS, DKIST (e.g. with asdf to glue) &lt;br&gt;
5. Add auto-linking to match wavelength and time dimensions in larger cubes (currently already works for Celestial dimensions)&lt;br&gt;
6. Enable image / Movie exports, both with axes and without axes via the matplotlib package&lt;br&gt;
7. Add support for pre-computed statistics in datasets / viewers&lt;/p&gt;
&lt;p&gt;The above, along with the accompanying documentation, are expected to be part of the deliverables of the GSoC project. So far a couple of pull requests (PRs) have been submitted to both the glue and glue-solar repositories (repos), with the most recent one being the one for updating the 1D Profile viewer to plot with wcsaxes instead, which can be accessed at glue-viz/glue's &lt;a href="https://github.com/glue-viz/glue/pull/2156"&gt;PR #2156&lt;/a&gt;. However, the CI problem encountered in this PR seems to be able to be fixed by upstreaming the pixel extraction tool which currently only resides in glue-solar. This will need to be discussed with my mentors as careful considerations such as one pertaining to timing are warranted.&lt;/p&gt;
&lt;p&gt;One of the first glue-solar PRs I have worked on are for adding an “open with SunPy Map” option to the “Import Data” tool. Part of this tool has been merged into glue-solar, while the other part is pending merge in glue. Basically if I load in an AIA map with its associated HMI map, like the sample one from SunPy, while choosing “SunPy Map” as opposed to the FITS format that gets detected by default, as shown in the Fig. 1:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*f1TZWTVe_Z7YqSwvPEGHXg.png"&gt;&lt;figcaption&gt;Fig. 1. Choosing “SunPy Map” to visualize SunPy maps with Glue.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So if one plots the SunPy maps individually, one would get the what is shown in Fig. 2. This is basically the same as what one would get with FITS files as well, except for the colormaps.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*-xqO_mMCzSNAAZAr6ipeJA.png"&gt;&lt;figcaption&gt;Fig. 2. Plotting “SunPy Map” objects individually&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The magic of our work is that now with the glue-solar plugin, we can overplot AIA map and its associated HMI map, as simply as dragging the HMI data from the Data section onto the AIA map 2D image already opened with the 2D Image viewer, as these are spatially linked by the plugin using some pixel-to-pixel transformation via WCS.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*q0SWRNVOImWlLmpQ2k6_hQ.png"&gt;&lt;figcaption&gt;Fig. 3. Overplotting HMI data with AIA data with colormaps&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So the subject of attention that has been the focus of my glue-solar work, or my favorite “toy”, over the last few weeks has been firstly a prototype for a “SunPy 1D Profile” tool which plots a 1D spectrum at a spatial position as picked out by the pixel extraction tool currently resides within glue-solar. To upstream the changes I have made to glue, and with the help of my mentors especially Stuart, we have started work on a PR to move such changes to the “1D Profile” in glue proper, using my “SunPy 1D Profile” work as a check and basis. If one loads in a raster cube using some IRIS level 2 data using the IRIS Spectrograph file type enabled by glue-solar, plots a slice of the data cube with the “2D Image” viewer, and then extracts a pixel position in the 2D image in the viewer (with the “HPLN” as the x-axis in lieu of the “wavelength” as the default option), one obtains a 1D profile upon hitting the spectrum icon in the 2D Image viewer panel. The result is as depicted in the collapsing “Fig. 4” image below:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WZdvkWlnqECjS66SIM9zbQ.png"&gt;&lt;figcaption&gt;Fig. 4. Plotting a 1D spectrum with wavelength as the x-axis and “Maximum” as the default function option.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;After which if one changes the “function” in the “Plot Options — 1D Profile” from the “maximum” to the newly added “slice” option in my PR, one would obtain a 1D spectrum without any collapsing as shown in the “Fig. 5” image below:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*8ha0cEHSzxaY1zX-iSgMLw.png"&gt;&lt;figcaption&gt;Fig. 5. Visualizing a 1D spectrum at a pixel coordinate position after switching to the `Slice` function option that is non-collapsing.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This non-collapsing 1D spectrum plotting facility is new to glue with the glue-solar plugin, and is currently still under heavy development.&lt;/p&gt;
&lt;p&gt;Overall it has been a great experience this second time around participating in GSoC at this early phase. The experience is especially positive given that I am engaged in some work that I could understand and really like. Previously I have been exposed to data cubes in my PhD studies in astrophysics, with the knowledge gained now comes in handy for my glue and glue-solar work. I look forward to contributing as much as possible to the project in the months to come during GSoC, and possibly beyond.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=c2151e535e0c" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200614_0634_kakirastern/</guid><pubDate>Sun, 14 Jun 2020 05:34:50 GMT</pubDate></item><item><title>GSoC 2020: Blog 1 - Beginning of Coding Period</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_1820_jes24/</link><dc:creator>Jyotirmaya Shivottam</dc:creator><description>&lt;div&gt;&lt;p&gt;So the community bonding period of GSoC has ended and the coding period is officially underway. In my last blogpost, I had outlined the basic principles of General Relativity that go into my project. I had also mentioned, that the next blog will have details about the coding process. However, things had to be slowed down considerably, due to the announcement of closure of my academic session and some logistical issues. This has also affected my blog schedule, as I could not work on a blog, that was supposed to be up 2 weeks ago. However, I am pleased to inform that all the issues are sorted out now, leaving the rest of the summer free for me to delve into the project. Whew. I am also exceedingly grateful to my mentors, who have been understanding throughout. As for details on the code implementation for my project, I have decided to break it up across the blogs, as "Progress Reports" (bland, I know), in order to provide a better understanding of both what I am working on and my approach to it. So, read on.&lt;/p&gt;

&lt;h3&gt;
&lt;!-- TEASER_END --&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200613_1820_jes24/#progress-so-far" class="anchor"&gt;
&lt;/a&gt;
Progress so far...
&lt;/h3&gt;

&lt;p&gt;Over the last few discussions with my GSoC mentors, we have discovered some logical bottlenecks in some of the EinsteinPy modules, especially the way the &lt;code&gt;metric&lt;/code&gt; &amp;amp; &lt;code&gt;utils&lt;/code&gt; modules work at the moment. Currently, the &lt;code&gt;utils&lt;/code&gt; module stores most of the necessary functions required to form a &lt;code&gt;metric&lt;/code&gt; class, while the &lt;code&gt;metric&lt;/code&gt; module lacks support for user-defined metrics. It also handles the calculation of particle trajectory, which logically belongs inside a &lt;code&gt;geodesic&lt;/code&gt; module. Since my project is on Null Geodesics, these issues are major obstacles, that must be overcome, before the work on adding support for Null Geodesic calculation begins.&lt;/p&gt;

&lt;p&gt;As such, I am refactoring these modules, so that we have logical cohesion across EinsteinPy, whilst also adding some new features, like a brand new &lt;code&gt;metric&lt;/code&gt; class, that supports defining arbitrary metrics and also adding first order linear perturbations to the metric, written in Kerr-Schild form. I have also grouped together the utility functions present in &lt;code&gt;utils&lt;/code&gt; in &lt;code&gt;metric&lt;/code&gt; itself. These changes can be followed at the PR link, &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/512"&gt;here&lt;/a&gt;. At the moment, I am reusing some of the old tests and writing some new ones for the new features. I hope to see this PR clear all tests and be merged soon.&lt;/p&gt;

&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200613_1820_jes24/#until-next-time" class="anchor"&gt;
&lt;/a&gt;
Until next time...
&lt;/h3&gt;

&lt;p&gt;After &lt;code&gt;metric&lt;/code&gt;, comes the &lt;code&gt;coordinates&lt;/code&gt; module, which will see some changes and code rearrangements too, albeit not as much as &lt;code&gt;metric&lt;/code&gt; and &lt;code&gt;utils&lt;/code&gt;. The basic work on this has already started and after the first PR is merged, I will open another PR with these changes.&lt;/p&gt;

&lt;p&gt;We have lost around 2 weeks, due to the aforementioned issues on my side. Therefore, it is contingent on me to accelerate the pace of development now. Over the next few weeks, we should see some cool new feature additions to EinsteinPy. I will be detailing them here, as we proceed with the project.&lt;/p&gt;&lt;/div&gt;</description><category>EinsteinPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_1820_jes24/</guid><pubDate>Sat, 13 Jun 2020 17:20:19 GMT</pubDate></item><item><title>Week 1 &amp; 2: Tip-Off</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_0950_sahilyadav27/</link><dc:creator>Sahil Yadav</dc:creator><description>&lt;div&gt;&lt;p&gt;The first week started off with having a video call with the mentors and trying to pave the path ahead for the next 3 months. There were 2 options: Either convert ROOT files to the hdf5 format from CTA or establish a new DL1 reader for ROOT. I decided to run some tests and get an idea about the speed and memory requirements for both the methods. We were more inclined to create a new class for the ROOT files so that we don’t have to save a separate hdf5 file for each ROOT file when using CTLearn. The reading times for both the file types were also similar, so we decided to implement a new child class for ROOT files.&lt;/p&gt;
&lt;p&gt;In order to move ahead with this plan, I first wrote down the entire DL1DataWriter code, highlighting the hdf5 dependent parts. This way, I was able to get a better understanding of the code and its intricacies. After talking with Tjark some more, we decided to implement 2 child classes for hdf5 and ROOT which inherited the parent Writer class.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/251/1*JDweXFtW-o-ZqcIbIfzkoQ.png"&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/251/1*BfDNzmeG5NYEQn8xTOGZrg.png"&gt;&lt;figcaption&gt;MC simulated images from MAGIC Cam 1 &amp;amp; 2, an event which only triggered one telescope and not the other.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;After another video call, Ari suggested that I convert the ROOT files into an hdf5 file with the CTA ML Data format to understand the differences between the formats of MAGIC and CTA. Although there is already a library ctapipe_io_magic to produce the MAGICEventSource and use it for DL1DataReader and produce an hdf5 file, there were a lot of issues with trying to use it.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;So we decided to implement our own code to convert the file. This way, any ROOT file can be converted to hdf5 and used by CTLearn before the actual project is complete and in place. During week 2, I worked on writing code for the same. It is mostly complete and a few things need to be ironed out which will be done in the next call on 15th.&lt;/p&gt;
&lt;p&gt;Once this is done, I’ll start to work on creating separate child classes for ROOT and hdf5 inheriting from DL1DataWriter as discussed above.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=1eb6744a41ea" width="1" height="1"&gt;&lt;/div&gt;</description><category>CTLearn</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_0950_sahilyadav27/</guid><pubDate>Sat, 13 Jun 2020 08:50:12 GMT</pubDate></item><item><title>Community Bonding Period-GSoC20</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;p&gt;It was around 11:30 in the night on 4th of May, the Google servers glitched for a second or so but then I could see my project on the Org’s list.&lt;/p&gt;

&lt;p&gt;Finally, I got selected for GSoC 2020 after around two months of involvement with the JuliaAstro community. Before my selection, I had primarily contributed to &lt;a href="https://github.com/JuliaAstro/Photometry.jl"&gt;Photometry.jl&lt;/a&gt; and &lt;a href="https://github.com/JuliaAstro/DustExtinction.jl"&gt;DustExtinction.jl&lt;/a&gt;, both were a part of the JuliaAstro community!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;The next step was the community bonding phase, in this phase, I got my development setup more robust (I updated my OS, updated Atom, and also Juno). I also sharpened my Julia skills and learned the art of succinct documentation in this period. I went through the codebase of the repositories available in this community to get a flavor of Julia and it’s usage for making things work!&lt;/p&gt;

&lt;p&gt;Since I was under lockdown back in my hometown, I got quite bored and decided to start contributing towards the project. I set up the basic framework of the package and added a few basic skeletal functions after discussions about it with the mentors.&lt;/p&gt;

&lt;p&gt;At last, I would like to thank Miles, Mosè, and Yash for their guidance and prompt responses to all my dumb queries, it wouldn’t have been possible for me to start contributing without their guidance and help. A big shout-out to you guys! Thank you so much!&lt;/p&gt;

&lt;p&gt;Oh! I forget to mention my project, this summers I will be developing a package for reduction of astronomical images in Julia.&lt;/p&gt;

&lt;p&gt;Stay tuned for my upcoming blogs to know more about the project!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_siddharthlal25/</guid><pubDate>Sat, 30 May 2020 17:04:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #0!</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey there. Welcome to the first of what is going to be a series of blog posts chronicling my journey as I participate in the Google Summer of Code this year with RADIS (registered as a sub-org under OpenAstronomy). This particular blog post, as the title suggests, is meant to give a quick introduction to GSoC as well as my organization and the project.&lt;/p&gt;

&lt;h4 id="what-is-google-summer-of-code"&gt;What is Google Summer of Code?&lt;/h4&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Borrowing straight from it’s landing page, Google Summer of Code is a global program focused on bringing more student developers into open source software development. Students work with an open source organization on a 3 month programming project during their break from school.
In other words, GSoC (as it is more commonly referred to) is a program sponsored by Google which aims to connect university students around the world with open source organizations in order to promote the open-source culture. The students get an opportunity to peek into the world of open source development, learn new skills and also get compensated for the work, quite generously. In turn, the organizations benefit from a few extra pairs of helping hands, using them for a wide array of issues, from refactoring code, to fixing existing bugs, and ofcourse, to add new features to the existing code base. It’s a great program and any college student interested in software development should definitely check it out. The website contains a lot more information &lt;a href="https://summerofcode.withgoogle.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now that’s clear, let me talk a little about the specific organization that I will be working with.&lt;/p&gt;

&lt;h4 id="radis--openastronomy"&gt;RADIS ∈ OpenAstronomy&lt;/h4&gt;

&lt;p&gt;While the most commmon way for organizations to participate in the program and request slots for GSoC is to register directly, many organizations, for various reasons, often come together under an umbrella organization and register for GSoC as one single unit. This bundling of organizations can happen on various basis, but the most common reason is that these organizations often work towards the same goal, or operate in the same domain. In my case, this is true as well. I applied for and got selected for GSoC with the OpenAstronomy organization, which as the name suggests is an umbrella organization meant to act as a central hub for all the great number of ‘sub-organizations’ that operate within it. You can read more about OpenAstronomy and what it does &lt;a href="https://openastronomy.org/"&gt;here&lt;/a&gt;. One such sub-organization, with which I shall be working, happens to be RADIS.&lt;/p&gt;

&lt;p&gt;RADIS is a radiation software, a fast line-by-line code for synthesizing and fitting infrared absorption and emission spectra such as encountered in laboratory plasmas or exoplanet atmospheres.&lt;/p&gt;

&lt;p&gt;While RADIS was written with performance in mind, and performance it delivers, it is still limited by factors such as the speed offered by Python, and using a single CPU to carry out all its calculations. While the problem with a programming language can be solved (not so) easily by switching to other languages, such as C++, we’re still limited to using a single processing unit to carry out all the computations. This is the exact problem that my project tries to solve. The title of my project, “Accelerate Synthetic Spectra Calculations using CUDA”, is all about removing the restriction of a single CPU and instead allow RADIS to perform much faster by utilising the power of a GPU instead. I will not be going into the detail of the project here/yet, but the general idea is to switch certain parts of the pipeline in RADIS’ execution which slow it down to the GPU, which as people familiar with GPUs would know, is adept at executing a large volume of simple tasks.&lt;/p&gt;

&lt;p&gt;The technicalities of the project, including how exactly the problem can be shifted to the GPU, how its being implemented on the GPU, or its integration with the RADIS will be discussed in the future blog posts. For now, I will like to keep this blog limited to the things that have already occured, as a part of the ‘Community Bonding Period’:&lt;/p&gt;

&lt;h4 id="the-community-bonding-period"&gt;The Community Bonding Period&lt;/h4&gt;

&lt;p&gt;The Community Bonding Period is an almost 30-days long period meant to serve as a warm-up or a buffer before the actual coding period begins. It can be used for a wide variety of purposes, such as getting a better understanding of the codebase, figuring out the intricacies of your project et al. As such, the greater part of my community bonding period went into understanding the exact details of what I will be doing over the coming months and how I will be doing it. While the pre-selection period did include a fair amount of contributions being made by me towards the organization, it was mainly an attempt to understand the general architecture and codebase of RADIS more thoroughly, and did not involve anything specific to the project I had applied for. Once the selected projects were made public on 4th May 2020, that is when the community bonding period officially started and I started to focus exclusively on my project as well. The seed idea that eventually led to my project started when my mentors decided to play around with the code, and instead of using pure Python for the processing, decided to precompile some of the slower parts of the code into a DLL and imported it to Python instead. The results of this experiment were incredible, and paved the way for my mentor, Dirk van den Bekerom to write the first proof-of-work code demonstrating the use of GPUs to calculate the spectras that were previously being done entirely on the CPU. Benchmarking showed performance boosts of upto 10,000x compared to the naive implementation of spectra calculations on Python and upto 50x from the current implementation of RADIS.&lt;/p&gt;

&lt;p&gt;After discussing with my mentors, the project timeline was decided and the work was done accordingly. Keeping in mind my objectives for the coming month, as a part of the first evaluation, I decided to spend a lot of time on understanding the existing code base of RADIS &lt;em&gt;which focuses on the spectra calculations&lt;/em&gt;. Note that this is completely different from the code that I worked on earlier, which focussed on issues completely different from this, and mostly revolved around the post-processing of spectra instead of calculating it. This included a light reading of the original RADIS paper which talked about the general idea and logic behind RADIS. In addition to that, I also spent time on setting up the right environment for the development work that was to come.
Since the project is about GPUs and CUDA, I had to ensure that CUDA was properly installed and running on my system. While this might seem like a trivial task, it can easily get very messy when working on a linux distribution. Fortunately, I already had a working installation of CUDA on my system so I didn’t have to spend much time on it except for testing and tuning it. Another major issue that this project entailed was the handling of vast amounts of data.&lt;/p&gt;

&lt;p&gt;To keep it simple, in order to calculate the spectra, RADIS requires some data. This data includes information on various parameters such as positions, intensities, air- and self-broadened half-widths, et cetera for different molecules. For my project, for the time being, I was using the CDSD-4000 database, which is a high-temperature databank for CO2 molecule. The major issue this databank presented was the vast size of it. While the complete databank would have been incredibly huge (but fortunately not needed) the portion of the databank that we did focus on was not a small package either, occupying 30GB space unprocessed. Further processing of this data reduced it down to 8GB. While that might seem like a manageable size, the issue was that in order to compute the spectra efficiently and reduce the latency in loading the data, all of it had to be stored on the device RAM. This requirement was simply not possible for me to satisfy with just my personal computer which has a NVidia GTX 1650 with only 4GB of VRAM. Thus, I was left with two options. To either trim the database further and then work on it, or find another machine with specifications high enough to crunch the numbers without trimming it down. After discussing with my mentors and weighing the pros and cons, I decided to try out both.
We used Google Colab with its free GPU access to process the entire 8GB data in one go. The major problem we faced with this method was loading the data onto the colab server. Since even the processed files were 8GB, and Colab did not offer persistent storage, we would have to upload 8GB of data every time we wanted to test the code out, which ofcourse would not have been practical. This was solved by using Google Drive, which can be mounted in colab and work as a persistent storage setup. So far, I have thoroughly enjoyed the convenience and power offered by Colab, and that too for no charge, and hope it continues to perform so wonderfully. In addition, I also trimmed the original database down to smaller sizes and tried to process them on my personal machine, which it did without any hassles.&lt;/p&gt;

&lt;p&gt;Another interesting question that we faced was the tools to use. While it might seem like a no-brainer to use C with CUDA, it unfortunately was not an option as RADIS was written in Python. Therefore, we had to spend a fair amount of time trying to figure out additions to Python in the form of libraries which allow CUDA access. A few of the many different options that are available for such purposes include using Cython, PyCUDA, Cupy, Numba, PyOpenCL and many more. The decision to pick one over the other is a very subjective one, and the answer mostly depends on the kind of application you’re trying to produce. For our particular project, the only requirement was to have access to constant memory on the device which can be achieved using Cython or PyCUDA. While I personally enjoyed PyCUDA due to its extensive documentation and support from NVidia, my mentor seems to prefer Cython so the final decision is still not here!&lt;/p&gt;

&lt;p&gt;Apart from all this, I also spent a good amount of time studying the proof-of-work code that already exists. That included the differences from pure CPU code, the division of work between host and the device, and way the the actual calculations are being done in order to compute the spectra. Finally, I also spent a fair amount of time on revising my CUDA concepts in order to ensure there were no knowledge gaps.&lt;/p&gt;

&lt;p&gt;That pretty much sums up my community bonding period! Over the coming 4 weeks, my objectives include reproducing the proof of work, and figure out the implementation details with my mentors. That will be followed by implementing one of the broadening steps in Python and integrating it with the RADIS.&lt;/p&gt;

&lt;p&gt;I am quite excited about the upcoming months and my journey with RADIS. I believe it will be a great learning experience and I would like to thank Google, OpenAstronomy, RADIS, but most importantly, my incredibly helpful and fun mentors Erwan Pannier, Dirk van den Bekerom and Minesi N for giving me this wonderful opportunity!&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</guid><pubDate>Sat, 30 May 2020 17:04:56 GMT</pubDate></item><item><title>gsoc_journey = {“Prologue”: [“I have a Dream!!”, “GSoC’2020”]}</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200524_2332_theand9/</link><dc:creator>Amogh Desai</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="Milky way as seen from the earth" src="https://cdn-images-1.medium.com/max/1024/1*8xikLJxwWazkSkLTEmKOFA.jpeg"&gt;&lt;figcaption&gt;&lt;strong&gt;“Curiosity is the essence of our existence”&lt;/strong&gt; ~ Gene Cernan&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Childhood, &lt;/strong&gt;as stated by &lt;a href="https://www.unicef.org/sowc05/english/childhooddefined.html"&gt;UNICEF&lt;/a&gt; is &lt;em&gt;“a time for children to be in school and at play, to grow strong and confident with the love and encouragement of their family and an extended community of caring adults.” &lt;br&gt;
&lt;/em&gt;Thinking about it today, it seems like being connected to a continuous 240 V supply of dreams, curiosity, excitement and innocence.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="Encyclopedia — Kingfisher’s Book of the Universe" src="https://cdn-images-1.medium.com/max/289/1*QgW1T6Eenq62-YRAw3ae-g.jpeg"&gt;&lt;figcaption&gt;My favourite encyclopedia. In mint condition after 15 years (Thank you mom for not letting me rip off the outer paper cover 😜)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;One of my dreams was to be an &lt;strong&gt;&lt;em&gt;astronomer&lt;/em&gt;&lt;/strong&gt;. I remember having a lot of encyclopedias on space as a kid(Geek Alert — I have read all my encyclopedias at least 10 times😅 ). I went to NASA once and even built a model telescope (which showed an inverted 20x zoomed image).&lt;br&gt;
&lt;!-- TEASER_END --&gt;
Whenever did an adult ask “&lt;em&gt;beta &lt;/em&gt;what do you want to be when you grow up?” I always replied, &lt;strong&gt;&lt;em&gt;“I want to be an Astronomer!!”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;But the hurdle for realizing my childhood dreams was none other than the &lt;em&gt;Indian Education System&lt;/em&gt;(a story for some other time).&lt;/p&gt;
&lt;p&gt;Back to the present, I am a sophomore pursuing my undergrad in Computer Science with a minor in Artificial Intelligence and Machine Learning(my second favourite area of interest) at Mumbai. &lt;br&gt;
Recently, I stumbled across a term called &lt;strong&gt;Computational Astrophysics, &lt;/strong&gt;which according to &lt;a href="https://www.nature.com/subjects/computational-astrophysics"&gt;Nature.com&lt;/a&gt; is &lt;em&gt;“the study of the phenomena that occur in space using computer simulations. This can involve modelling processes that take place over millions of years, such as colliding galaxies or the slow destruction of a star by a black hole.” &lt;/em&gt;There exists a harmonious amalgamation of &lt;strong&gt;Astrophysics and Computer Science&lt;/strong&gt;(uses ML as well, woohoo!!). I was overjoyed, I felt like I had finally found my calling, life had come around in a full circle.&lt;/p&gt;
&lt;blockquote&gt;“When you have a childhood dream that still burns and tugs at your heart when you’re an adult, you owe it to yourself to pursue and achieve this dream.” — Robert Cheeke&lt;/blockquote&gt;&lt;figure&gt;&lt;img alt="Google Summer of Code 2020" src="https://cdn-images-1.medium.com/max/1024/1*_nxcAB2S0wiyT-KOscvDqA.png"&gt;&lt;figcaption&gt;Viral if you’re reading this. Wouldn’t be inspired to try for GSoC without you. Thanks man!!&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;&lt;strong&gt;Google Summer of Code 2020 — My journey&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;2020 brought with it bushfires, riots, plane crashes and the most dreaded COVID-19 &lt;em&gt;Coronavirus&lt;/em&gt;. But COVID-19 turned out to be a blessing in disguise for me!! (more on this later).&lt;/p&gt;
&lt;p&gt;I planned to apply for Google Summer of Code(GSoC; I’m particularly fond of the abbreviation) during my semester break in December. I read about the program, it’s benefits to the Open-Source community, the value it would add to my profile, the unique learning experience it provides, as well as the nitty-gritty of the application process. I won’t lie, it seemed to be pretty intimidating at first, but luckily my seniors who were a part of GSoC’2019 had briefed us about the program(thanks a ton Pujan, Ruturaj, Sahil😁) well in advance.&lt;/p&gt;
&lt;p&gt;First things first, I dual booted Ubuntu on my laptop(best decision ever!!), got familiarized with the basics of GitHub and set up IRC and Slack on my laptop(I was already using Slack for another college club).&lt;br&gt;
Now, with the prerequisites out of the picture, I went through the organizations that had consistently been a part of GSoC for the last 5 years. &lt;br&gt;
My skillset mainly includes Python, Data Science and Machine Learning with some experience in Web Development. I searched for organizations which had projects in Python with some exciting applications. I shortlisted CERN-HSF, OpenAstronomy and INCF. During my break, I contributed to a few repositories by fixing a few bugs, spelling-errors, refactoring code and the like.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;February 18th&lt;/strong&gt;, &lt;strong&gt;2020, &lt;/strong&gt;the date when the student projects were going to be announced came faster than I had anticipated. I followed the same approach as I did in December while shortlisting organizations and topics. In addition to the organizations I had shortlisted in December, I looked for new organizations and topics that interested me. Initially, I had a long list of &lt;em&gt;8 topics&lt;/em&gt;(too many!) which then narrowed down to 5 and then finally 2. &lt;br&gt;
One from CERN-HSF and another from OpenAstronomy for a framework called Stingray. I did not qualify the evaluations for the topic at CERN-HSF(tough luck).&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*UjeIIWLdcqMjsRnoi64EYw.png"&gt;&lt;figcaption&gt;OpenAstronomy and Stingray&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Time passed in a blink, and lo and behold it was the 5th of March, 2020. I had barely made any real progress on the Stingray topic. I was constantly juggling my college work, tests and the GSoC project to no avail. Remember, I had mentioned above that COVID-19 turned out to be a boon in disguise for me? here’s why. &lt;br&gt;
My college was shut by the 12th of March, 2020 due to the fear of COVID-19. The last day of the proposal submission was on the 31st of March, 2020. This meant I had 19 whole days(with continuous college work and lectures 🤦‍♂️) to work on the project and submit my proposal for the topic “&lt;em&gt;A lightning-fast stingray: Parallelizing stingray operations to analyze larger-than-memory datasets”.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;The task seemed to be daunting but finally after a lot of coffee, monster energy drinks, sleepless nights and an amazing amount of help and support from my mentor &lt;a href="http://www.matteobachetti.it/about"&gt;Mr Matteo Bachetti&lt;/a&gt;(I was stupefied and scared to approach Mr Bachetti initially after reading his credentials, but Matteo you’re an amazing person!! I look up to you) I finally submitted my &lt;a href="https://docs.google.com/document/d/1NGL3jqTCHcQyaWwjmU-zCG5qenZsQGSqlnzNB6UcjpE/edit?usp=sharing"&gt;proposal&lt;/a&gt; on the 28th of March, 2020(phew!). Now came the hardest phase, &lt;strong&gt;&lt;em&gt;waiting for the results&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="Chances to get into GSoC’2020. The odds were stacked against me." src="https://cdn-images-1.medium.com/max/1024/1*cJkVm-zJ7_hgi_MJfle8-A.jpeg"&gt;&lt;figcaption&gt;The acceptance rate for GSoC in 2020 was 2.398%&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;37 days, 11 hours, 30 minutes &lt;/strong&gt;later(approx.) at 11:30 pm on the 4th of May, 2020… the Google Summer of Code website &lt;strong&gt;crashed&lt;/strong&gt;🙄. &lt;br&gt;
It was11:33 pm(believe me, every second passes like an eternity) and I hadn’t received an email and the website was still not active. After &lt;em&gt;60 eternities&lt;/em&gt; the website finally loaded. I carefully typed in my email id and password and as I &lt;strong&gt;clicked enter&lt;/strong&gt;(cue the palpitations, dry mouth, fidgety fingers and the tick-tock of an old clock) &lt;strong&gt;Hallelujah!!&lt;/strong&gt; a dashboard with my topic and my name opened. I was overjoyed, ecstatic, elated, thrilled, jubilant, on the seventh heaven; in short, all the synonyms of the word ‘&lt;em&gt;happiness’&lt;/em&gt; couldn’t describe the emotions racing through me at that moment. &lt;strong&gt;I had just got into Google Summer of Code 2020!! &lt;/strong&gt;I was one of &lt;strong&gt;1199 students&lt;/strong&gt; from the 50,000+ who had registered for the program!!!&lt;/p&gt;
&lt;p&gt;This was my first blog for my GSoC series. I will be posting weekly blogs. Please comment and leave a clap if you liked the article. Feel free to reach out to me on &lt;a href="https://www.linkedin.com/in/theand9/"&gt;Linkedin&lt;/a&gt;. Thank you soo much for giving it a read, have an amazing day!! &lt;strong&gt;You are awesome!!!&lt;/strong&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=c8a7bf0f529d" width="1" height="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200524_2332_theand9/</guid><pubDate>Sun, 24 May 2020 22:32:49 GMT</pubDate></item><item><title>Tryst with Astronomy and Space Science</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200521_0452_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;h4&gt;Tryst with Astronomy and Computer science&lt;/h4&gt;&lt;p&gt;When I was very young, my dad used to tell me stories of how people can float in space because of zero gravity, how brave Indian astronauts like Kalpana Chawla gave their life for the pursuit of space science and that the stars we see in the night sky are several light-years away!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/550/1*eVw2qOKIvYB8HmYgW1-Q2A.png"&gt;&lt;figcaption&gt;My dad telling me stories&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Many a time I would lay down on our open terrace and stare at the never-ending sky filled with millions of stars and just ruminate on the fact that we are living in such a vast universe!&lt;/p&gt;
&lt;p&gt;Then came high school and while randomly browsing the internet I came across a few articles written by Al Globus who happened to be one of the Board of Directors of The National Space Society.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;In the articles, he talked about how humans can live in outer space and how humans will someday become a multi-planet and multi-orbital species.&lt;/p&gt;
&lt;p&gt;I instantly was captivated by the idea of living in space and I spent that year of high school designing a space settlement that could sustain the life of 10,000 residents. I even wrote C++ programs that could help calculate the amount of oxygen, food, water, the surface area, and the radius of the torus needed to sustain a given amount of population.&lt;br&gt;
Eventually, I sent my design to the NASA AMES SPACE SETTLEMENT CONTEST 2015, and our team got an honorable mention!&lt;/p&gt;
&lt;p&gt;The next year, I got an amazing opportunity to work on a collaborative project funded by the US Department of State!&lt;br&gt;
In that project, our team from &lt;a href="https://ncsm.gov.in/"&gt;NCSM India&lt;/a&gt;, and another team from &lt;a href="https://chabotspace.org/"&gt;Chabot Space Science Center, California&lt;/a&gt; worked on designing “space-spin off” technologies that could be used to control pollution levels on earth.&lt;br&gt;
It was really fun and a great learning experience for me and it taught me a lot about collaboration, teamwork, and about how much space science affects our day to day life! &lt;br&gt;
Our project was even featured in many media channels!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/871/1*15BFL6H9M7WQrWudL7TXtA.png"&gt;&lt;figcaption&gt;India + US team meeting near UC Berkeley.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="I am with the green Shirt" src="https://cdn-images-1.medium.com/max/543/1*FQaKhO0brsxCm66MNXiVHg.png"&gt;&lt;figcaption&gt;Getting featured in Times Of India&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;After this, I went to college! My college was nothing less than a roller coaster ride!&lt;/p&gt;
&lt;p&gt;So, I dedicated most of my time learning to code, doing internships, traveling to as many hackathons and tech events as possible, and having a good social life!&lt;br&gt;
I worked for some really cool tech startups like&lt;a href="https://pratilipi.com/"&gt; Pratilipi.com&lt;/a&gt; (one of India’s largest vernacular self-publishing platforms), &lt;a href="https://www.upgrad.com/"&gt;upGrad.com&lt;/a&gt; (Linkedin’s top 20 startups 2019–2020) and even went to &lt;a href="https://imaginecup.microsoft.com/en-us/Events?id=0"&gt;Microsoft Imagine Cup’s National Finals&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;And one of the coolest things that happened in my final year of engineering is that I got into Google Summer Of Code 2020 with &lt;/em&gt;&lt;/strong&gt;&lt;a href="https://openastronomy.org/"&gt;&lt;strong&gt;&lt;em&gt;OpenAstronomy.org&lt;/em&gt;&lt;/strong&gt;&lt;/a&gt;&lt;strong&gt;&lt;em&gt;!&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Inside the OpenAstronomy Organization, I would be working with the &lt;a href="https://dirac.astro.washington.edu/"&gt;DIRAC or &lt;em&gt;Data Intensive Research in Astrophysics and Cosmology&lt;/em&gt;&lt;/a&gt; at the University of Washington.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WAn4V8DHfxMOJSQBLZF-Dg.png"&gt;&lt;figcaption&gt;My Mentors from DIRAC: TOP LEFT: Steven TOP RIGHT: Me (Biswarup) BOTTOM: Professor Mario&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I had multiple team meetings over zoom and I am totally fascinated by the people behind &lt;a href="https://dirac.astro.washington.edu/"&gt;DIRAC&lt;/a&gt;. They are a very experienced and passionate team of astronomers, engineers, and researchers and I feel really lucky to be part of such an amazing group!&lt;/p&gt;
&lt;p&gt;The projects that they work on include building tools and software for analyzing very large data sets (in terabytes and petabytes) coming from &lt;a href="https://www.lsst.org/"&gt;The Large Synoptic Survey Telescope&lt;/a&gt; or the LSST and from the &lt;a href="https://www.ztf.caltech.edu/"&gt;Zwicky Transient Facility (ZTF)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The project that I will be working on is a very interesting one and it revolves around building a user interface/dashboard that would allow astronomers/space scientists to easily create and manage Apache Pyspark from their Jupyter Notebooks. With the dashboard, the astronomers would no longer have to write multiple lines of code to launch and manage a pyspark cluster, and instead, they can achieve that by a very user-friendly drag and drop interface!&lt;/p&gt;
&lt;p&gt;In the next 3 months, I will be working with my GSoC mentors &lt;a href="https://depts.washington.edu/astron/profile/stetzler-steven/"&gt;Steven&lt;/a&gt; and &lt;a href="https://dirac.astro.washington.edu/team_member/mario-juric/"&gt;Professor Mario Juric&lt;/a&gt; and the other teammates at DIRAC’s Data Engineering Group, and I am very much excited for the same!&lt;/p&gt;
&lt;p&gt;Linkedin: &lt;a href="https://www.linkedin.com/in/techguybiswa/"&gt;https://www.linkedin.com/in/techguybiswa/&lt;/a&gt;&lt;br&gt;
Mail-Id: bis.banerjee.bb@gamil.com&lt;/p&gt;
&lt;p&gt;Thanks &lt;a href="https://medium.com/u/ffd8efb5df45"&gt;gishtah&lt;/a&gt; for helping me to edit my post!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b8df974cb159" width="1" height="1"&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://blog.usejournal.com/tryst-with-astronomy-and-space-science-b8df974cb159"&gt;Tryst with Astronomy and Space Science&lt;/a&gt; was originally published in &lt;a href="https://blog.usejournal.com"&gt;Noteworthy - The Journal Blog&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200521_0452_techguybiswa/</guid><pubDate>Thu, 21 May 2020 03:52:58 GMT</pubDate></item></channel></rss>