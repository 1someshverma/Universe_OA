<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about gsoc2020)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/cat_gsoc2020.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Wed, 08 Jul 2020 01:36:57 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>GSoC 2020: Blog 2 - Parameters and incompatible units</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/</link><dc:creator>Jyotirmaya Shivottam</dc:creator><description>&lt;div&gt;&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#progress-so-far" class="anchor"&gt;
&lt;/a&gt;
&lt;!-- TEASER_END --&gt;
Progress so far...
&lt;/h3&gt;

&lt;p&gt;Over the last two weeks, PR &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/512"&gt;#512&lt;/a&gt; was finalized and merged into EinsteinPy. With it, the big refactor of the &lt;code&gt;metric&lt;/code&gt; module is over. As I had mentioned in my last blog, this PR adds a core structure to the &lt;code&gt;metric&lt;/code&gt; module, with the &lt;code&gt;metric.BaseMetric&lt;/code&gt; class, and adds some new functionalities, like support for Kerr-Schild Perturbations. Also, 7 issues, big and small, were fixed in this PR, ranging from purely semantic issues to mathematical inaccuracies. One of the important ones was Issue &lt;a href="https://github.com/einsteinpy/einsteinpy/issues/514"&gt;#514&lt;/a&gt;, the distinction between Rotational Length Parameter,

&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and Dimensionless Spin Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, which has had a cascade effect across the codebase. It is worth a discussion, as it has led to many changes across the numerical side of EinsteinPy.&lt;/p&gt;




&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#whats-all-the-fuss-about" class="anchor"&gt;
&lt;/a&gt;
What's all the fuss about?
&lt;/h3&gt;

&lt;p&gt;The expressions for the Rotational Length Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, and Spin Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, are as follows:&lt;br&gt;

&lt;/p&gt;
&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=JMc
\alpha = \frac{J}{Mc}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;

&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;a=JJMax=JcGM2
a = \frac{J}{J_{Max}} = \frac{Jc}{GM^2}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;a&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;
which give us:&lt;br&gt;

&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=GMc2a
\boxed{
\alpha = \frac{GM}{c^2}a
}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="boxpad"&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="stretchy fbox"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;
Here,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;J,MJ, M &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
denote the angular momentum and mass of the gravitating body (for example, black holes), respectively, while
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;G,cG, c &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
denote the Gravitational Constant and speed of light in vacuum, respectively. As the expression for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
tells us, it is a constraint on the body's angular momentum. It might seem arbitrary at first, as in classical physics, we do not bother with such constraints and
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;JJ &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
is not limited. However, in General Relativity, especially in the context of how black holes are formed, or more appropriately, how we hypothesize their formation, we find that, for certain solutions to the Einstein Field Equations, like the Kerr solutions (rotating black hole), a maximum limit needs to be placed on the black hole angular momentum. This is a direct consequence of the efforts to contain the causality-breaking nature of black hole singularities, especially a naked singularity. As the name suggests, naked singularities are not covered by an Event Horizon and so, they would be observable from outside the black hole. This breaks the framework of GR, as no deterministic predictions about the future evolution of spacetime can be made near a singularity. Note that, GR breaks for covered singularities as well, but causality remains intact, because the spacetime within the event horizon is not viewable or approachable from outside. To complicate things further, GR, as is, does not preclude the existence of naked singularities. All of this led to much deliberation on this issue and ultimately, in 1969, Sir Roger Penrose postulated the (Weak) Cosmic Censorship Hypothesis. This hypothesis aims to alleviate the issue with physical singularities by claiming that naked or observable singularities cannot exist in the universe, as the deterministic nature of general relativity will fall apart otherwise. It is worth mentioning that, while this is still a conjecture, we are yet to detect naked singularities through astronomical observations. Also, in order to work in the theoretical framework of GR and make physical predictions using GR, one needs to circumvent the problem of naked singularities and this is where
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
comes in for rotating black holes, like in the Kerr solution. To ensure that, the black hole singularity has an event horizon, we must constrain
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;JJ &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and this is done by the spin parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. Here, for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;∣J∣≤GM2c|J| \leq \frac{GM^2}{c} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;≤&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;G&lt;/span&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size3 size1 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, the solution has an event horizon, while for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;∣J∣&amp;gt;GM2c|J| &amp;gt; \frac{GM^2}{c} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;G&lt;/span&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size3 size1 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, the solution possesses naked singularities, which we must exclude, due to reasons discussed above. This condition is obtained by solving for singularities in the Kerr solutions.

&lt;p&gt;As for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, it is a convenient length parameter, that helps in making equations shorter to write.&lt;/p&gt;

&lt;p&gt;Physics aside, the issue, as mentioned in &lt;a href="https://github.com/einsteinpy/einsteinpy/issues/514"&gt;#514&lt;/a&gt;, was that the modules in EinsteinPy do not differentiate between
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. This is due to the intermixing of Geometrized quantities with that in SI units. In geometrized units,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;G=c=1G = c = 1 &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, making
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=a=JM\alpha = a = \frac{J}{M} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. However, in SI, this is not the case. EinsteinPy works purely in SI and this issue is an artifact from the changes around unit conversions. This issue has been fixed now, after &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/512"&gt;#512&lt;/a&gt;, with
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
being one of the defining parameters in rotating spacetimes, while
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
is calculated using
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
.&lt;/p&gt;

&lt;p&gt;As I mentioned earlier, this issue has caused a ripple effect across the numerical side of EinsteinPy. It has highlighted some problems, around systems of unit, in the definition of a few core methods in the &lt;code&gt;metric&lt;/code&gt; classes, as well as the &lt;code&gt;coordinates&lt;/code&gt; module.&lt;/p&gt;

&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#until-next-time" class="anchor"&gt;
&lt;/a&gt;
Until next time...
&lt;/h3&gt;

&lt;p&gt;I am currently working on fixing the aforementioned issues, as well as refactoring the &lt;code&gt;coordinates&lt;/code&gt; module. To be specific, I am working on adding support for 4-Vector calculations and Kerr-Schild coordinates to the &lt;code&gt;coordinates&lt;/code&gt; module. The latter would make use of the Kerr-Schild perturbation functionality of the &lt;code&gt;metric&lt;/code&gt; module and help in modularizing the definition of new metric classes. I will discuss Kerr-Schild perturbations and the so-called Kerr-Schild form of the metric tensor in my next blog. &lt;/p&gt;




&lt;p&gt;In the meantime, here's a piece of trivia, related to the Cosmic Censorship Hypothesis.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In 1991, John Preskill and Kip Thorne bet against Stephen Hawking that the hypothesis was false. Hawking conceded the bet in 1997, due to the discovery of some special situations, that violated the hypothesis, which he characterized as "technicalities". Hawking later reformulated the bet to exclude those technicalities. The revised bet is still open, with the prize being "clothing to cover the winner's nakedness".&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The description of the original bet can be found &lt;a href="http://www.theory.caltech.edu/people/preskill/old_naked_bet.html"&gt;here&lt;/a&gt;, while that of the new bet can be found &lt;a href="http://www.theory.caltech.edu/people/preskill/new_naked_bet.html"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>EinsteinPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/</guid><pubDate>Tue, 30 Jun 2020 08:54:19 GMT</pubDate></item><item><title>Google Summer of Code - Blog #2!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hello! This blog marks the end of the first phase of Google Summer of Code. The journey so far has been challenging but also extremely rewarding. The knowledge gained as a by-product of the work I’ve been doing on my project so far is unbelievable, but more importantly has been a better, more pleasant experience compared to the traditional system of gaining knowledge by reading books and tutorials. In this blog, I will be summarising the work that I’ve been doing for the past 2 weeks, update the readers on my current position and give an idea of what lies ahead.&lt;/p&gt;

&lt;p&gt;As I discussed in my previous blog, the work for the first two weeks mostly involved using Cython to translate the host code into something which could be compiled to provide better performance. More importantly, apart from the Cython part, I had to also start working on porting the kernels from their pure CUDA C form into something which Python/Cython could also understand. While the actual work to do so did not take long or came across as very challenging, the most difficult part in the whole process, undeniably, was to get the two, Cython and CuPy to talk to one another.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;When I finished writing the previous blog, I was still left with quite a large volume of host code which was waiting to be converted to the Cython equivalent. Going through the previous blog, I’d like to make one correction in the part where I said I found Cython quite confusing. Infact, calling it a correction would not be correct. Instead, I should say that Cython isn’t actually all that difficult as I might have made it look like in the last blog. After a fair amount of reading and writing code in Cython, I think the developers of Cython have actually done an excellent job. After the initial barrier is crossed (and it happens fairly naturally), writing Cython code feels just as normal and second nature as pure Python code. Infact, I’d go so far as to claim that Cython feels more natural to me now than Python itself because of my previous experience in C++. This newly found familiarity allowed me to proceed quite quickly with this part of the project. The only problems that I encountered were: (1) the inter-conversion between arrays/vectors and pointers that we are used to in C++ is not possible in case of Cython, and this resulted in me being forced to make some slight changes in the host code, and (2) using structs in Cython isn’t as direct and straighforward as in C/C++. The reason behind this is the fact that Cython tries to estabilish relationships between C-type data structures and Python objects. While this is quite trivial for objects of types int, float, char, and even arrays to some extent, in case of structs this is nowhere near as easy. While I am sure there must have been some hacky way around this problem too, me and my mentors decided it is not something worth wasting time on, and thus we decided to bypass all structs and directly used each of their attributes as variables with the struct name attached as prefix, so &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.shared_size&lt;/code&gt; became &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h_shared_size&lt;/code&gt;. While not the exact same thing, it allowed us to achieve the same objective without a lot of modifications to the code, either in terms of declaration or syntax. The only downside to this whole approach was that it made the code quite verbose, as instead of passing a single struct with 10 fields inside it, we were forced to pass 10 variables for each struct. This unique problem was further aggravated as we were using global variables instead of passing them around as arguments, and as every Python user would know, this meant adding the line &lt;code class="language-plaintext highlighter-rouge"&gt;global &amp;lt;varname&amp;gt;&lt;/code&gt; before every function body, which when done for every method and every variable, meant a lot of lines which could have been avoided. Apart from these two major issues and couple of minor problems here and there, the whole process was fairly straight forward. At the end of this step, I was left with a Cython file which compiled just fine, but didn’t really accomplish much. The key ingredient that was missing, was the very the heart of the project: the kernels.&lt;/p&gt;

&lt;p&gt;Kernel is actually nothing but a fancy word for the part of the code which actually executes on the GPU. Given the project title, it’d be fairly obvious that in our project, the kernels are actually where the magic happens. While this is not meant to discount the importance of the host (or the CPU code), the kernels are ulimately the part of the program which are responsible for the performance boosts that we observe. Kernels, atleast those which are meant to be executed on Nvidia’s GPUs, are usually written in a language known as CUDA C. This is a special language that is written on top of the original C language, but with extra set of features, classes and methods which provide us an abstracted interface to control various aspects of the program and the way it is implemented on the GPU, more so than a conventional serial algorithm meant to be implemented on the GPU. While using CUDA C is quite straightforward, especially with the large community support and well-written documentation, we unfortunately could not make use of that as we wanted something that was written and compatible with Python and things written on top of Python. Thus, after a lot of deliberation and discussion, my mentors and I agreed to use something known as CuPy to handle the CUDA C part of our code.  CuPy is an incredibly well-written module with neat documentation and decent community support, which made things a lot simple for us. However, more than anything, the biggest advantage of using CuPy was its RawModule method. The idea behind RawModule was to allow users who already have a CUDA C file written to do some specific task (us!) could simply re-use their code and get away with the whole problem of running kernels in Python very, very easily. Let me demonstrate it using an example and that would perhaps make things even more clear:&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;
&lt;span class="n"&gt;loaded_from_source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r'''
extern "C"{
...
__global__ void test_sum(const float* x1, const float* x2, float* y, \
unsigned int N)
{
unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;
if (tid &amp;lt; N)
{
y[tid] = x1[tid] + x2[tid];
}
}
}'''&lt;/span&gt;

&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RawModule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loaded_from_source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'test_sum'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# y = x1 + x2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the code looks fairly self-explanatory, I’ll give a quick runthrough anyway. The idea behind CuPy’s RawModule method, true to it’s name, is to allow the raw CUDA source to work with Python, which in our case is the string named &lt;code class="language-plaintext highlighter-rouge"&gt;loaded_from_source&lt;/code&gt;. Using RawModule, we process the string as a CUDA C source file, extract the relevant kernels from the file, &lt;code class="language-plaintext highlighter-rouge"&gt;test_sum&lt;/code&gt; in our case, and we’re done! The function is stored as &lt;code class="language-plaintext highlighter-rouge"&gt;ker_sum&lt;/code&gt; in Python, and is ready for use just like any other Python method. In order to keep the look and feel of the module as close to the original CUDA C source codes, even the way kernels are called is quite similar to how they’re called in C. The first two parameters, are the grid and block dimensions, and finally we follow through with the actual parameters to the kernel. Clearly, this allowed us to fast-track a lot of the kernel porting work, and quickly develop a Python version of our original proof-of-concept code.
However, like everything else, even this wasn’t going to work as easily as we’d initially expected. Instead, I faced a new challenge, which was the use of a struct written in the CUDA library, used for fast fourier trasforms, known as &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt;. Like I explained in the previous paragraph, this problem was quite similar in nature to the whole Python object to C object transformation and vice versa. If anything, this probably felt more explicit in nature since we could clearly see the actual C code written (as the RawModule’s string). The problem was that the structs are very specific to their definition, and it is simply not possible to pass anything to the RawModule and expect it to process it as a struct. Even though a numpy array of datatype complex64 might be storing the exact same data as an array of &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt;, the two cannnot be interconverted like vectors of integers and other primitive types can be. This again posed a challenge as it would mean a deviation from the original code. Finally, after reading a lot of stackoverflow and still not being satisfied with any of the answers, I let my mentors help me out with the code. The final solution that came out did a couple of things: first we got rid of the &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt; structs, and instead introduced the other, C datatype, serving the same purpose, a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt;. This amazing datatype did the exact same thing, except we could pass a numpy (or cupy) array of type complex64 and it would automatically read it as a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt; array! It quite literally solved the whole problem in an instant, and the only modifications we had to make were change how the real and imaginary parts of the complex numbers were being handled. While the struct definition required us to handle both separately, the new format made things even simpler by letting us perform calculations on both the real and imaginary parts simultaneously (basically how you’d expect to work with a complex number anyway!). With this, and again a few minor changes here and there to ensure the data transfer between Cython and CuPy wasn’t throwing errors, I was done! However, by now I had a Cython file with 1300+ lines with a &lt;em&gt;lot&lt;/em&gt; of room for bugs and unexpected errors and behavior.&lt;/p&gt;

&lt;p&gt;This brings us to the current time. The current objective for me is to get the file to work properly and produce the right about, so basically debugging. However, unlike smaller programs and files which are debugged with usually a single method in focus, I have to constantly let the whole chain of methods to execute even if I know that the bug is in some specific method, simply because its impossible to recreate the testing environment otherwise. For instance, I have been debugging the code since yesterday, and except one time where I got a segmentation fault, every time the program crashes, I am being forced to restart my computer just to start the debugging process again. Reason you ask? The program is working on a small subset of an already trimmed dataset, occupying around 3 GB of space. However, whenever I execute the program and try to run it, it is loading all that data first in the RAM (which slows the computer to a crawl almost instantly due to the limited 8GB RAM), and subsequently to the GPU (where it takes up 3/4 GB VRAM present). On force closing the program, while the RAM does free up after some time to a state where I can start using the computer again, the GPU does not!! I am yet to read into the nitty-gritty of this, but from what I understood, we need to explicitly clear the VRAM occupied by CuPy using methods given in the documentation. However, when the program does not work as expected (which is currently 100 percent of the times I have run it), the program simply crashes before executing the lines which free up the memory. The result? A GPU which is loaded up and unable to free its VRAM. Resetting seems to not work for some reason, and the only option I have found so far (admittedly I havent researched well enough but its only been 24 hours since I reached this stage) which does work is restarting my computer. This, as I am sure you can already feel, is a very frustrating way to debug things, but I am happy to say that I am still making progress, albeit a little slowly than I would have liked to.&lt;/p&gt;

&lt;p&gt;That pretty much sums up everything that I have been upto for the past 2 weeks. The progress is a little on the slower side, as I expected to have the demo working &lt;em&gt;and&lt;/em&gt; producing the correct output by now, but unfortunately the code still needs debugging. Hopefully this should be over soon, and we can then move to integrating it with RADIS and making changes that should allow the user to make use of our program. After that, we would be focussing on implementing other methods of calculating spectra, and possibly also methods which support non-equilibria conditions. Hopefully I should have a lot more to tell you guys 2 weeks from now! Till then, adios! And thanks for making it this far (if you actually did so :P) Cheers.&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</guid><pubDate>Mon, 29 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Launching Version 1 of Start Spark</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GKZekrHbmzNBggdsyVxSSA.jpeg"&gt;&lt;figcaption&gt;Even my workstation is excited for the product demo!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So after 4 weeks of planning and coding and debugging, the day came when I had to launch version 1.0 of the product!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JGcxp4eCl8d7t0omgPAFIQ.png"&gt;&lt;figcaption&gt;My extension “Start Spark” deployed at the prod servers&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The extension I built is now deployed in the DiRAC Jupyter Hub and is currently getting used by the astronomy community at DiRAC!&lt;/p&gt;
&lt;p&gt;What you can do with my extension:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;ol&gt;&lt;li&gt;Create a PySpark cluster on the click of a single button. Creating a PySpark cluster would have otherwise taken writing multiple lines of cumbersome codes.&lt;/li&gt;&lt;li&gt;Get the link where you can access the PySpark web UI and see all the executors, jobs, and the environment.&lt;/li&gt;&lt;li&gt;The “spark” variable is automatically injected into the kernel and hence users can use it as they like.&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qUI3KU07owQgFF6x35_V4Q.png"&gt;&lt;figcaption&gt;Get access to the PySpark Web UI&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*shTWfgSYlHyTD-KkB7w2mw.png"&gt;&lt;figcaption&gt;“spark” variable is injected in the kernel&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;How does it work?&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/976/1*sV-BVWeI7hPzr1ZyYFGmKA.png"&gt;&lt;figcaption&gt;Workflow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Step 1: The extension gets loaded.&lt;br&gt;
Step 2: While it loads it automatically calls an API/serverextension handler /all-config and that API gives all the list of the available configs.&lt;br&gt;
Step 3: We can see that list of all available configs in the dropdown.&lt;br&gt;
Step 4: We can select any config that we want and click on “Start Spark” Button&lt;br&gt;
Step 5 : When we click Start Spark Button, the front end detects which config we have selected and then tells the serverextension about the selected config via REST API.&lt;br&gt;
Step 6: The serverextension fetches all the config details of the config that is selected in the frontend from the config dir located at home dir.&lt;br&gt;
Step 7: Then once it has the required config fetched from the config dir it converts it into a Jinja Template and sends the jinja template to the front end via API&lt;br&gt;
Step 8: Once the front end receives the Jinja template of the required config it sends the Jinja Template to the Kernel Extension via Sockets&lt;br&gt;
Step 9: The kernel extension executes the jinja template to start the spark cluster that it receives from the Jupyter front end.&lt;/p&gt;
&lt;blockquote&gt;Select Config -&amp;gt; Click the Start Spark Button -&amp;gt; Config Data fetched in backend -&amp;gt; Config data converted to Jinja Template in Backend -&amp;gt; Jinja Template Sent from backend to front end -&amp;gt; Jinja sent from front end to Kernel → Jinja template gets executed in Kernel to start the cluster!&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;Video Reference Link&lt;/strong&gt;: &lt;a href="https://slack-redir.net/link?url=https%3A%2F%2Fwww.loom.com%2Fshare%2Fdc18b670e08a47c6a96db3176f3be9ef"&gt;https://www.loom.com/share/dc18b670e08a47c6a96db3176f3be9ef&lt;/a&gt; (PS: Watch it in 1.5x speed)&lt;/p&gt;
&lt;p&gt;I am super excited to see how the astronomy community feels about it and gives their feedback.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b16c4e9516fb" width="1" height="1"&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</guid><pubDate>Mon, 29 Jun 2020 19:34:53 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 1.2</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;It has been a month since GSoC’s coding period started early in June 2020. Much has happened since then in the glue-solar project, and to sum it up I have been pretty much spending all my GSoC time working on a WCSAxes-enabled version the 1D Profile viewer for extracting 1D spectrum from data cubes using the pixel extracted in a 2D Image viewer. To be honest it has been very effort-intensive, though not necessarily time-intensive as I have previously feared. But the journey has been fun given my very supportive and friendly project mentors. To the layman and non-specialist what I have related regarding the project details probably sounds esoteric, which it is. With this realization I will split this and remaining GSoC blog posts into two halves: one pertaining to my personal struggles, and the other pertaining to the technical aspect of the work carried out thus far, in that order, so that that latter part can be conveniently skipped over (but I do encourage you to do read both sections in tandem so get a better understanding of the project :-p) Anyway, let me begin…&lt;/p&gt;
&lt;h4&gt;Part 1: Personal struggles&lt;/h4&gt;&lt;p&gt;One personal “secret” I wish to reveal is that this is my last year as a PhD Candidate in Astrophysics at the University of Hong Kong (HKU). Not only that, since my Postgraduate Scholarship officially ran out in October 2019 and no other funding options are available, I have been holding down a job as a front-end developer for some parts of the weekdays to support my PhD studies. So far I have been trying to manage my time wisely and balancing my various duties and obligations as best as possible, but it has been a genuine struggle, especially in me trying to find enough time to sleep. To make matters worse I have a tendency to drift towards writing code than writing my thesis, though I am making progress in both. So I did hesitated to apply for GSoC for a 2nd time this year and was originally against the idea. But when I saw the project ideas available I changed my mind. Glue-solar is actually like a godsend for me; the project enabled me to not only further develop my self-discipline as a person, it also allowed me to learn from experts in the field working on open-source data visualization, and to grow from the experience. I thoroughly enjoyed interacted with my mentors, who have been very patient and helpful in offering me guidance (as well as friendship) throughout. If I have any advice I am allowed to offer anyone wanting to try out open-source software development through GSoC, and if GSoC does continue in the near future, I would recommend them to try out any of the OpenAstronomy projects. This is because OpenAstronomy is one (relatively) small but vibrant community of dedicated programmers, many of which scientists, that is welcoming to newcomers coming from a diverse background. And also, simply put, ASTRONOMY IS FUN! This is especially true for SunPy. I remember I started to contribute to open-source software as a relative novice with some bookish knowledge but not a lot of real-world experience back in around January 2019. My first contributions were to SunPy and Astropy. I remember I have read an article about how to get into GSoC in 2018 to learn about the program, though was not all that keen in getting into it at first. My first motivation to contribute was to give back to the community, because I had been using Python-based astronomy packages like Astropy for my PhD research. But at the urge of a mentor active in the Astropy community, I did apply. The GSoC project I worked on last year in 2019 was &lt;a href="https://summerofcode.withgoogle.com/archive/2019/projects/6094580905148416/"&gt;IRISpy&lt;/a&gt;, and my mentors were &lt;strong&gt;Dan Ryan&lt;/strong&gt; and &lt;strong&gt;Laura Hayes&lt;/strong&gt;. They were amazing as mentors, and were instrumental in my being able to complete the project successfully in the end of the program. I still miss my time spent with them on that project. IRISpy has officially changed its name to sunraster, which I was fortunate enough to help launch earlier this year in 2020. Basically when I was working on it as a GSoC project it was to provide additional functionalities for the analysis of observations from NASA’s Interface Region Imaging Spectrograph (IRIS) satellite which looks at UV emission from the solar chromosphere in particular. Now that scope has been extended to not just IRIS data, but data collected with similar instruments. This year I am using a lot of the code I have written for the IRISpy project for the current glue-solar project, which is kind of cool. As an icing to the cake, I get to work on data cubes for glue-solar, which is one of my favorite things in this world, a passion I have gained through my PhD research into integral field spectroscopy (IFS). For the present GSoC work I even get to work on &lt;strong&gt;4D data cubes (ones with an extra &lt;em&gt;time&lt;/em&gt; dimension)&lt;/strong&gt;, which has one more dimension than the IFS cubes I am so familiar with! So far it has been another incredible GSoC experience for me. All in all I have a feeling it will be a good one, and also a fruitful one.&lt;/p&gt;
&lt;h4&gt;Part 2: Technical aspect of progress made in glue-solar&lt;/h4&gt;&lt;p&gt;So we (me and my mentors) have ventured away from focusing on glue-solar and have entered the glue “proper” territory as we put more time and effort towards modifying the 1D Profile viewer. By this I mean we have begun work on glue instead of glue-solar as was the case as described in &lt;a href="https://medium.com/@krisastern/gsoc-2020-glue-solar-project-1-1-c2151e535e0c"&gt;my previous article&lt;/a&gt; where we have built a “SunPy Map” viewer. So I am well on my way to complete the task “modifying the existing glue 1D Profile viewer to provide sliders for extra dimensions (currently collapses)” soon, which is a significant part of the glue-solar project. Personally, I am really looking forward to working on the “adding support for pre-computed statistics in datasets / viewers” task, which I will surely make time to complete before end of August.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Let me demonstrate how far we have come with the modification of the 1D Profile viewer. So ordinarily it is hard to get 4D data cubes with a time dimension. This can be fixed by stacking sequential (IRIS) raster scans/cubes. After firing up glue from the terminal by the magic command “glue”, and importing some if not all raster scans from the same observation using the IRIS OBS directory importer, and choosing to “Stack the sequential raster scans” , we see some data points appearing in the Data field of the GUI. This is illustrated by the sequence of images to follow:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5te3r5u7q5pxeWhiBv4x9Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Loading an multi-scan IRIS Observation and choosing to stack the sequential raster scans / cubes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DvJ0gwjAKMjdGefNeggEpA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; Stacked datasets which are essentially 4D data cubes appear in the Data field of the glue-solar GUI.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*c1fcKBkCGbcibrc2nfU93w.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt; As per usual, choosing the 2D Viewer option will enable us to inspect the different sides of the N-dimensional or ND data cube.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*A_dQDmastlGwmif17b7J2Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 4.&lt;/strong&gt; Choosing the right (N-1) slices for the slicing to obtain the 1D profile (which I have learned in a hard way is not always the same as a 1D spectrum coding-wise) using some pre-defined logic that warrants some explanation, though should be intuitive to some.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Qq70FXHsyObzBniXG35BOQ.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 5.&lt;/strong&gt; Using the 1D Profile tool, as opposed to the red 1D spectrum button in the 2D Image viewer, to generate the desired profile, which may or may not be a 1D spectrum.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FuXVHmy-MOFS-ELa6gFSUw.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 6.&lt;/strong&gt; Plotting of the uncollapsed version of the 1D profile by choosing the newly added “Slice” function which does nothing statistical to the data like the other functions such as “Maximum”, “Median”, and “Sum” that can be chosen as alternatives. (The default is “Maximum”).&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As we can see in Figure 6, all 4 dimensions are represented in the 1D Profile viewer either as the x-axis or as a slider quantity. In this example, the x-axis is indeed wavelength (which yields a 1D spectrum by definition), the other dimensions are time, longitude (HPLN), and latitude (HPLT). Even though for now the sliders are still not yet functional and will need some tender loving care to make them work in tandem with the reference data as inherited or passed from the 2D Image viewer, which may take a few more days to complete, I believe this is truly a milestone in this GSoC project. If we can control the sliders to change the coordinate values, that would be a very useful tool in data exploration. I will spare the perhaps rather dry details regarding the reasoning through the whole thinking process that leads to this check point. However, I would like to explain the logic used in the slicing. What I have done is to introduced a SlicedData class, much like the existing IndexedData class that is used for pixel extraction with a tool my mentor &lt;strong&gt;Stuart Mumford&lt;/strong&gt; originally wrote for glue-solar (currently in a draft PR to be upstreamed to glue). First to pick a spatial coordinate, we choose in the 2D Image viewer the spatial axes for the image axes, selecting a point in the image shown on screen with the pixel selection tool, and then tweak the slider we would like its corresponding axis to be used as the x-axis in the 1D Profile viewer. Then we drag the same dataset to the viewing area and view using the 1D Profile viewer, in order to generate a profile for the slicing we have chosen. So this has been the work completed thus far. What is yet to be completed is to enable the manipulating of the 4D or higher dimensional data cube using the sliders for the same x-axis. So in the end regardless of the starting point, we could potentially use the 1D profile viewer to inspect the 4D or ND data cube in ways previously impossible before, at least to me.&lt;/p&gt;
&lt;p&gt;Again, I would like to thank my mentors for their guidance and support which enabled the progress I have made to happen. Much work will need to be done in order for the PRs to be polished up and merged later on in the summer. I really enjoy my glue-solar work for GSoC this summer. I hope you enjoyed reading this article as much as I had fun writing it too!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=65ef40ba2b71" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</guid><pubDate>Mon, 29 Jun 2020 18:11:30 GMT</pubDate></item><item><title>GSoC 2020: Generalization of Clients</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/0*EsjuLxEt1BrtrdCG"&gt;&lt;figcaption&gt;Solar Eclipse 2020 in Vadodara, Gujarat (Lucky Enough to witness it this year!)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This fortnight, I worked around iterating over different designs for redesigning the Dataretriever Clients so that its implementation can be simpler and more general. Generalization here means the ability to inherit most of the methods from the base class itself; therefore minimizing a number of similar methods in the subclasses.&lt;/p&gt;
&lt;h5&gt;Show Method for QueryResponse&lt;/h5&gt;&lt;p&gt;I got&lt;a href="https://github.com/sunpy/sunpy/pull/4309"&gt; PR #4309&lt;/a&gt; merged which solved an old &lt;a href="https://github.com/sunpy/sunpy/issues/556"&gt;Issue #556&lt;/a&gt;. A simple show() function in ~sunpy.net.base_client.BaseQueryResponse enabled QueryResponse objects for Dataretriever, VSO, and JSOC clients to specify the columns to be shown in the result.&lt;/p&gt;
&lt;p&gt;This returns an ~astropy.table.Table instance, so table operations can also be easily performed on the result.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href"&gt;https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;_extract_files_meta method in Scraper&lt;/h5&gt;&lt;p&gt;&lt;a href="https://github.com/sunpy/sunpy/pull/4313"&gt;PR #4313&lt;/a&gt; was merged in sunpy:master that allows the scraper to extract the metadata stored in the file URLs. This function will prove very useful for refactoring the whole ~sunpy.net.dataretriever submodule.&lt;/p&gt;
&lt;p&gt;A new module parse was added in ~sunpy.extern which allowed to specify the extractor which will parse the file URL and return a dict containing the value of attrs like Wavelength, Time, Level, etc. Even the URL is returned by the method, which ensures no changes are to be made in fetch() methods for clients.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/da15de642196febf9eab940219efac0f/href"&gt;https://medium.com/media/da15de642196febf9eab940219efac0f/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;Playing with post filters&lt;/h5&gt;&lt;p&gt;Last fortnight I was working with post filters and concatenation of responses for VSO. Last week I dabbled a bit with post-filters for attrs used in all net clients. Using single_dispatch decorator over filter_results enabled post-filtering in dataretriver and VSO. It is pretty similar to the way it is done for ~sunpy.net.vso.attrs.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/274b4e0b885d17b391589d15c593f046/href"&gt;https://medium.com/media/274b4e0b885d17b391589d15c593f046/href&lt;/a&gt;&lt;/iframe&gt;&lt;h4&gt;Redesigning GenericClient&lt;/h4&gt;&lt;p&gt;So there is a draft &lt;a href="https://github.com/sunpy/sunpy/pull/4321"&gt;PR #4321&lt;/a&gt; where work is in progress for the new implementation for the generalization. QueryResponeBlock is removed from the client.py since by few changes in the QueryResponse enables us to do it all using a dictionary. Similarly &lt;a href="https://github.com/sunpy/sunpy/pull/4321/files"&gt;a lot of methods were removed or changed&lt;/a&gt; under the aim to simplify the two Generic Classes.&lt;/p&gt;
&lt;p&gt;Not only the base class, even the client class were made simple. For simple clients, we are supposed to only define required attrs, optional attrs, a baseurl, and an extractor which makes the search working.&lt;/p&gt;
&lt;p&gt;After this refactoring, the example dataretriever source client class would look something like this:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href"&gt;https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Only a class method and few class attributes are sufficient for defining a simple DR client!&lt;/p&gt;
&lt;h5&gt;Hooks for translating attrs&lt;/h5&gt;&lt;p&gt;There are some clients which deviate from generalization. For those clients, it was discussed in a meeting with mentors that post-hooks and pre-hooks for scraper are to be designed which shall perform a translation of attrs provided in the search to their representation in the url. While working around it, I discovered few bugs in fermi_gbm and other clients to be addressed in scraper hooks. Responses for Detector numbers 10 and 11 were never returned because in the url they were represented by na and nb respectively. They will be fixed by translators as a part of pre-hook before passing it to the scraper.&lt;/p&gt;
&lt;h5&gt;Moving Rhessi out from Generic&lt;/h5&gt;&lt;p&gt;Since rhessi didn’t follow the Generalization as the metadata can’t just be extracted from the file URL, so it is being implemented as subclass of base_client.&lt;/p&gt;
&lt;p&gt;Every week we move closer and closer to Generalization :). Enjoying the meetings where I and my mentors discuss the pros and cons of different designs of GenericClient!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=1879f5dfe436" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</guid><pubDate>Mon, 29 Jun 2020 17:13:52 GMT</pubDate></item><item><title>gsoc_journey.update({“Chapter 1”: [“Community Bonding Phase”, “Stingray”]})</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_0011_theand9/</link><dc:creator>Amogh Desai</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*WHlJZxJwoGsHr2RSafxoRQ.jpeg"&gt;&lt;figcaption&gt;&lt;strong&gt;“Across the sea of space, the stars are other suns.” &lt;/strong&gt;~ Carl Sagan&lt;/figcaption&gt;&lt;/figure&gt;&lt;iframe src="https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Feb1A4KmVJME%3Ffeature%3Doembed&amp;amp;display_name=YouTube&amp;amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Deb1A4KmVJME&amp;amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Feb1A4KmVJME%2Fhqdefault.jpg&amp;amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;amp;type=text%2Fhtml&amp;amp;schema=youtube" width="640" height="480" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/09696909e30878c50221a3fd74dca870/href"&gt;https://medium.com/media/09696909e30878c50221a3fd74dca870/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Firstly, I would like to apologize for not posting a blog for more than a month.&lt;/p&gt;
&lt;p&gt;Secondly, I would again like to apologize as this blog is going to be astronomically jargon-heavy(pun intended). &lt;br&gt;
Now before you decide to just watch the funny Joey video and go watch more Friends episodes; trust me after reading this 7 minute blog you will gain serious bragging rights. After which you can binge Friends to your heart’s content(I already got my popcorn bowl with me 😉).&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Community Bonding Phase and APE — 17&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/925/1*r3LeWqbDsz2bz-NfL3zadA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;“Community is about doing something that makes belonging matter”&lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Community, as defined by the Cambridge Dictionary is the “people living in one particular area or people who are considered as a unit because of their common interests, social group, or nationality.”&lt;/p&gt;
&lt;p&gt;Akin to the communities in the real world, the Open-Source Software community is one of the most diverse and active communities in the world. All Open-Source projects from the Linux Kernel to a niche, newly conceptualized project have several contributors keeping the project alive. &lt;br&gt;
The best part about this online community is that any individual willing to contribute to the project is welcomed irrespective of their caste, creed, gender, race, nationality, level of expertise. &lt;br&gt;
To be a part of a community of zealous, like-minded individuals working towards making the world a better place with software, makes you feel somewhat like a superhero😁.&lt;/p&gt;
&lt;blockquote&gt;&lt;strong&gt;The power of Open-Source is the power of the people &lt;/strong&gt;~ Philippe Kahn&lt;/blockquote&gt;&lt;p&gt;The community bonding phase is probably the most important part of the whole program. A month is given to students to get acquainted with the project community and mentors. Students are expected to get familiarized with the &lt;em&gt;Code of Conduct&lt;/em&gt; and other guidelines such as Contributing, Coding, Testing guidelines.&lt;br&gt;
This is an amazing opportunity to not only plan and research more about one’s project but also interact with other students of the same/different organization’s and learn more about their projects.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*rzgbbfXrjVV2jcr08x8MUg.png"&gt;&lt;figcaption&gt;First Contact. The most exhilarating~2700 seconds of my life&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;I had two calls with my mentor Mr Matteo Bachetti during the community bonding phase. Lucky me, I got a one-to-one introduction to X-Ray Astronomy(with an amazing presentation) from Mr Bachetti himself!!&lt;br&gt;
We discussed the goals, specifics as well as a rough trajectory of the project.&lt;/p&gt;
&lt;p&gt;The community bonding phase gave me an amazing opportunity to not only associate with my peers from OpenAstronomy but also other organizations. I was particularly interested in a few projects from CERN-HSF as well as other projects from various sub-organizations in OpenAstronomy. &lt;br&gt;
Thank you so much, Siddharth Lal, Biswarup Banerjee, Raahul Singh, Kris Stern, Abhijeet Manhas and Sahil Yadav, Honey Gupta, Prateek Kumar Agnihotri and Pranath Reddy for answering my persistent and often novice-level questions. You guys are awesome!!&lt;/p&gt;
&lt;p&gt;Towards the end of the community bonding phase, I started working on updating stingray to APE-17(view my PR &lt;a href="https://github.com/StingraySoftware/stingray/pull/469"&gt;here&lt;/a&gt;). It was my first major PR(For all the non-techies out there a Pull Request(PR) is a proposal to implement changes to the main codebase to squash a bug or add a new feature). Looking at the status of the PR changed to “&lt;strong&gt;merged&lt;/strong&gt;” gave me an unprecedented level of gratification. &lt;em&gt;#justprogrammerthings&lt;/em&gt;&lt;br&gt;
I will not bore you with the technical aspects of APE-17 but if you wish to learn more about it, here’s a &lt;a href="https://github.com/StingraySoftware/stingray/files/4718995/APE17.Update.pdf"&gt;summarized document I created&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;X-ray Astronomy 101 with stingray&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/879/1*EsYpWW63Ui-bHMtjnIHjtQ.png"&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Disclaimer: &lt;/strong&gt;I am not an expert at X-ray Astronomy, not even by a long shot(Just a month’s experience). I am a Computer Science techie, passionate about space and great at googling stuff 😁.&lt;/p&gt;
&lt;p&gt;Now the part that all of you have been waiting for, the part that will give you the ultimate bragging rights of learning something new, &lt;em&gt;being productive&lt;/em&gt; in these lazy lockdown times, presenting to you&lt;em&gt;(insert drum roll) &lt;/em&gt;&lt;br&gt;
&lt;strong&gt;X-ray Astronomy 101 with stingray.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;1. What is stingray? What does it do?&lt;/p&gt;
&lt;p&gt;Stingray is a community-developed spectral-timing software package in Python for astrophysical data. It provides a basis for advanced spectral-timing analysis with a correct statistical framework while also being open-source.&lt;br&gt;
Stingray provides functionalities such as:&lt;br&gt;
a. Constructing light curves from event data and performing various operations on light curves (e.g. add, subtract, join, truncate)&lt;br&gt;
b. Good Time Interval operations&lt;br&gt;
c. Creating periodograms(power spectra) and cross spectra&lt;br&gt;
and many more.&lt;/p&gt;
&lt;p&gt;2. So well what does all of this mean?&lt;/p&gt;
&lt;p&gt;I apologize for the abrupt deep dive into the realm of long and daunting words that make zero sense at the moment. But please bear with me for a moment, once we are done with the basic you will truly appreciate the role that stingray plays.&lt;/p&gt;
&lt;p&gt;So let’s start with the basics.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/780/1*c_HQHP_uPGD4z6o11j7veg.png"&gt;&lt;figcaption&gt;A time series is a simple graph that can be plotted for any values eg. temperature, rainfall, stock price etc.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;a. &lt;strong&gt;Time Series:&lt;/strong&gt; It is a sequence of observations recorded at a succession of time intervals. In general, time series are characterized by the interdependence of its values. This means that the value of the series at some time &lt;strong&gt;t&lt;/strong&gt; is generally not independent of its value at, say, &lt;strong&gt;t−1&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;b.&lt;strong&gt; Time Series Analysis:&lt;/strong&gt; It is a statistical technique that deals with gaining insights from periodic or stochastic(a fancy way of saying random, aperiodic) time-series data.&lt;/p&gt;
&lt;p&gt;Now let’s learn some astronomical terms:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/850/1*yMWqnSRF06lxoYKptQ4d-A.png"&gt;&lt;figcaption&gt;FFT I am looking at you&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;a. &lt;strong&gt;Timing Analysis&lt;/strong&gt;: Many time series show periodic behaviour. This periodic behaviour can be very complex. Spectral analysis is a technique that allows us to discover underlying periodicities by decomposing the complex signal into simpler parts. To perform spectral analysis, we first must transform data from the time domain to the frequency domain. &lt;br&gt;
Hence spectral analysis can be defined as decomposing a stationary time series {&lt;em&gt;xT}&lt;/em&gt; into a combination of sinusoids(sine waves), with a random (and uncorrelated) coefficient; essentially analysis in the frequency domain.&lt;/p&gt;
&lt;p&gt;b. &lt;strong&gt;Good Time Intervals (GTI’s)&lt;/strong&gt;: When observing a stellar object with a satellite, data is accumulated by observing the source with short exposures over time or collecting single photons(light particles) with their arrival time.&lt;br&gt;
While recording observations, there will be times when everything is working perfectly. At other times we might have obstructions from the Earth that hinder our ability to observe the source properly.&lt;br&gt;
Good time intervals (GTIs) are the time intervals where instruments are working well and the source is perfectly visible.&lt;/p&gt;
&lt;p&gt;c. &lt;strong&gt;Light Curves&lt;/strong&gt;: Light curves are graphs that show the brightness of an object over a period of time. Images show from the part of an object from where light is emitted. Another piece of information we have about light is the time when it reaches the detector. Astronomers use this “timing” information to create light curves and perform timing analysis. &lt;br&gt;
They are simply graphs of brightness (Y-axis) vs. time (X-axis). Brightness increases as you go up the graph and time advances as you move to the right.&lt;br&gt;
eg. The following lightcurve can be generated with the values from the table on the left. The change in brightness is periodic.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/860/1*FNFYTegivTDTnsfqis1Tag.jpeg"&gt;&lt;/figure&gt;&lt;p&gt;We can generate similar light curves for studying any part of the light spectrum eg. X-Rays. The record of changes in brightness that a light curve provides can help astronomers understand processes at work within the object they are studying and identify specific categories of stellar events.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/591/0*r2NyyR6RtBfhevGq.png"&gt;&lt;/figure&gt;&lt;p&gt;d.&lt;strong&gt; Spectral Density/Power Spectra&lt;/strong&gt;: The power spectra of a time series {&lt;em&gt;xT} &lt;/em&gt;describes the distribution of power into the frequency components of that signal. When these signals are viewed in the form of a frequency spectrum, certain aspects of the received signals or the underlying processes producing them are revealed.&lt;/p&gt;
&lt;p&gt;e.&lt;strong&gt; Power Spectral Density Function&lt;/strong&gt;: A Power spectral density function (PSD) shows the number of energy variations as a function of frequency. In other words, it shows at which frequencies are variations strong, weak.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/582/0*ZYcuX1JdLSPTjPeM.png"&gt;&lt;/figure&gt;&lt;p&gt;f. &lt;strong&gt;Cross Spectra&lt;/strong&gt;: Cross spectral analysis allows one to determine the relationship between two time-series as a function of frequency. Normally, we wish to compare two time-series along their peaks to see if these signals are related to one another at the same frequency and if so, what is the phase relationship between them. Even if two signals look identical we wish to check their periodicity and understand how they are related.&lt;br&gt;
The Cross spectrum is a frequency domain analysis of the cross-correlation (how two lightcurves are related) or cross-covariance(how two lightcurves are related if one of them is linearly transformed eg. shifted in time).&lt;br&gt;
For further reference check this out: &lt;a href="https://atmos.washington.edu/~dennis/552_Notes_6c.pdf"&gt;https://atmos.washington.edu/~dennis/552_Notes_6c.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3. How does stingray contribute to all of this confusing stuff?&lt;/p&gt;
&lt;p&gt;Stingray implements all of these complex functions in a single easy to use package. It has various methods and classes such as lightcurve, powerspectrum, crossspectrum.&lt;br&gt;
Stingray also provides a &lt;em&gt;HENDRICS &lt;/em&gt;CLI and &lt;em&gt;dave &lt;/em&gt;GUI interface for abstract analysis.&lt;/p&gt;
&lt;p&gt;Woohoo!!🎉🎉 you made it through.&lt;br&gt;
Now if all of this intrigues you as much as it did me, you can go through the references mentioned below and the &lt;a href="https://github.com/StingraySoftware/notebooks"&gt;stingray notebooks &lt;/a&gt;that demonstrate the functionality mentioned above or even fork the repository and tinker around with the code yourself(&lt;strong&gt;Highly Recommended!&lt;/strong&gt;).&lt;/p&gt;
&lt;p&gt;Thank you soo much for giving it a read. Please comment and leave a clap if you liked the article. Feel free to reach out to me on &lt;a href="https://www.linkedin.com/in/theand9/"&gt;Linkedin&lt;/a&gt;. &lt;br&gt;
Have an amazing day!! &lt;strong&gt;You are awesome!!!&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;&lt;strong&gt;References:&lt;/strong&gt;&lt;/blockquote&gt;&lt;blockquote&gt;1. &lt;a href="http://web.stanford.edu/class/earthsys214/notes/series.html"&gt;http://web.stanford.edu/class/earthsys214/notes/series.html &lt;/a&gt;&lt;br&gt;
2. &lt;a href="https://www.investopedia.com/terms/t/timeseries.asp.."&gt;https://www.investopedia.com/terms/t/timeseries.asp&lt;/a&gt;&lt;br&gt;
3. &lt;a href="https://imagine.gsfc.nasa.gov/science/toolbox/timing1.html.."&gt;https://imagine.gsfc.nasa.gov/science/toolbox/timing1.html&lt;/a&gt;&lt;br&gt;
4. &lt;a href="http://coolwiki.ipac.caltech.edu/index.php/What_is_a_periodogram"&gt;http://coolwiki.ipac.caltech.edu/index.php/What_is_a_periodogram&lt;/a&gt;&lt;/blockquote&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=f3f95dffe246" width="1" height="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_0011_theand9/</guid><pubDate>Sun, 28 Jun 2020 23:11:13 GMT</pubDate></item><item><title>Chapter 2: Inquisition</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/</link><dc:creator>Raahul Singh</dc:creator><description>&lt;div&gt;&lt;h5&gt;Does AR Complexity correlate to Flaring Activity?&lt;/h5&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1020/1*UYJ3RzoWUcEgQUhWyo9uAA.jpeg"&gt;&lt;figcaption&gt;Rhododendrons flowering in the mountains. The State Flower of my state, Uttarakhand. The &lt;strong&gt;rhododendron&lt;/strong&gt; is native to sunny areas, it symbolizes beauty and energy. With its symbolism of optimism and cheer, it also serves as a symbol of love and the general positivity of the mountains.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;There has never been a better time to help scientists understand the mysteries of the sun.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.scientificamerican.com/gallery/turbulent-inner-life-of-a-sunspot-uncovered/"&gt;‘Sunspots&lt;/a&gt;’ and ‘&lt;a href="https://www.scientificamerican.com/citizen-science/solar-stormwatch/"&gt;solar storms&lt;/a&gt;’ are the feature of an ambitious project launched internationally by astrophysicists at Trinity College Dublin. Citizen scientists work as part of a global team to better understand sunspot and solar storm phenomena and their impacts on Earth. They do this by ‘rating’ the relative complexity of each sunspot image they see on the &lt;a href="http://www.sunspotter.org/"&gt;Sunspotter Web site&lt;/a&gt;, based on its size, shape and arrangement of ‘magnetic blobs’. &lt;a href="http://www.sunspotter.org/?utm_source=Newsletter&amp;amp;utm_medium=Email&amp;amp;utm_campaign=SunspotterLaunch&amp;amp;utm_content=T"&gt;Sunspotter&lt;/a&gt; is essentially a game of hot-or-not for sunspot data; citizen scientists are shown two images of sunspot groups and asked which is more complex. This is extremely useful in helping astronomers understand the physics of our star, the Sun.&lt;br&gt;
&lt;br&gt;
&lt;!-- TEASER_END --&gt;
Researchers cannot just use computers to classify all of this data because ‘complexity’ is not easily quantifiable. &lt;br&gt;
This project is part of the ‘&lt;a href="https://www.zooniverse.org/"&gt;Zooniverse&lt;/a&gt;’, a Web portal devoted to citizen science projects and which has more than 1 million volunteers.&lt;/p&gt;
&lt;p&gt;Now the question arises, does this &lt;strong&gt;complexity&lt;/strong&gt; actually correlate to &lt;strong&gt;Flare Activity&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;To find the answer, we must leverage the power of Statistical Hypothesis Testing.&lt;/p&gt;
&lt;h4&gt;Statistical Hypothesis Testing&lt;/h4&gt;&lt;p&gt;A &lt;strong&gt;statistical hypothesis&lt;/strong&gt;, sometimes called &lt;strong&gt;confirmatory data analysis&lt;/strong&gt;, is a &lt;a href="https://en.wikipedia.org/wiki/Hypothesis"&gt;hypothesis&lt;/a&gt; that is testable on the basis of &lt;a href="https://en.wikipedia.org/wiki/Observable_variable"&gt;observing&lt;/a&gt; a process that is &lt;a href="https://en.wikipedia.org/wiki/Statistical_model"&gt;modeled&lt;/a&gt; via a set of &lt;a href="https://en.wikipedia.org/wiki/Random_variable"&gt;random variables&lt;/a&gt;. A &lt;strong&gt;statistical hypothesis test&lt;/strong&gt; is a method of &lt;a href="https://en.wikipedia.org/wiki/Statistical_inference"&gt;statistical inference&lt;/a&gt;. Commonly, two statistical data sets are compared, or a data set obtained by sampling is compared against a synthetic data set from an idealized model. An &lt;a href="https://en.wikipedia.org/wiki/Alternative_hypothesis"&gt;alternative&lt;/a&gt; hypothesis is proposed for the statistical-relationship between the two data-sets, and is compared to an idealized null hypothesis that proposes no relationship between these two data-sets. This comparison is deemed &lt;a href="https://en.wikipedia.org/wiki/Statistically_significant"&gt;&lt;em&gt;statistically significant&lt;/em&gt;&lt;/a&gt; if the relationship between the data-sets would be an unlikely realization of the &lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt; according to a threshold probability — the significance level. Hypothesis tests are used when determining what outcomes of a study would lead to a rejection of the null hypothesis for a pre-specified level of significance.&lt;/p&gt;
&lt;h4&gt;The Null Hypothesis&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Inferential_statistics"&gt;inferential statistics&lt;/a&gt;, the &lt;strong&gt;null hypothesis&lt;/strong&gt; is a general statement or default position that there is no relationship between two measured phenomena or no association among groups.&lt;/p&gt;
&lt;p&gt;In other words nothing interesting is going on. The data on complexity has no relationship with the data on Flaring Activity.&lt;/p&gt;
&lt;p&gt;Our primary work here is to find evidence against the Null Hypothesis.&lt;/p&gt;
&lt;h4&gt;The Alternative Hypothesis&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"&gt;statistical hypothesis testing&lt;/a&gt;, the &lt;strong&gt;alternative hypothesis&lt;/strong&gt; is a position that states something is happening, a new theory is preferred instead of an old one (&lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;For our present study, the alternative hypothesis states that there indeed is&lt;strong&gt; &lt;/strong&gt;a&lt;strong&gt; positive correlation &lt;/strong&gt;between&lt;strong&gt; AR complexity and Flaring Activity.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It is this hypothesis that gets proved if we can successfully disregard the Null Hypothesis&lt;/p&gt;
&lt;p&gt;I take a statistical approach to determine if the complexity indeed does correlate to Solar Flare Activity.&lt;/p&gt;
&lt;h4&gt;p-Value&lt;/h4&gt;&lt;p&gt;In &lt;a href="https://en.wikipedia.org/wiki/Statistical_hypothesis_testing"&gt;statistical hypothesis testing&lt;/a&gt;, the &lt;strong&gt;&lt;em&gt;p&lt;/em&gt;-value &lt;/strong&gt;or &lt;strong&gt;probability value&lt;/strong&gt; is the best probability of obtaining test results at least as extreme as the &lt;a href="https://en.wikipedia.org/wiki/Realization_(probability)"&gt;results actually observed&lt;/a&gt;, assuming that the &lt;a href="https://en.wikipedia.org/wiki/Null_hypothesis"&gt;null hypothesis&lt;/a&gt; is correct. A very small &lt;em&gt;p&lt;/em&gt;-value means that the observed &lt;a href="https://en.wikipedia.org/wiki/Outcome_(probability)"&gt;outcome&lt;/a&gt; is possible but not very likely under the null hypothesis, even under the best explanation which is possible under that hypothesis.&lt;br&gt;
A smaller p-value would indicate that the Alternative Hypothesis is more likely than the Null Hypothesis. A small p-value is necessary but not sufficient to disregard the Null Hypothesis.&lt;/p&gt;
&lt;p&gt;The task at hand, thus, is to find the correlation between the AR complexity and the Flaring Activity, should any exist, and to find the p-value for the correlation.&lt;/p&gt;
&lt;h5&gt;To calculate the correlation and the associated p-value,&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/2e5b9911891a95b71ac8552bf4a33585/href"&gt;https://medium.com/media/2e5b9911891a95b71ac8552bf4a33585/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/9edb4aec3096ee9f1e50d2f69850bc4d/href"&gt;https://medium.com/media/9edb4aec3096ee9f1e50d2f69850bc4d/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/80c3c7f9805376f4fdfb9a6cc1c377bb/href"&gt;https://medium.com/media/80c3c7f9805376f4fdfb9a6cc1c377bb/href&lt;/a&gt;&lt;/iframe&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/a13636850986a3fbebbf8db3c25da0bd/href"&gt;https://medium.com/media/a13636850986a3fbebbf8db3c25da0bd/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Now that we have the DataFrames, we move on to use Point-Biserial Correlation.&lt;/p&gt;
&lt;h4&gt;Point-Biserial Correlation&lt;/h4&gt;&lt;p&gt;A point-biserial correlation is used to measure the strength and direction of the association that exists between one continuous variable and one dichotomous variable. It is a special case of the Pearson’s product-moment correlation, which is applied when you have two continuous variables, whereas in this case one of the variables is measured on a dichotomous scale.&lt;/p&gt;
&lt;h4&gt;Assumptions for using Point-Biserial Correlation&lt;/h4&gt;&lt;h5&gt;Assumption 1&lt;/h5&gt;&lt;blockquote&gt;One of the two variables should be measured on a continuous scale. In this analysis, the &lt;strong&gt;Complexity&lt;/strong&gt; is continuous.&lt;/blockquote&gt;&lt;h5&gt;Assumption 2&lt;/h5&gt;&lt;blockquote&gt;The other variable should be dichotomous. In this analysis, the whether an AR &lt;strong&gt;flares&lt;/strong&gt; is dichotomous, &lt;strong&gt;&lt;em&gt;0&lt;/em&gt;&lt;/strong&gt; denoting no flaring and &lt;strong&gt;&lt;em&gt;1&lt;/em&gt;&lt;/strong&gt; denoting flaring.&lt;/blockquote&gt;&lt;h5&gt;Assumption 3&lt;/h5&gt;&lt;blockquote&gt;The continuous variable should have equal variances for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;h5&gt;Assumption 4&lt;/h5&gt;&lt;blockquote&gt;There should be no outliers for the continuous variable for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;h5&gt;Assumption 5&lt;/h5&gt;&lt;blockquote&gt;The continuous variable should be approximately normally distributed for each category of the dichotomous variable.&lt;/blockquote&gt;&lt;p&gt;Having already satisfied assumptions 1 and 2,&lt;/p&gt;
&lt;h5&gt;For Assumption 3&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/ef13a7a8d2ae7170f901d2653794b912/href"&gt;https://medium.com/media/ef13a7a8d2ae7170f901d2653794b912/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;Thus Assumption 3 holds.&lt;/h5&gt;&lt;blockquote&gt;Continuous variable in both positive and negative classes has equal variance.&lt;/blockquote&gt;&lt;h5&gt;For Assumption 4&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/42d552cf02963d648621c29a8ee0c652/href"&gt;https://medium.com/media/42d552cf02963d648621c29a8ee0c652/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;This script gives the following two plots:&lt;/p&gt;
&lt;p&gt;In both plots &lt;strong&gt;&lt;em&gt;1 &lt;/em&gt;&lt;/strong&gt;denotes that a flare has been observed and&lt;strong&gt;&lt;em&gt; 0 &lt;/em&gt;&lt;/strong&gt;denotes no flaring activity is observed.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/999/1*5qHyB09_s4XL75Q9TrnLAw.png"&gt;&lt;figcaption&gt;Box plot&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/999/1*KEp3Tx0v27ftK46duSSFfw.png"&gt;&lt;figcaption&gt;Violin Plot&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;These plots show some outliers. For the current analysis, it is assumed that the outliers do not affect the correlation significantly. It is of interest to see the quantitative effect that the outliers have on the overall forecasting.&lt;/blockquote&gt;&lt;h5&gt;For Assumption 5&lt;/h5&gt;&lt;h5&gt;Plotting the distribution of positive and negative classes&lt;/h5&gt;&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/b4c3a28d823e308a396667756e76a167/href"&gt;https://medium.com/media/b4c3a28d823e308a396667756e76a167/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Which gives,&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/990/1*OxNolvY3nxrDCA9XqWbUGQ.png"&gt;&lt;figcaption&gt;Distribution plots for both classes&lt;/figcaption&gt;&lt;/figure&gt;&lt;blockquote&gt;From the distribution plots, the distribution of the normalized complexity in the negative and positive classes can be considered Gaussian.&lt;/blockquote&gt;&lt;h5&gt;Thus Assumption 5 holds.&lt;/h5&gt;&lt;h4&gt;Point-Biserial Correlation&lt;/h4&gt;&lt;p&gt;Since all the assumptions are satisfied, we move on to the actual correlation.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/4a0e4ec72ca37503044c4a6fd141e54a/href"&gt;https://medium.com/media/4a0e4ec72ca37503044c4a6fd141e54a/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Thus,&lt;/p&gt;
&lt;blockquote&gt;The Point-Biserial Correlation shows a moderate positive correlation between AR complexity and Flare Production.&lt;/blockquote&gt;&lt;p&gt;The moderate positive correlation of 0.45 indicates that there indeed exists a positive relationship between AR complexity and Flare activity.&lt;/p&gt;
&lt;p&gt;Although the negligible &lt;strong&gt;p-value &lt;/strong&gt;of&lt;strong&gt; &lt;/strong&gt;0.0&lt;strong&gt; &lt;/strong&gt;is necessary to disregard the the Null Hypothesis, it is not sufficient.&lt;/p&gt;
&lt;p&gt;My mentors and I are devising a strategy to firmly establish the&lt;strong&gt; alternative hypothesis.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This post marks the end of the first month of my GSoC journey, and my oh my what a month it has been!&lt;br&gt;
I am used to working long hours but somehow working on Pythia always makes these long hours pass me by in minutes.&lt;/p&gt;
&lt;p&gt;July brings with it, Deep Learning. The next month will be the most fun as I get to play around with neural networks and actually work on forecasting flares!&lt;br&gt;
I just hope the gods that govern CUDA and PyTorch are benevolent and do not curse me with exploding gradients.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;:)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;References &lt;/em&gt;: &lt;br&gt;
1) &lt;a href="https://www.scientificamerican.com/citizen-science/zooniverse-sunspotter/"&gt;&lt;em&gt;On Sunspotter&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) &lt;a href="https://en.wikipedia.org/wiki/Statistical_inference"&gt;&lt;em&gt;Statistical Inference and related sub topics&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;3) &lt;a href="https://statistics.laerd.com/spss-tutorials/point-biserial-correlation-using-spss-statistics.php"&gt;&lt;em&gt;Point-Biserial correlation&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=dd46de0863f6" width="1" height="1"&gt;&lt;hr&gt;&lt;p&gt;&lt;a href="https://blog.usejournal.com/chapter-2-inquisition-dd46de0863f6"&gt;Chapter 2: Inquisition&lt;/a&gt; was originally published in &lt;a href="https://blog.usejournal.com"&gt;Noteworthy - The Journal Blog&lt;/a&gt; on Medium, where people are continuing the conversation by highlighting and responding to this story.&lt;/p&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_2315_raahul-singh/</guid><pubDate>Sun, 28 Jun 2020 22:15:06 GMT</pubDate></item><item><title>Week 3 &amp; 4: The end of first month!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1804_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;h3 id="hey-sid-you-mentioned-about-releasing-the-package-in-the-previous-post-did-you-go-for-the-release"&gt;&lt;em&gt;Hey Sid, you mentioned about releasing the package in the previous post, did you go for the release?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes, I wrote the interface for &lt;code class="language-plaintext highlighter-rouge"&gt;combine&lt;/code&gt; function with FITS files and finally released &lt;em&gt;version-0.2.0&lt;/em&gt;, come check it! (&lt;a href="https://github.com/JuliaAstro/CCDReduction.jl"&gt;CCDReduction.jl&lt;/a&gt;)&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="so-how-were-the-weeks-3--4"&gt;&lt;em&gt;So, how were the weeks 3 &amp;amp; 4?&lt;/em&gt;&lt;/h3&gt;

&lt;p align="center"&gt; &lt;img src="https://beta.techcrunch.com/wp-content/uploads/2010/10/awesome.jpg"&gt; &lt;/p&gt;

&lt;p&gt;These two weeks were quite interesting! After packing all the basic functionalties in the package, &lt;em&gt;version-0.2.0&lt;/em&gt; was released, the next problem to be tackled was collecting and listing all relevant files from a directory. So, to solve this &lt;code class="language-plaintext highlighter-rouge"&gt;fitscollection&lt;/code&gt; was created, it takes a path, searches it recursively (if the user wants) for FITS files with ImageHDUs, list them together and return them in a data frame. It has some advanced functionalities as well, check the &lt;a href="https://juliaastro.github.io/CCDReduction.jl/dev/api/#CCDReduction.fitscollection-Tuple%7BString%7D"&gt;documentation&lt;/a&gt; to know more!&lt;/p&gt;

&lt;p&gt;Next, we created generators for filenames, image arrays, and ImageHDUs which works something like this:&lt;/p&gt;
&lt;div class="language-plaintext highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;# listing all FITS files present at some location with ImageHDUs
df = fitscollection(“location_of_some_fits_files”)
for arr in arrays(df)
# arr is the array representation of images present in entries of the data frame
# (i.e. array of ImageHDU's image data)
end
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The generators created were &lt;code class="language-plaintext highlighter-rouge"&gt;filenames&lt;/code&gt;, &lt;code class="language-plaintext highlighter-rouge"&gt;arrays&lt;/code&gt;, and &lt;code class="language-plaintext highlighter-rouge"&gt;images&lt;/code&gt;. &lt;code class="language-plaintext highlighter-rouge"&gt;filenames&lt;/code&gt; generates the path of the file, &lt;code class="language-plaintext highlighter-rouge"&gt;arrays&lt;/code&gt; generates the array representation of images in ImageHDU and &lt;code class="language-plaintext highlighter-rouge"&gt;images&lt;/code&gt; generates ImageHDU of FITS files. These generators work on output of &lt;code class="language-plaintext highlighter-rouge"&gt;fitscollection&lt;/code&gt; i.e. a data frame returned by the function. All these generators were written using &lt;a href="https://github.com/BenLauwens/ResumableFunctions.jl"&gt;ResumableFunctions.jl&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id="hmmm-interesting-whats-next"&gt;&lt;em&gt;Hmmm, interesting! What’s next?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Currently, I am working on issue &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/issues/28"&gt;#28&lt;/a&gt;, once this gets done, there will be a big release! Stay tuned to know more!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1804_siddharthlal25/</guid><pubDate>Sun, 28 Jun 2020 17:04:56 GMT</pubDate></item><item><title>Week 3 &amp; 4: First blood</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1322_sahilyadav27/</link><dc:creator>Sahil Yadav</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/680/1*eVG6uotsjTa5V092bqJ_uw.jpeg"&gt;&lt;figcaption&gt;“Magic”&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Since the last blog post, where there was a discussion about creating a script to convert the ROOT file into an HDF5 file with the CTA ML data format. So, during week 3 and 4 I was working on making this script. There were a few issues in this conversion.&lt;/p&gt;
&lt;p&gt;In the current DL1DataHandler, the event number is created conveniently in accordance with CTA data. But, the MAGIC data uses a different way to store event numbers. There are 2 arrays for each camera, one for the EvtNumber and another for StereoEvtNumber. The StereoEvtNumber array is mapped from the EvtNumber array. So, I used all the stereo events and stored their values in the HDF5 file. Mono study can be also done on these stereo events. Since MAGIC doesn’t currently do mono analysis on events triggering only one telescope, that part is currently omitted.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*aDisON-sEtx0T9-w9Lvkeg.png"&gt;&lt;/figure&gt;&lt;p&gt;So, now that this mapping is figured, we also mapped all the variables required in the HDF5 file with them in the ROOT file. Once everything was set up, I tried reading this converted file using the DL1DataReader. The first run yielded amazing results.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/365/1*gwcmu83NnKO8jYQUFYl5yA.png"&gt;&lt;figcaption&gt;First run output for MAGIC cam 1 and 2 from the converted HDF5 file&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So now I made &lt;a href="https://github.com/cta-observatory/dl1-data-handler/pull/90"&gt;PR #90&lt;/a&gt; to add this script to the DL1DataHandler. There are a few additions, like reading a runlist instead of filename, adding metadata, etc.&lt;/p&gt;
&lt;p&gt;Hence, the first milestone of the project is complete along with the first month.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=dc1ba79de370" width="1" height="1"&gt;&lt;/div&gt;</description><category>CTLearn</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_1322_sahilyadav27/</guid><pubDate>Sun, 28 Jun 2020 12:22:03 GMT</pubDate></item><item><title>What we've been working on these days!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_0700_meuge/</link><dc:creator>Meuge</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey, folks! I hope everyone is okay out there. Today, I am going to explain a little bit about &lt;strong&gt;Repeat ground track orbits&lt;/strong&gt;, and the value that lies behind.
Orbits with repeating ground tracks play a significant role in space engineering. Ground tracks that repeat according to any pattern have meaningful applications in remote sensing missions, reconnaissance missions, and numerous rendezvous and docking opportunities with an orbiting spacecraft. Since they overfly the same points on the planet’s surface every repeat cycle, such as those studying gravity, the atmosphere, or the movement of the polar ice cap.&lt;/p&gt;
&lt;p&gt;&lt;img alt="mind-blown" src="https://media.giphy.com/media/OK27wINdQS5YQ/giphy.gif"&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;So as you might imagine, this is amazing. In one way, the data we consume relies on these orbits. As mentioned before, Repeat ground track (RGT) orbits allows a satellite to reobserve the same area after a repeat cycle. &lt;/p&gt;
&lt;p&gt;&lt;img alt="repeat-ground-track" src="https://www.iceye.com/hs-fs/hubfs/new-pages-website-2019/Img%20(no%20adding)/Sat%20Data%20-%20constellation.gif?width=450&amp;amp;name=Sat%20Data%20-%20constellation.gif"&gt;&lt;/p&gt;
&lt;h2&gt;So how do we …&lt;/h2&gt;&lt;/div&gt;</description><category>poliastro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200628_0700_meuge/</guid><pubDate>Sun, 28 Jun 2020 06:00:00 GMT</pubDate></item></channel></rss>