<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy</title><link>http://openastronomy.org/Universe_OA/</link><description>This is an aggregator of openastronomy people</description><atom:link href="http://openastronomy.org/Universe_OA/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 23 Jul 2021 04:52:24 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>astropy@GSoC Blog Post #5, Week 6&amp;7</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210721_2000_suyog7130/</link><dc:creator>Suyog Garg</dc:creator><description>&lt;div&gt;&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;How are you?&lt;/p&gt;
&lt;p&gt;My dear mentors and I have decided to have the MRT (Machine Readable Table) format writing first. The same CDS code as been used now will be used, just the template of the written table will be in the MRT format.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Points to be noted regarding this and the immediate things that have been and will done are as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul style="text-align: left;"&gt;&lt;li&gt;Leave out writing all the optional CDS ReadMe fields as of now. These can be dealt with individual PRs later.&lt;/li&gt;&lt;li&gt;Some tests fail because &lt;span style="font-family: courier;"&gt;start_line = None&lt;/span&gt; doesn't work. It has been introduced once again within &lt;span style="font-family: courier;"&gt;CdsData.write&lt;/span&gt; function in addition to been defined in the main &lt;span style="font-family: courier;"&gt;Cds&lt;/span&gt; class. The test failure occurs because CdsData now inherits from &lt;span style="font-family: courier;"&gt;FixedWidthData&lt;/span&gt; which itself inherits &lt;span style="font-family: courier;"&gt;basic.BasicReader&lt;/span&gt; instead of BaseReader. I should make sure that all tests pass properly.&lt;/li&gt;&lt;li&gt;Have a template for MRT tables and write them first. &lt;b&gt;Title&lt;/b&gt;, &lt;b&gt;Authors&lt;/b&gt;, &lt;b&gt;Date&lt;/b&gt;, &lt;b&gt;Caption&lt;/b&gt; and &lt;b&gt;Notes&lt;/b&gt; sections, i.e. all sections except the Byte-By-Byte and the Data itself, will be left blank in the template, with warning for the user to put them in manually afterwards.&lt;/li&gt;&lt;li&gt;Documentation for the CDS/MRT format writer.&lt;/li&gt;&lt;li&gt;At present issue a warning note for tables with two or more mix-in columns (&lt;span style="font-family: courier;"&gt;SkyCoord&lt;/span&gt; cols primarily). If ways to correctly work out such situations is thought of, add that feature in a separate PR.&lt;/li&gt;&lt;li&gt;Work with a copy of the original table, so that¬† the copy is modified and not the original table, when component coordinate columns are written. The modified copy of the table is written to a file, while the user retains access to the columns of the original table.&lt;/li&gt;&lt;li&gt;Need to have features to recognise non Spherical coordinates, like the Cartesian coordinates, and either skip them or write them as Single column string values. Add test for such other coordinates. Also for cases when coordinates are in a &lt;span style="font-family: courier;"&gt;SkyCoord&lt;/span&gt; object but the frame is not Spherical.&lt;/li&gt;&lt;li&gt;Have two other templates, one for CDS in which the user fills values of optional fields manually later and another in which filling optional fields can be done from within Astropy, via a &lt;span style="font-family: courier;"&gt;cdsdict&lt;/span&gt;. In separate PRs. Here too write only the required fields in the ReadMe first, like &lt;b&gt;Abstract&lt;/b&gt;.&lt;/li&gt;&lt;li&gt;Have features for Time columns later within the original PR or much later.&lt;/li&gt;&lt;li&gt;Simplify how column format is obtained for float columns. The current manner of string formatting is too complicated. &lt;span style="font-family: courier;"&gt;col.width&lt;/span&gt; value can be directly used in some cases. The &lt;span style="font-family: courier;"&gt;Outputter&lt;/span&gt; class will also know the column format since it writes out the table.&lt;/li&gt;&lt;li&gt;Other minor/major edits and modifications as suggested by others.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;With this PR for the MRT format table writing getting eventually merged to Astropy, the main goal of my astropy@GSoC project will be completed. The support for other extra features essentially serves as appendages to the primary task been done by this PR.&lt;/div&gt;&lt;div&gt;Let's see how it goes.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Oh! On another note, a few days back I received the GSoC First Evaluations payment! üòÅ&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Adious!&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Astropy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210721_2000_suyog7130/</guid><pubDate>Wed, 21 Jul 2021 19:00:00 GMT</pubDate></item><item><title>Halfway into GSoC</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1916_dhruv9vats/</link><dc:creator>Dhruv Vats</dc:creator><description>&lt;div&gt;&lt;p&gt;This introductory adventure to Open Source is already at its midpoint, and while the learnings have been great and the experiences meaningful, I‚Äôm sure many of my fellow participants feel that a program like this should have an extended duration, and I am no exception. Such an extended timeline could provide many benefits, such as the ability to work on more complex and sophisticated projects, more time to collaborate and improve, to name a¬†few.&lt;/p&gt;
&lt;h5&gt;First Evaluation&lt;/h5&gt;&lt;p&gt;Another noteworthy thing concerning GSoC that happened in the last week was that the results of the first evaluation were declared, and while most cleared it, some didn‚Äôt. Although there is little to no need to question their abilities, sometimes life just doesn‚Äôt go as planned; it seems easy to say that that‚Äôs what the real test is, nevertheless it can quickly become something tricky to cope¬†with.&lt;/p&gt;
&lt;h5&gt;What next?&lt;/h5&gt;&lt;p&gt;While most of the ‚Äúproposed‚Äù work has been done, I will now be preparing some tutorials for the newly added functionality and tools, in an attempt to reduce the barrier to experimentation, use, and possible adoption of these new techniques into the workflow of its¬†users.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;So while this could take a good amount of time if quality is needed, there will surely some be time to play around with other things, but what exactly will end up happening will be answered by¬†time.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b6f9ec014333" width="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1916_dhruv9vats/</guid><pubDate>Mon, 19 Jul 2021 18:16:00 GMT</pubDate></item><item><title>Chapter 3: Midnight Sun</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1645_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;Phase 1 is over :) ! We are half way through the journey. Great learning experience so far. Let‚Äôs find out what I accomplished during the previous 2 weeks (since I believe you have been following me from the beginning ;)&lt;/p&gt;
&lt;p&gt;Getting straight to the point, most of the time was spent on fixing bugs of the Profiler class and other Pull requests regarding documentation and gallery example. A new gallery example was added to demonstrate the working of &lt;code class="language-text"&gt;SpecDatabase&lt;/code&gt; and &lt;code class="language-text"&gt;init_database&lt;/code&gt; to help user to store all Spectrums in the form of a &lt;code class="language-text"&gt;.spec&lt;/code&gt; file and all input parameters in a &lt;code class="language-text"&gt;csv&lt;/code&gt; file under a folder. The same folder can be used to retrieve all Spectrums thus saving a lot of time and also no need to recompute all spectrums, so quite a handy feature. Radis has &lt;code class="language-text"&gt;plot_cond&lt;/code&gt; function to plot a 2D heat map based on the parameters in csv file for all spectrums. Creates some good looking and informative plots :) &lt;br&gt;-&amp;gt; &lt;a href="https://radis.readthedocs.io/en/latest/auto_examples/plot_SpecDatabase.html#sphx-glr-auto-examples-plot-specdatabase-py"&gt;Gallery Example&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Back to the analysis part; for LDM we expected:&lt;br&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;time(LDM_fft) ~ c2*N_lines + c3*(N_G*N_L + 1)*N_v*log(N_v) (where N_v =  Spectral Points)
time(LDM_voigt) ~ c2*N_lines + c3'*(N_G*N_L + 1)*N_truncation*log(N_truncation) (where N_truncation = broadening width / wstep)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Legacy method I was able to prove that Calculation Time is independent of Spectral Range if we keep the N&lt;em&gt;lines and wstep constant but same is not for LDM voigt.&lt;br&gt;
A straight up comparison between Legacy and LDM voigt for NO  keeping N&lt;/em&gt;lines and wstep constant and varying the Spectral range:
&lt;a href="https://public.tableau.com/app/profile/anand.kumar4841/viz/LDMvsLegacyforSpectralRangeN_linesconstantandVoigtbroadening/Sheet1"&gt;Link&lt;/a&gt;&lt;br&gt;
Here also for None optimization we are getting constant time for different spectral range but a linear dependency for LDM Voigt which will fail the assumption of&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;t_LDM_voigt ~ c2*N_lines + c3'*(N_G*N_L + 1)*N_truncation  *log(N_truncation  )
but rather t_LDM_voigt ~ c2*N_lines + c3*(N_G*N_L + 1)*N_v*log(N_v)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;A New Discovery&lt;/h3&gt;
&lt;p&gt;On generating spectrum for millions of lines, one unique observation was seen. The bottleneck step was no longer taking the most time. Max time was spent upon an unknown process. Upon deep analysis it was found a part of code was using &lt;code class="language-text"&gt;sys.getsizeof()&lt;/code&gt; to get the size of dataframe, and when the dataframe consisited of &lt;code class="language-text"&gt;object&lt;/code&gt; type columns with millions of lines, most of the time was spent on this step only.&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/95eda74e349d883f4a1fcc85291a91cc/6af66/ldm.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/95eda74e349d883f4a1fcc85291a91cc/f058b/ldm.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We replaced it with &lt;code class="language-text"&gt;memory_usage(deep=False)&lt;/code&gt; with a different threshold which made computation almost &lt;strong&gt;2x&lt;/strong&gt; faster.&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/28b1ad4d276fa9921520808bc6360002/87488/ba.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/28b1ad4d276fa9921520808bc6360002/f058b/ba.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So phase 1 is over,and phase 2 is going to begin which will mainly focus on optimizing the the existing LDM method with appropriate truncation and other possible areas!&lt;/p&gt;
&lt;p&gt;See you on the other side of the sea ;)&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/6c695ad1951b1c737cc12c701ffce0e4/2551b/other.jpg" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/6c695ad1951b1c737cc12c701ffce0e4/828fb/other.jpg" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1645_anandxkumar/</guid><pubDate>Mon, 19 Jul 2021 15:45:32 GMT</pubDate></item><item><title>GSoC - 2</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_0300_gagan-aryan/</link><dc:creator>Gagan Aryan</dc:creator><description>&lt;div&gt;&lt;p&gt;Welcome back !! So we are done with our first phase of the project and are shifting into the second one. I will be keeping this blog short since most of the details of the refactor have already been written in my previous post.&lt;/p&gt;
&lt;p&gt;By the time I was writing my previous post I had a pretty decent idea of how I would be doing each of the refactors. We had already decided that we may not have to implement all of them because Vaex might render a few of those changes redundant.&lt;/p&gt;
&lt;p&gt;I started out by writing a proof-of-concept to remove the column where partition function was added. Only the case of equilibrium molecules was handled here. The idea was to make use of pandas‚Äô dictionary efficiently and remove the column. With the proof-of-concept we could conclude that not only did this approach reduce memory, but it also reduced CPU pressure by around 2x. For the lines of &lt;code&gt;HITEMP-CH4&lt;/code&gt; molecules for the waverange 2000-3000 previously the dataframe occupied 1.2 GB but with this method we could compress that to around 100 MB. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Apart from this I wrote down another notebook that demostrated that we can radically improve memory usage by crunching the datatypes of the columns of &lt;code&gt;HITRAN/HITEMP&lt;/code&gt; molecules. The notebook just contains elementary operations to arrive at the right datatype for each of the column. We haven‚Äôt implemented this into the codebase yet because we still haven‚Äôt figured out what we will be doing with the missing lines. A problem I had already mentioned in my first post. &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I was somehow able to sneak my way into successfully completing GSoC phase one with feedback that has pumped me to do even better. I am looking forward to the second phase and hope to deliver.&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="https://github.com/radis/radis-benchmark/blob/master/manual_benchmarks/test_Qgas.ipynb"&gt;Proof-of-Concept for Qgas&lt;/a&gt; &lt;a class="footnote-backref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fnref:1"&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="https://github.com/radis/radis-benchmark/pull/11"&gt;Proof-of-Concept for Datatype Crunching - WIP&lt;/a&gt; &lt;a class="footnote-backref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fnref:2"&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_0300_gagan-aryan/</guid><pubDate>Mon, 19 Jul 2021 02:00:06 GMT</pubDate></item><item><title>So here I am, a month into the coding period and at the onset of the first evaluation.</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210711_1548_adwaitbhope/</link><dc:creator>Adwait Bhope</dc:creator><description>&lt;div&gt;&lt;h4&gt;About my Google Summer of Code Project: Part¬†2&lt;/h4&gt;&lt;p&gt;So here I am, a month into the coding period and at the onset of the first evaluation. I talked about what my project was in the &lt;a href="https://adwaitbhope.medium.com/about-my-google-summer-of-code-project-part-1-b56e7277046e"&gt;last blog&lt;/a&gt;, and I‚Äôll use this one to cover the progress we‚Äôve¬†made.&lt;/p&gt;
&lt;p&gt;All the work so far has been compiled into 3 messy PRs. To start with, reprojecting an NDCube onto another WCS requires that you first validate whether the source and target WCS transformations are in fact compatible. It‚Äôs no good if they represent an entirely different coordinate system. They need to have the same number of world axes and in the same order. The first PR introduces a function to check this and it has been merged into the main¬†branch.&lt;/p&gt;
&lt;p&gt;The second one implements the actual reproject method on NDCube, leveraging the reproject package. Currently, it serves as a wrapper around the interpolation algorithm, with plans to support more algorithms soon. But that bit is dependent on optimizing the current functionality by being a little smarter about detecting axes that do not need to be modified. This would also help speed up the function AND use less¬†memory!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The third PR is an interesting one. There is a class called NDCubeSequence, which is, as the name says, a sequence of NDCubes. Think of it as multiple NDCubes arranged in an array with some additional convenient functionality. Let‚Äôs say you have some information about an image that isn‚Äôt really related to any of the axes but applies to the whole image‚Ää‚Äî‚Ääthe timestamp of the image, for example. If you have multiple similar images taken at different timestamps, they can form an NDCubeSequence, where the sequence axis represents time. You can also combine the sequence axis with an existing axis of the cubes so that they form a large panorama or mosaic, which is wider than the field of view that could‚Äôve been captured in one¬†image.&lt;/p&gt;
&lt;p&gt;In most cases, the individual cubes do not share the same WCS object even if they are images of the same entity. This is because of effects like wobble or rotation that introduce slight changes in the WCS. So we used the previously implemented reproject method to get all the cubes on the same grid, so they can share the WCS. Then, we stacked the data of all cubes together in one single numpy array, introducing an extra dimension that corresponds to the sequence. A new WCS is also constructed that includes this newly formed dimension. You combine this data and the WCS, and voila, you have reduced the NDCubeSequence to an¬†NDCube!&lt;/p&gt;
&lt;p&gt;The next steps would be to refine this behaviour and try to optimize wherever possible. Then we‚Äôll try to get these 2 remaining PRs merged in the main branch to avoid getting inundated later. So, this is all for this post, see you in the next¬†one!&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=2e6f76a45653" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210711_1548_adwaitbhope/</guid><pubDate>Sun, 11 Jul 2021 14:48:45 GMT</pubDate></item><item><title>Not just Python.</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210710_1254_jeffreypaul15/</link><dc:creator>Jeffrey Paul</dc:creator><description>&lt;div&gt;&lt;h4&gt;Not just¬†Python&lt;/h4&gt;&lt;p&gt;Sunkit-Pyvista is doing quite well as of today, this goes without saying due to the fact the the Sunpy developers put in quite a bit of effort into reading all the stuff that I write and they do carefully review¬†them.&lt;/p&gt;
&lt;p&gt;That being said, I‚Äôve personally faced no a few issues with getting things to work as they are. I don‚Äôt have much to say about this project except the fact that I‚Äôm super stoked about it and it has been going super¬†well.&lt;/p&gt;
&lt;p&gt;I get to write code from scratch that‚Äôs turned into an actual project that would help someone, I also get to learn stuff that I never saw myself doing. From tinkering around with CircleCI to getting documentation to work the way we want them to, this project seems like the ideal one for a python developer like¬†me.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;To summarize what happened over the past few weeks¬†‚Äî&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;We‚Äôve gotten over most of the project and we‚Äôre now working towards the initial stuff we put a pin¬†in.&lt;/li&gt;&lt;li&gt;The basic plotting functionality of Sunpy now exists with Sunkit-Pyvista.&lt;/li&gt;&lt;li&gt;We moved the documentation over to GitHub workflows and I‚Äôm hoping that we get it to work by the end of the¬†month.&lt;/li&gt;&lt;li&gt;We‚Äôve introduced animations as a new feature to our work and we‚Äôve got some ideas with how to take this¬†forward.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Having no prior experience with Astrophysics, I decided to give Stephen Hawking‚Äôs ‚ÄúThe Theory of Everything‚Äù a read. (Well, not a read, I prefer listening to audio books even though they are inferior). Revisiting physics with an astronomical sense gave me such a new perspective on what I am doing and fueled the motivation to continue the project with the same excitement I began¬†with.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zrsJJIzLw4FexpUa1-SAUw.png"&gt;&lt;figcaption&gt;Regardless of it not actually looking like this‚Ää‚Äî‚Ääit still is fascinating, isn‚Äôt¬†it?&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A year ago, I never saw myself voluntarily taking an interest in astrophysics or open source software, but here I am today, doing both of them simultaneously. Who knows what the future holds for me, I‚Äôve always been anxious about that. At times like these I try to think of how this universe is so nondeterministic, we may have a few guesses and theories as to why things happen the way it does but, we can‚Äôt say for sure. This thought grounds my thoughts and I suddenly stop worrying about everything, for sometime at-least‚Ä¶&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=ef21d76e0152" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210710_1254_jeffreypaul15/</guid><pubDate>Sat, 10 Jul 2021 11:54:23 GMT</pubDate></item><item><title>astropy@GSoC Blog Post #4, Week 4</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210709_2232_suyog7130/</link><dc:creator>Suyog Garg</dc:creator><description>&lt;div&gt;&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;How you doing?&lt;/p&gt;
&lt;p&gt;Yup! Lots of things done again. I have finally completed the main goal of the project. Yahoo!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;&lt;/div&gt;</description><category>Astropy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210709_2232_suyog7130/</guid><pubDate>Fri, 09 Jul 2021 21:32:00 GMT</pubDate></item><item><title>Chapter 2: Survey Corps</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_2340_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;So its been around 4 weeks into the coding period, a lot of insights and progress so far!&lt;/p&gt;
&lt;h3&gt;Profiler Class&lt;/h3&gt;
&lt;p&gt;The good news is that the Profiler class has been successfully implemented in the develop branch and will be available to users by version &lt;code class="language-text"&gt;0.9.30&lt;/code&gt; .&lt;br&gt;
&lt;!-- TEASER_END --&gt;
Link : &lt;a href="https://github.com/radis/radis/pull/286"&gt;Profiler PR&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Below is a simple example how all steps are printed based on the verbose level:&lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;wmin = 2000
wmax = 3300
wstep = 0.01
T = 3000.0 #K
p = 0.1 #bar
broadening_max_width=10

sf = SpectrumFactory(wavenum_min=wmin, wavenum_max=wmax,
pressure=p,
wstep=wstep,
broadening_max_width=broadening_max_width,
molecule="CO",
cutoff=0, # 1e-27,
verbose=3,
)
sf.load_databank('HITEMP-CO')
s = sf.eq_spectrum(T)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Output:&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;... Scaling equilibrium linestrength
... 0.01s - Scaled equilibrium linestrength
... 0.00s - Calculated lineshift
... 0.00s - Calculate broadening HWHM
... Calculating line broadening (60869 lines: expect ~ 6.09s on 1 CPU)
...... 0.16s - Precomputed DLM lineshapes (30)
...... 0.00s - Initialized vectors
...... 0.00s - Get closest matching line &amp;amp; fraction
...... 0.02s - Distribute lines over DLM
...... 1.95s - Convolve and sum on spectral range
... 2.14s - Calculated line broadening
... 0.01s - Calculated other spectral quantities
... 2.21s - Spectrum calculated (before object generation)
... 0.01s - Generated Spectrum object
2.22s - Spectrum calculated&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Also we can access these steps and the time taken by them using &lt;code class="language-text"&gt;Spectrum.get_conditions()['profiler']&lt;/code&gt;. Also there is a parameter &lt;code class="language-text"&gt;SpectrumFactory.profiler.relative_time_percentage&lt;/code&gt; that stores the percentage of time taken by each steps at a particular verbose level, helpful seeing the most expensive steps in Spectrum calculation.&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Legacy Method Complexity&lt;/h3&gt;
&lt;p&gt;Several Spectrums were benchmarked against various parameters to see it‚Äôs correlation and derive its complexity. We used Profiler class with &lt;a href="https://radis.readthedocs.io/en/latest/source/radis.lbl.loader.html#radis.lbl.loader.DatabankLoader.init_database"&gt;init_database()&lt;/a&gt; which stores all parameters of Spectrum along the Profiler in a &lt;code class="language-text"&gt;csv&lt;/code&gt; generated file; all spectrum info got added into the csv file  which could be used to do create visualizations to analyze the data. We used &lt;code class="language-text"&gt;Xexplorer&lt;/code&gt; library and &lt;code class="language-text"&gt;Tableau&lt;/code&gt;(a visual analytics platform) to create visualizations. A &lt;a href="https://github.com/anandxkumar/Benchmark_Visualization_GSoC_2021"&gt;github repository&lt;/a&gt; was created to store the Visualization along the CSV data file of each benchmark.&lt;/p&gt;
&lt;p&gt;Following are the inference of the benchmarks for Legacy Method:&lt;/p&gt;
&lt;b&gt;
‚Ä¢  Calculation Time ‚àù Number of lines&lt;br&gt;
‚Ä¢  Calculation Time ‚àù Broadening max width&lt;br&gt;
‚Ä¢  Calculation Time ‚àù 1/wstep&lt;br&gt;
‚Ä¢  Calculation Time not dependent on Spectral Range&lt;br&gt;
&lt;/b&gt;&lt;br&gt;
&lt;p&gt;So complexity of Legacy method can be derived as: &lt;br&gt;
&lt;strong&gt;&lt;code class="language-text"&gt;complexity = constant * Number of lines * Broadening Max Width / Wstep&lt;/code&gt;&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;
&lt;h3&gt;LDM Method Complexity&lt;/h3&gt;
&lt;p&gt;Similar technique was used to benchmark LDM method. Now LDM uses 2 types of broadening method that are &lt;code class="language-text"&gt;voigt&lt;/code&gt; and &lt;code class="language-text"&gt;fft&lt;/code&gt;. &lt;code class="language-text"&gt;voigt&lt;/code&gt; uses truncation for calculating spectrum  in wavenmber space where as &lt;code class="language-text"&gt;fft&lt;/code&gt; calculates spectrum on entire spectral range in fourier space. So benchmarks were done on both methods to compare their performance against various parameters.&lt;/p&gt;
&lt;p&gt;Spectrum were benchmarked against parameters like Spectral Range, Wstep, Spectral Points, Number of Lines and Broadening Max Width. Following are the inferences.&lt;/p&gt;
&lt;p&gt;For &lt;code class="language-text"&gt;fft&lt;/code&gt;:&lt;br&gt;
&lt;b&gt;
‚Ä¢ Calculation Time ‚àù Spectral Points&lt;br&gt;
‚Ä¢ Calculation Time ‚àù Number of Lines&lt;br&gt;
&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;For &lt;code class="language-text"&gt;voigt&lt;/code&gt;:&lt;br&gt;
&lt;b&gt;
‚Ä¢ Calculation Time ‚àù Spectral Points&lt;br&gt;
‚Ä¢ Calculation Time ‚àù Number of Lines&lt;br&gt;
‚Ä¢ Calculation Time ‚àù Broadening Max Width&lt;br&gt;
&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;For LDM we are expecting the following complexity:&lt;br&gt;
&lt;strong&gt;&lt;code class="language-text"&gt;t_LDM_fft ~ c2*N_lines + c3*(N_G*N_L + 1)*N_v*log(N_v)&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;&lt;code class="language-text"&gt;t_LDM_voigt ~ c2*N_lines + c3'*(N_G*N_L + 1)*N_truncation*log(N_truncation)&lt;/code&gt;&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt; So the goal for the next 2 weeks will be to get the complexity of both &lt;code class="language-text"&gt;voigt&lt;/code&gt; and &lt;code class="language-text"&gt;fft&lt;/code&gt; method and see places for improving both methods and quite possibily create a &lt;code class="language-text"&gt;Hybrid&lt;/code&gt; method taking the best of both worlds. &lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_2340_anandxkumar/</guid><pubDate>Mon, 05 Jul 2021 22:40:32 GMT</pubDate></item><item><title>A Month into GSoC</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_2037_dhruv9vats/</link><dc:creator>Dhruv Vats</dc:creator><description>&lt;div&gt;&lt;p&gt;It‚Äôs almost been a month since the start of GSoC‚Äôs coding period and the work, I‚Äôm glad to write, is progressing at a steady and satisfactory rate.&lt;/p&gt;
&lt;h5&gt;The Developments&lt;/h5&gt;&lt;p&gt;The last time around, my first ever not-so-meaningless contribution to open-source had just got merged, and I was really happy about it. But what that also did was, get me over the initial anxiety and intimidation I might have been feeling towards open-source. This, I think, has also helped speed things¬†along.&lt;/p&gt;
&lt;p&gt;While I started working on the optional features of my project around 2 weeks ago, I had to scrape the initial implementation because it turned out to be very, very slow and therefore had to be completely replaced with a better and more efficient approach, which was a bit less straightforward. But now, two weeks into experimenting and iterating, a new pull-request has been opened with the newly implemented efficient version of the feature, and while it's still a few minor commits away from its final form, the core functionality works as expected and, if everything goes as expected, which is never a guarantee, a hefty part of my proposal‚Äôs objectives will be complete.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;And while this does not guarantee anything, I‚Äôd be lying if I said that I am not hoping for something exciting to do as I might have time to try out other things. What exactly, I honestly don‚Äôt know, but if I find myself in that minority who actually like what there doing, it‚Äôll be an absolute privilege, which I‚Äôm looking forward to and wishing¬†for.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DvmM4lhclsVa5tIwl5um4A.png"&gt;&lt;figcaption&gt;Just some pastel colors for you to look¬†at&lt;/figcaption&gt;&lt;/figure&gt;&lt;h5&gt;The Goal&lt;/h5&gt;&lt;p&gt;What follows might be a very steep change in topic, but is one, that I think lies at the root of many seemingly normal activities. This is just something that has been on my mind lately, and what writing is, if not a tool to better understand yourself?&lt;/p&gt;
&lt;p&gt;I feel like an invisible aura is building around me saying that you are at a stage in life where you need to man up, where you should have everything together and figured out, but whenever I try and assess myself in this context, I always, without fail, fell short of it and by a good margin. While the contrasting opposite of this would be saying that I am everything I ever wanted to be and have nothing to work towards, would be outright arrogant and even dangerous, there must be a balance somewhere, right?&lt;/p&gt;
&lt;p&gt;But why should I have it all figured out, what‚Äôs even the need? And while statements like these can be argued against using something like, because everyone is doing it, and this is the way, they give the vibes of being in a pipeline you‚Äôve been pushed into and now have no option but to pass through. And this, I think, many will agree, is not a very desirable situation.&lt;/p&gt;
&lt;p&gt;This need to progress towards something also spurs off many questions, one of which is ‚Äúthe why¬†?‚Äù. The why, is an oh-so-difficult question to answer that honestly makes me feel frustrated at times, not knowing to what end all the efforts are being¬†put.&lt;/p&gt;
&lt;p&gt;While it can be argued that this is a ridiculous thing to think about, and one should not set overly optimistic expectations, this, I feel, contradicts the notion of elegance that I somehow have associated with the fundamental workings of the world. If someone asked me to comment on the secrets of the Universe, I‚Äôd be very comfortable with using the words elegant and sophisticated, even though I basically know nothing about it? Why? Is this just a desire to find meaning in everything, or is there something else at¬†play?&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=805d42b1b5ce" width="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_2037_dhruv9vats/</guid><pubDate>Mon, 05 Jul 2021 19:37:36 GMT</pubDate></item><item><title>Insight of Implementation of JAX to stingray- GSoC coding period!</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_1420_rashmiraj137/</link><dc:creator>Raj Rashmi</dc:creator><description>&lt;div&gt;&lt;p&gt;In the last blog, I wrote about Introduction to JAX and Automatic Differentiation. In this one, my plan for the next stage of implementation. Currently, I am working on the modeling notebook (&lt;a href="https://github.com/StingraySoftware/notebooks/blob/main/Modeling/ModelingExamples.ipynb"&gt;https://github.com/StingraySoftware/notebooks/blob/main/Modeling/ModelingExamples.ipynb&lt;/a&gt;) to re-design it using JAX, especially to make optimization more robust by having JAX compute gradients on the likelihood function.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/380/1*u_c4S0h60T1IECOBQVTS1A.jpeg"&gt;&lt;/figure&gt;&lt;p&gt;My mentor Daniela highlighted the issue that the current implementation is not robust using NumPy. The plan is to keep working on the current modeling notebook replacing NumPy by jax.numpy and also use grad, jit, vmap, random functionality of JAX.&lt;br&gt;When it comes to re-design, understanding the current design and the possible drawback and issues with corresponding packages comes on you first and I am trying them out. One such challenge is importing emcee into jupyter notebook for sampling. Despite making sure, I download the dependency in the current virtual environment and then making sure I import emcee into the notebook, it is still acting weird and showing an error: emcee not installed! Can‚Äôt sample! It looks like a clash of dependencies.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/240/1*JtGB50sLscB1BBPt9k3pfw.jpeg"&gt;&lt;figcaption&gt;Trying to have fun while it¬†lasts!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;For now, the plan is to solve every bug I face in the journey and then proceed with understanding how everything connects and the next step is to come up with the report of optimization using JAX. Stay tuned for more on how JAX can accelerate and augment the current modeling framework.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I would recommend one video for anyone who wants to understand the functionality of JAX better and relate more to my study (click¬†&lt;a href="https://www.youtube.com/watch?v=0mVmRHMaOJ4&amp;amp;ab_channel=GoogleCloudTech"&gt;here&lt;/a&gt;).&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=1756040fa5ae" width="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210705_1420_rashmiraj137/</guid><pubDate>Mon, 05 Jul 2021 13:20:55 GMT</pubDate></item></channel></rss>