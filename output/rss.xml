<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy</title><link>http://openastronomy.org/Universe_OA/</link><description>This is an aggregator of openastronomy people</description><atom:link href="http://openastronomy.org/Universe_OA/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Mon, 02 Aug 2021 04:59:40 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>About my Google Summer of Code Project: Part 3</title><link>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1853_adwaitbhope/</link><dc:creator>Adwait Bhope</dc:creator><description>&lt;div&gt;&lt;p&gt;First and foremost, I celebrate the merging of the PR that brings reproject to NDCube! It defines a base-level functionality or MVP if you want to call it that, along with some relevant documentation. We also mark the release of ndcube’s 2.0 RC1. This is an important milestone since ndcube 2.0 brings significant changes, owing to the implementation of the new high-level WCS API.&lt;/p&gt;
&lt;p&gt;Our next plan of action was to extend the method to use other algorithms that reproject supports. Interpolation (the one that the above PR implements) supports multi-dimensional cubes but “adaptive” and “exact” algorithms do not. For the time being, they only work on 2D cubes containing celestial axes. So that’s what I’ve implemented them for in a new PR, which is currently under review and should hopefully get merged soon.&lt;/p&gt;
&lt;p&gt;The only problem for this PR was identifying celestial axes. We’ve taken a shortcut to solve this quickly and avoid creating a blocker, but a better implementation is due.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The NDCubeSequence PR that I talked about in the last blog post hit a few unexpected edge cases which are under work.&lt;/p&gt;
&lt;p&gt;We’re nearing the end of GSoC’s official timeline and while that is saddening, the good thing is that open source doesn’t need a GSoC timeline for contributing. I do hope that I’ll be able to tie up any loose ends before the end date, but I suppose that does not matter in the community’s bigger picture. Functional additions, bug fixes, and performance improvements are always going to be coming in for reproject, and I plan to maintain at least that bit of code (or more) in the future.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=f6354389b27f" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1853_adwaitbhope/</guid><pubDate>Sun, 01 Aug 2021 17:53:41 GMT</pubDate></item><item><title>Chapter 4: The Other Side</title><link>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1424_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;A new month has started and I have started to see the light at the end of the tunnel. Good Morning and welcome back. Phase 2 has been rolling and let us look at the new findings.&lt;/p&gt;
&lt;p&gt;Earlier the complexity of Legacy method was determined. The complexity of LDM Voigt and LDM FFT was to be determined using similar approach. Upon executing several benchmarks based on Number of lines, Spectum range, wstep, broadening max width. Previously it was thought the complexity was: &lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;time(LDM_fft) ~ c2*Nlines + c3*(N_G*N_L + 1)*N_v*log(N_v) (where N_v =  Spectral Points)
&lt;!-- TEASER_END --&gt;
time(LDM_voigt) ~ c2*Nlines + c3'*(N_G*N_L + 1)*N_truncation*log(N_truncation) (where N_truncation = broadening width / wstep)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;But in actual Re running all benchmarks for &lt;strong&gt;LDM&amp;gt;Voigt&lt;/strong&gt; and &lt;strong&gt;LDM&amp;gt;FFT&lt;/strong&gt; with a &lt;code class="language-text"&gt;broadening max width = 300 cm-1&lt;/code&gt;. All benchmarks and visualizations can be found &lt;a href="https://anandxkumar.github.io/Benchmark_Visualization_GSoC_2021/"&gt;here&lt;/a&gt; we were able to conclude the followings:&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;FFT:&lt;/strong&gt;&lt;br&gt;
•  Complexity doesn’t depend on Nlines but rather wL x wG ; check this benchmark: &lt;a href="https://public.tableau.com/app/profile/anand.kumar4841/viz/LDMLinesvsCalculationTimeUpdatedCO2/Sheet1"&gt;link&lt;/a&gt;, it certainly looks like Complexity ∝ Nlines but its actually dependent on wL and wG, and gives same result on (wL x wG+ 1) x Spectral&lt;em&gt;Points x Log(Spectral&lt;/em&gt;Points).&lt;br&gt;
•  Upon implementing multiple linear regression for &lt;strong&gt;c1 x Nlines + c2 x (wL x wG+ 1)*Spectral&lt;em&gt;Points x Log(Spectral&lt;/em&gt;Points)&lt;/strong&gt; gives &lt;code class="language-text"&gt;c1=2.65e-07&lt;/code&gt;, &lt;code class="language-text"&gt;c2=4.48256e-08&lt;/code&gt; but their &lt;code class="language-text"&gt;p value = 0.648 and 0.00001&lt;/code&gt;, and &lt;code class="language-text"&gt;p&amp;gt;0.05&lt;/code&gt; are insignificant, thus Nlines is insignificant for determining the complexity.&lt;br&gt;
•  Since FFT is independent of broadening max width; benchmark: &lt;a href="https://public.tableau.com/app/profile/anand.kumar4841/viz/LDMVoigtandFFTBMW_NEW/Sheet1"&gt;link&lt;/a&gt;, so on comparing it Spectral point gives us same same time. Thus Spectral Point =  (wavenum max - wavenum max)/wstep instead of (wavenum maxcalc - wavenum min calc)/wstep&lt;br&gt;
•  &lt;strong&gt;Overall complexity =  4.48256897e-08 x (wL x wG+ 1) x Spectral&lt;em&gt;Points(without BMW) x Log(Spectral&lt;/em&gt;Points(without BMW))&lt;/strong&gt;  &lt;a href="https://anandxkumar.github.io/Benchmark_Visualization_GSoC_2021/LDM/Complexity_FFT_Final/Complexity_FFT_Final.html"&gt;link&lt;/a&gt; (with the help of multple linear regression using sklearn; is almost accurate)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Voigt:&lt;/strong&gt;&lt;br&gt;
•  Similar to 1st point of FFT.&lt;br&gt;
•  Upon doing multiple linear regression for &lt;strong&gt;c1 x N lines + c2 x (wL x wG + 1) x SpectralPoints x BMW xLog(SpectralPoints x (BMW) )&lt;/strong&gt; gives &lt;code class="language-text"&gt;c1=-1.9392e-06, c2=1.28256e-09&lt;/code&gt; but their &lt;code class="language-text"&gt;p value = 0.848 and 0.00001&lt;/code&gt;, and &lt;code class="language-text"&gt;p&amp;gt;0.05&lt;/code&gt; are insignificant, thus N&lt;em&gt;lines is insignificant for determining the complexity.&lt;br&gt;
•  Calculation time is dependent `Broadening&lt;/em&gt;Max&lt;em&gt;width`, but upon inspections with Spectral Points, we have the exact same plot. So complexity is dependent only on Spectral Points but with broadening&lt;/em&gt;max&lt;em&gt;width i.e. wavenum&lt;/em&gt;calc, which causes the increase in computational time on increasing broadening&lt;em&gt;max&lt;/em&gt;width.&lt;br&gt;
•  &lt;strong&gt;Overall complexity = 5.26795e-07 * (wL x wG+ 1)*Spectral Points x Log(Spectral Points)&lt;/strong&gt; &lt;a href="https://anandxkumar.github.io/Benchmark_Visualization_GSoC_2021/LDM/Complexity_Voigt_Final/Complexity_Voigt_Final.html"&gt;link&lt;/a&gt; (with the help of multple linear regression using sklearn; almost straight)&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Also:&lt;/strong&gt; From all the above plots, it really clear if going with broadening&lt;em&gt;max&lt;/em&gt;width=300cm-1 in wavespace, it will take alot more time than fft in all aspects.&lt;/p&gt;
&lt;p&gt;But upon replacing &lt;code class="language-text"&gt;np.convolve&lt;/code&gt; with &lt;code class="language-text"&gt;scipy.signal.oaconvolve&lt;/code&gt;, we were able to achieve &lt;code class="language-text"&gt;2 to 30&lt;/code&gt; times performance boost. So it will be interesting to re run benchmarks with the latest piece of code and see which method performs better. Also some benchmarks will be added to ASV benchmark too to see how its performance changes over time.&lt;/p&gt;
&lt;p&gt;Also profiler was modified to a tree like a stucture using &lt;code class="language-text"&gt;OrderedDict&lt;/code&gt; and &lt;code class="language-text"&gt;YAML&lt;/code&gt; has been used to print the profiler in a proper structued way using &lt;strong&gt;Spectrum.print_perf_profiler()&lt;/strong&gt; or &lt;strong&gt;SpectrumFactory.print_perf_profiler()&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;s = calc_spectrum(1900, 2300,         # cm-1
molecule='CO',
isotope='1,2,3',
pressure=1.01325,   # bar
Tvib=1000,          # K
Trot=300,           # K
mole_fraction=0.1,
verbose=3,
)
s.print_perf_profile()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Gives the following output:&lt;/strong&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;&amp;gt;&amp;gt;&amp;gt; spectrum_calculation:
&amp;gt;&amp;gt;&amp;gt;   applied_linestrength_cutoff: 0.0024361610412597656
&amp;gt;&amp;gt;&amp;gt;   calc_emission_integral: 0.006468772888183594
&amp;gt;&amp;gt;&amp;gt;   calc_hwhm: 0.006415128707885742
&amp;gt;&amp;gt;&amp;gt;   calc_line_broadening:
&amp;gt;&amp;gt;&amp;gt;     DLM_Distribute_lines: 0.0003898143768310547
&amp;gt;&amp;gt;&amp;gt;     DLM_Initialized_vectors: 9.775161743164062e-06
&amp;gt;&amp;gt;&amp;gt;     DLM_closest_matching_line: 0.0005028247833251953
&amp;gt;&amp;gt;&amp;gt;     DLM_convolve: 0.029767990112304688
&amp;gt;&amp;gt;&amp;gt;     precompute_DLM_lineshapes: 0.013132810592651367
&amp;gt;&amp;gt;&amp;gt;     value: 0.07619166374206543
&amp;gt;&amp;gt;&amp;gt;   calc_lineshift: 0.00074005126953125
&amp;gt;&amp;gt;&amp;gt;   calc_noneq_population:
&amp;gt;&amp;gt;&amp;gt;     part_function: 0.03405046463012695
&amp;gt;&amp;gt;&amp;gt;     population: 0.005669832229614258
&amp;gt;&amp;gt;&amp;gt;     value: 0.03983640670776367
&amp;gt;&amp;gt;&amp;gt;   calc_other_spectral_quan: 0.002928495407104492
&amp;gt;&amp;gt;&amp;gt;   calc_weight_trans: 0.008247852325439453
&amp;gt;&amp;gt;&amp;gt;   check_line_databank: 0.0002810955047607422
&amp;gt;&amp;gt;&amp;gt;   check_non_eq_param: 0.04109525680541992
&amp;gt;&amp;gt;&amp;gt;   fetch_energy_5: 0.014983654022216797
&amp;gt;&amp;gt;&amp;gt;   generate_spectrum_obj: 0.00032138824462890625
&amp;gt;&amp;gt;&amp;gt;   generate_wavenumber_arrays: 0.0010433197021484375
&amp;gt;&amp;gt;&amp;gt;   reinitialize:
&amp;gt;&amp;gt;&amp;gt;     copy_database: 2.1457672119140625e-06
&amp;gt;&amp;gt;&amp;gt;     memory_usage_warning: 0.0018389225006103516
&amp;gt;&amp;gt;&amp;gt;     reset_population: 2.6226043701171875e-05
&amp;gt;&amp;gt;&amp;gt;     value: 0.001964569091796875
&amp;gt;&amp;gt;&amp;gt;   scaled_non_eq_linestrength:
&amp;gt;&amp;gt;&amp;gt;     corrected_population_se: 0.002747774124145508
&amp;gt;&amp;gt;&amp;gt;     map_part_func: 0.0010590553283691406
&amp;gt;&amp;gt;&amp;gt;     value: 0.0038983821868896484
&amp;gt;&amp;gt;&amp;gt;   value: 0.1904621124267578&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So at the end a productive week! Looking forward to conclude GSoC with a worthy ending :)&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1424_anandxkumar/</guid><pubDate>Sun, 01 Aug 2021 13:24:32 GMT</pubDate></item><item><title>GSoC Post 3</title><link>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1244_ndanzanello/</link><dc:creator>ndanzanello</dc:creator><description>&lt;div&gt;&lt;p&gt;Hi! In my last post I mentioned that we would start calculating the distortions contained in the image. But we followed a different path! As the linear part was ready, we first worked on making some plots (scatter plots with side histograms of the difference in pixel scale of the celestial coordinates measured with the WCS we find and the celestial coordinates given as input) and drawing some quads to visualize it. This part was done using LaTeX and TikZ, a wonderful tool to produce graphics!&lt;/p&gt;


&lt;!-- TEASER_END --&gt;

&lt;div class="wp-block-image"&gt;&lt;figure class="aligncenter size-large"&gt;&lt;img alt="" class="wp-image-73" src="https://ndanzanello.files.wordpress.com/2021/08/image.png?w=342"&gt;&lt;figcaption&gt;Example of a quad drawn using TikZ. The black points are the stars of the catalog.&lt;/figcaption&gt;&lt;/figure&gt;&lt;/div&gt;



&lt;p&gt;After that, we started to evaluate our results, and some changes were made: in statistics, for example, instead of getting direct the median, we use sigma clipping (a technique that removes outliers), allowing a better result. We also compared our results with one well established software: Astrometry.net. We’re getting pretty good results, but our running time was way bigger than the Astrometry.net one. So, we started working on that, and we have some ways to decrease our running time, such as making an only geo-hash search on the kdtree before the search containing the magnitude hashes. This reduces the dimentionality, which degrades the performance the higher it is. Other solution is to divide the celestial catalog in tiles, decreasing the number of total quads that we have to evaluate. Also, we can reduce the number of stars that we use to make quads. With these approaches, our running time got way better! &lt;img alt="🙂" class="wp-smiley" src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;"&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description><category>gnuastro</category><guid>http://openastronomy.org/Universe_OA/posts/2021/08/20210801_1244_ndanzanello/</guid><pubDate>Sun, 01 Aug 2021 11:44:53 GMT</pubDate></item><item><title>Balance</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210730_1925_jeffreypaul15/</link><dc:creator>Jeffrey Paul</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/400/1*6vTTZ8HC33kEpYk0Wr8gxg.jpeg"&gt;&lt;figcaption&gt;“Cosmic Balance” — completely unrelated type of balance to what I go on to talk to talk about in this post. Although, outer space looks all fancy and it goes well with the theme of OpenAstronomy.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;From all my previous posts, it is quite evident that I obsess over small and insignificant details, mainly directed towards how my life is going to be in the future and this entire concept of “happiness”. However, the past few months of working with Sunpy has brought about this odd sense of calm. The entire feeling of stress being an emotion goes out the window. Maybe this is what doing something you love, maybe it’s the people — or maybe it’s just extremely good timing combined with coincidence.&lt;/p&gt;
&lt;p&gt;Ah, I suppose these questions don’t have simple answers. Regardless, whatever I’m doing with right now has restored that balance that I was longing for.&lt;/p&gt;
&lt;p&gt;Coming to what has been happening with sunkit-pyvista. To summarize, I spent an entire week fixing things that I caused due to over-confidence :)&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Aside from that, I think I’m nearing the end of this project. A few bits of functionality has to be added in but for the most part, I think it’s all in there.&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Saving and loading entire scenes are now possible with the work that we’ve done. This took quite a bit of time and it was pretty interesting to see how we could extend functionality to such massive extents.&lt;/li&gt;&lt;li&gt;We uncovered a few hidden issues that may have occurred because of me. Ones such as ill-defined tests because I may have been slightly over-confident with how I write code.&lt;/li&gt;&lt;li&gt;Quite a bit of time was spent resolving these issues, but I can definitely conclude that it was well worth the effort and I certainly learnt my lesson.&lt;/li&gt;&lt;li&gt;Figure tests are now a thing, we drew some parallels with Pyvista’s code and structured our own figure testing methodology which makes it easier for us to visually identify any mishaps in our plots. After all, we’re creating a library for data visualization. It’d be sad if our code tests pass and we’re under the assumption that everything is working fine (yet another dig at myself for not writing efficient tests).&lt;/li&gt;&lt;li&gt;I can safely say that Sunkit-Pyvista is quite balanced and usable now, or at least I hope so.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Getting back to how this might be the last few PRs of this project under the whole “GSoC timeline”, this makes me both sad and happy. It’s saddening to see that something I worked towards for over 6 months has kind of come to an end. Happy because I’ve gotten to work with some of the best developers and I genuinely enjoyed every bit of it. This offsets the balance in my life, but I think we may have a solution to this?&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=239840d26318" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210730_1925_jeffreypaul15/</guid><pubDate>Fri, 30 Jul 2021 18:25:35 GMT</pubDate></item><item><title>astropy@GSoC Blog Post #5, Week 6&amp;7</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210721_2000_suyog7130/</link><dc:creator>Suyog Garg</dc:creator><description>&lt;div&gt;&lt;p&gt;Hi,&lt;/p&gt;
&lt;p&gt;How are you?&lt;/p&gt;
&lt;p&gt;My dear mentors and I have decided to have the MRT (Machine Readable Table) format writing first. The same CDS code as been used now will be used, just the template of the written table will be in the MRT format.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Points to be noted regarding this and the immediate things that have been and will done are as follows:&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul style="text-align: left;"&gt;&lt;li&gt;Leave out writing all the optional CDS ReadMe fields as of now. These can be dealt with individual PRs later.&lt;/li&gt;&lt;li&gt;Some tests fail because &lt;span style="font-family: courier;"&gt;start_line = None&lt;/span&gt; doesn't work. It has been introduced once again within &lt;span style="font-family: courier;"&gt;CdsData.write&lt;/span&gt; function in addition to been defined in the main &lt;span style="font-family: courier;"&gt;Cds&lt;/span&gt; class. The test failure occurs because CdsData now inherits from &lt;span style="font-family: courier;"&gt;FixedWidthData&lt;/span&gt; which itself inherits &lt;span style="font-family: courier;"&gt;basic.BasicReader&lt;/span&gt; instead of BaseReader. I should make sure that all tests pass properly.&lt;/li&gt;&lt;li&gt;Have a template for MRT tables and write them first. &lt;b&gt;Title&lt;/b&gt;, &lt;b&gt;Authors&lt;/b&gt;, &lt;b&gt;Date&lt;/b&gt;, &lt;b&gt;Caption&lt;/b&gt; and &lt;b&gt;Notes&lt;/b&gt; sections, i.e. all sections except the Byte-By-Byte and the Data itself, will be left blank in the template, with warning for the user to put them in manually afterwards.&lt;/li&gt;&lt;li&gt;Documentation for the CDS/MRT format writer.&lt;/li&gt;&lt;li&gt;At present issue a warning note for tables with two or more mix-in columns (&lt;span style="font-family: courier;"&gt;SkyCoord&lt;/span&gt; cols primarily). If ways to correctly work out such situations is thought of, add that feature in a separate PR.&lt;/li&gt;&lt;li&gt;Work with a copy of the original table, so that  the copy is modified and not the original table, when component coordinate columns are written. The modified copy of the table is written to a file, while the user retains access to the columns of the original table.&lt;/li&gt;&lt;li&gt;Need to have features to recognise non Spherical coordinates, like the Cartesian coordinates, and either skip them or write them as Single column string values. Add test for such other coordinates. Also for cases when coordinates are in a &lt;span style="font-family: courier;"&gt;SkyCoord&lt;/span&gt; object but the frame is not Spherical.&lt;/li&gt;&lt;li&gt;Have two other templates, one for CDS in which the user fills values of optional fields manually later and another in which filling optional fields can be done from within Astropy, via a &lt;span style="font-family: courier;"&gt;cdsdict&lt;/span&gt;. In separate PRs. Here too write only the required fields in the ReadMe first, like &lt;b&gt;Abstract&lt;/b&gt;.&lt;/li&gt;&lt;li&gt;Have features for Time columns later within the original PR or much later.&lt;/li&gt;&lt;li&gt;Simplify how column format is obtained for float columns. The current manner of string formatting is too complicated. &lt;span style="font-family: courier;"&gt;col.width&lt;/span&gt; value can be directly used in some cases. The &lt;span style="font-family: courier;"&gt;Outputter&lt;/span&gt; class will also know the column format since it writes out the table.&lt;/li&gt;&lt;li&gt;Other minor/major edits and modifications as suggested by others.&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;With this PR for the MRT format table writing getting eventually merged to Astropy, the main goal of my astropy@GSoC project will be completed. The support for other extra features essentially serves as appendages to the primary task been done by this PR.&lt;/div&gt;&lt;div&gt;Let's see how it goes.&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Oh! On another note, a few days back I received the GSoC First Evaluations payment! 😁&lt;/div&gt;&lt;div&gt;&lt;br&gt;&lt;/div&gt;&lt;div&gt;Adious!&lt;/div&gt;&lt;p&gt;&lt;/p&gt;&lt;/div&gt;</description><category>Astropy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210721_2000_suyog7130/</guid><pubDate>Wed, 21 Jul 2021 19:00:00 GMT</pubDate></item><item><title>Halfway into GSoC</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1916_dhruv9vats/</link><dc:creator>Dhruv Vats</dc:creator><description>&lt;div&gt;&lt;p&gt;This introductory adventure to Open Source is already at its midpoint, and while the learnings have been great and the experiences meaningful, I’m sure many of my fellow participants feel that a program like this should have an extended duration, and I am no exception. Such an extended timeline could provide many benefits, such as the ability to work on more complex and sophisticated projects, more time to collaborate and improve, to name a few.&lt;/p&gt;
&lt;h5&gt;First Evaluation&lt;/h5&gt;&lt;p&gt;Another noteworthy thing concerning GSoC that happened in the last week was that the results of the first evaluation were declared, and while most cleared it, some didn’t. Although there is little to no need to question their abilities, sometimes life just doesn’t go as planned; it seems easy to say that that’s what the real test is, nevertheless it can quickly become something tricky to cope with.&lt;/p&gt;
&lt;h5&gt;What next?&lt;/h5&gt;&lt;p&gt;While most of the “proposed” work has been done, I will now be preparing some tutorials for the newly added functionality and tools, in an attempt to reduce the barrier to experimentation, use, and possible adoption of these new techniques into the workflow of its users.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;So while this could take a good amount of time if quality is needed, there will surely some be time to play around with other things, but what exactly will end up happening will be answered by time.&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b6f9ec014333" width="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1916_dhruv9vats/</guid><pubDate>Mon, 19 Jul 2021 18:16:00 GMT</pubDate></item><item><title>Chapter 3: Midnight Sun</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1645_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;Phase 1 is over :) ! We are half way through the journey. Great learning experience so far. Let’s find out what I accomplished during the previous 2 weeks (since I believe you have been following me from the beginning ;)&lt;/p&gt;
&lt;p&gt;Getting straight to the point, most of the time was spent on fixing bugs of the Profiler class and other Pull requests regarding documentation and gallery example. A new gallery example was added to demonstrate the working of &lt;code class="language-text"&gt;SpecDatabase&lt;/code&gt; and &lt;code class="language-text"&gt;init_database&lt;/code&gt; to help user to store all Spectrums in the form of a &lt;code class="language-text"&gt;.spec&lt;/code&gt; file and all input parameters in a &lt;code class="language-text"&gt;csv&lt;/code&gt; file under a folder. The same folder can be used to retrieve all Spectrums thus saving a lot of time and also no need to recompute all spectrums, so quite a handy feature. Radis has &lt;code class="language-text"&gt;plot_cond&lt;/code&gt; function to plot a 2D heat map based on the parameters in csv file for all spectrums. Creates some good looking and informative plots :) &lt;br&gt;-&amp;gt; &lt;a href="https://radis.readthedocs.io/en/latest/auto_examples/plot_SpecDatabase.html#sphx-glr-auto-examples-plot-specdatabase-py"&gt;Gallery Example&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Back to the analysis part; for LDM we expected:&lt;br&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;time(LDM_fft) ~ c2*N_lines + c3*(N_G*N_L + 1)*N_v*log(N_v) (where N_v =  Spectral Points)
time(LDM_voigt) ~ c2*N_lines + c3'*(N_G*N_L + 1)*N_truncation*log(N_truncation) (where N_truncation = broadening width / wstep)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;For Legacy method I was able to prove that Calculation Time is independent of Spectral Range if we keep the N&lt;em&gt;lines and wstep constant but same is not for LDM voigt.&lt;br&gt;
A straight up comparison between Legacy and LDM voigt for NO  keeping N&lt;/em&gt;lines and wstep constant and varying the Spectral range:
&lt;a href="https://public.tableau.com/app/profile/anand.kumar4841/viz/LDMvsLegacyforSpectralRangeN_linesconstantandVoigtbroadening/Sheet1"&gt;Link&lt;/a&gt;&lt;br&gt;
Here also for None optimization we are getting constant time for different spectral range but a linear dependency for LDM Voigt which will fail the assumption of&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;t_LDM_voigt ~ c2*N_lines + c3'*(N_G*N_L + 1)*N_truncation  *log(N_truncation  )
but rather t_LDM_voigt ~ c2*N_lines + c3*(N_G*N_L + 1)*N_v*log(N_v)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3&gt;A New Discovery&lt;/h3&gt;
&lt;p&gt;On generating spectrum for millions of lines, one unique observation was seen. The bottleneck step was no longer taking the most time. Max time was spent upon an unknown process. Upon deep analysis it was found a part of code was using &lt;code class="language-text"&gt;sys.getsizeof()&lt;/code&gt; to get the size of dataframe, and when the dataframe consisited of &lt;code class="language-text"&gt;object&lt;/code&gt; type columns with millions of lines, most of the time was spent on this step only.&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/95eda74e349d883f4a1fcc85291a91cc/6af66/ldm.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/95eda74e349d883f4a1fcc85291a91cc/f058b/ldm.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;We replaced it with &lt;code class="language-text"&gt;memory_usage(deep=False)&lt;/code&gt; with a different threshold which made computation almost &lt;strong&gt;2x&lt;/strong&gt; faster.&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/28b1ad4d276fa9921520808bc6360002/87488/ba.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/28b1ad4d276fa9921520808bc6360002/f058b/ba.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So phase 1 is over,and phase 2 is going to begin which will mainly focus on optimizing the the existing LDM method with appropriate truncation and other possible areas!&lt;/p&gt;
&lt;p&gt;See you on the other side of the sea ;)&lt;/p&gt;
&lt;p&gt;&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/6c695ad1951b1c737cc12c701ffce0e4/2551b/other.jpg" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="display: block;"&gt;&lt;/span&gt;
&lt;img alt="complexity.jpg" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/6c695ad1951b1c737cc12c701ffce0e4/828fb/other.jpg" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="complexity.jpg"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_1645_anandxkumar/</guid><pubDate>Mon, 19 Jul 2021 15:45:32 GMT</pubDate></item><item><title>GSoC - 2</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_0300_gagan-aryan/</link><dc:creator>Gagan Aryan</dc:creator><description>&lt;div&gt;&lt;p&gt;Welcome back !! So we are done with our first phase of the project and are shifting into the second one. I will be keeping this blog short since most of the details of the refactor have already been written in my previous post.&lt;/p&gt;
&lt;p&gt;By the time I was writing my previous post I had a pretty decent idea of how I would be doing each of the refactors. We had already decided that we may not have to implement all of them because Vaex might render a few of those changes redundant.&lt;/p&gt;
&lt;p&gt;I started out by writing a proof-of-concept to remove the column where partition function was added. Only the case of equilibrium molecules was handled here. The idea was to make use of pandas’ dictionary efficiently and remove the column. With the proof-of-concept we could conclude that not only did this approach reduce memory, but it also reduced CPU pressure by around 2x. For the lines of &lt;code&gt;HITEMP-CH4&lt;/code&gt; molecules for the waverange 2000-3000 previously the dataframe occupied 1.2 GB but with this method we could compress that to around 100 MB. &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fn:1"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Apart from this I wrote down another notebook that demostrated that we can radically improve memory usage by crunching the datatypes of the columns of &lt;code&gt;HITRAN/HITEMP&lt;/code&gt; molecules. The notebook just contains elementary operations to arrive at the right datatype for each of the column. We haven’t implemented this into the codebase yet because we still haven’t figured out what we will be doing with the missing lines. A problem I had already mentioned in my first post. &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fn:2"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I was somehow able to sneak my way into successfully completing GSoC phase one with feedback that has pumped me to do even better. I am looking forward to the second phase and hope to deliver.&lt;/p&gt;
&lt;div class="footnotes"&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="https://github.com/radis/radis-benchmark/blob/master/manual_benchmarks/test_Qgas.ipynb"&gt;Proof-of-Concept for Qgas&lt;/a&gt; &lt;a class="footnote-backref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fnref:1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;&lt;a href="https://github.com/radis/radis-benchmark/pull/11"&gt;Proof-of-Concept for Datatype Crunching - WIP&lt;/a&gt; &lt;a class="footnote-backref" href="https://gagan-aryan.netlify.app/tags/gsoc21//index.xml#fnref:2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210719_0300_gagan-aryan/</guid><pubDate>Mon, 19 Jul 2021 02:00:06 GMT</pubDate></item><item><title>So here I am, a month into the coding period and at the onset of the first evaluation.</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210711_1548_adwaitbhope/</link><dc:creator>Adwait Bhope</dc:creator><description>&lt;div&gt;&lt;h4&gt;About my Google Summer of Code Project: Part 2&lt;/h4&gt;&lt;p&gt;So here I am, a month into the coding period and at the onset of the first evaluation. I talked about what my project was in the &lt;a href="https://adwaitbhope.medium.com/about-my-google-summer-of-code-project-part-1-b56e7277046e"&gt;last blog&lt;/a&gt;, and I’ll use this one to cover the progress we’ve made.&lt;/p&gt;
&lt;p&gt;All the work so far has been compiled into 3 messy PRs. To start with, reprojecting an NDCube onto another WCS requires that you first validate whether the source and target WCS transformations are in fact compatible. It’s no good if they represent an entirely different coordinate system. They need to have the same number of world axes and in the same order. The first PR introduces a function to check this and it has been merged into the main branch.&lt;/p&gt;
&lt;p&gt;The second one implements the actual reproject method on NDCube, leveraging the reproject package. Currently, it serves as a wrapper around the interpolation algorithm, with plans to support more algorithms soon. But that bit is dependent on optimizing the current functionality by being a little smarter about detecting axes that do not need to be modified. This would also help speed up the function AND use less memory!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The third PR is an interesting one. There is a class called NDCubeSequence, which is, as the name says, a sequence of NDCubes. Think of it as multiple NDCubes arranged in an array with some additional convenient functionality. Let’s say you have some information about an image that isn’t really related to any of the axes but applies to the whole image — the timestamp of the image, for example. If you have multiple similar images taken at different timestamps, they can form an NDCubeSequence, where the sequence axis represents time. You can also combine the sequence axis with an existing axis of the cubes so that they form a large panorama or mosaic, which is wider than the field of view that could’ve been captured in one image.&lt;/p&gt;
&lt;p&gt;In most cases, the individual cubes do not share the same WCS object even if they are images of the same entity. This is because of effects like wobble or rotation that introduce slight changes in the WCS. So we used the previously implemented reproject method to get all the cubes on the same grid, so they can share the WCS. Then, we stacked the data of all cubes together in one single numpy array, introducing an extra dimension that corresponds to the sequence. A new WCS is also constructed that includes this newly formed dimension. You combine this data and the WCS, and voila, you have reduced the NDCubeSequence to an NDCube!&lt;/p&gt;
&lt;p&gt;The next steps would be to refine this behaviour and try to optimize wherever possible. Then we’ll try to get these 2 remaining PRs merged in the main branch to avoid getting inundated later. So, this is all for this post, see you in the next one!&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=2e6f76a45653" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210711_1548_adwaitbhope/</guid><pubDate>Sun, 11 Jul 2021 14:48:45 GMT</pubDate></item><item><title>Not just Python.</title><link>http://openastronomy.org/Universe_OA/posts/2021/07/20210710_1254_jeffreypaul15/</link><dc:creator>Jeffrey Paul</dc:creator><description>&lt;div&gt;&lt;h4&gt;Not just Python&lt;/h4&gt;&lt;p&gt;Sunkit-Pyvista is doing quite well as of today, this goes without saying due to the fact the the Sunpy developers put in quite a bit of effort into reading all the stuff that I write and they do carefully review them.&lt;/p&gt;
&lt;p&gt;That being said, I’ve personally faced no a few issues with getting things to work as they are. I don’t have much to say about this project except the fact that I’m super stoked about it and it has been going super well.&lt;/p&gt;
&lt;p&gt;I get to write code from scratch that’s turned into an actual project that would help someone, I also get to learn stuff that I never saw myself doing. From tinkering around with CircleCI to getting documentation to work the way we want them to, this project seems like the ideal one for a python developer like me.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;To summarize what happened over the past few weeks —&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;We’ve gotten over most of the project and we’re now working towards the initial stuff we put a pin in.&lt;/li&gt;&lt;li&gt;The basic plotting functionality of Sunpy now exists with Sunkit-Pyvista.&lt;/li&gt;&lt;li&gt;We moved the documentation over to GitHub workflows and I’m hoping that we get it to work by the end of the month.&lt;/li&gt;&lt;li&gt;We’ve introduced animations as a new feature to our work and we’ve got some ideas with how to take this forward.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Having no prior experience with Astrophysics, I decided to give Stephen Hawking’s “The Theory of Everything” a read. (Well, not a read, I prefer listening to audio books even though they are inferior). Revisiting physics with an astronomical sense gave me such a new perspective on what I am doing and fueled the motivation to continue the project with the same excitement I began with.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*zrsJJIzLw4FexpUa1-SAUw.png"&gt;&lt;figcaption&gt;Regardless of it not actually looking like this — it still is fascinating, isn’t it?&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;A year ago, I never saw myself voluntarily taking an interest in astrophysics or open source software, but here I am today, doing both of them simultaneously. Who knows what the future holds for me, I’ve always been anxious about that. At times like these I try to think of how this universe is so nondeterministic, we may have a few guesses and theories as to why things happen the way it does but, we can’t say for sure. This thought grounds my thoughts and I suddenly stop worrying about everything, for sometime at-least…&lt;/p&gt;
&lt;img alt="" height="1" src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=ef21d76e0152" width="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2021/07/20210710_1254_jeffreypaul15/</guid><pubDate>Sat, 10 Jul 2021 11:54:23 GMT</pubDate></item></channel></rss>