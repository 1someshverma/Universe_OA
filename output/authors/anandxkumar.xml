<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts by anandxkumar)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/authors/anandxkumar.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Sun, 04 Jul 2021 04:40:19 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Chapter 1: First Flight</title><link>http://openastronomy.org/Universe_OA/posts/2021/06/20210621_2240_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey! Missed me? I’m back with another blog, the first related to the Coding Period. Got some progress and interesting observation to share!&lt;/p&gt;
&lt;h3&gt;Ready -&amp;gt; Set -&amp;gt; Code -&amp;gt; Analyze&lt;/h3&gt;
&lt;p&gt;The first thing I did in the coding period, was analyse the problem and get a feasible approach to resolve it.&lt;br&gt;&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;&lt;strong&gt;Problem:&lt;/strong&gt; Find the complexity of the Legacy and LDM method.&lt;br&gt;
&lt;strong&gt;Solution:&lt;/strong&gt; Run some benchmarks and find the bottleneck step.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;First I chose the &lt;strong&gt;Legacy&lt;/strong&gt; method because if its simpler architecture. I ran some benchmarks varying the &lt;code class="language-text"&gt;spectral range&lt;/code&gt; of &lt;code class="language-text"&gt;OH&lt;/code&gt; and &lt;code class="language-text"&gt;CO2&lt;/code&gt; molecule to get similar number of lines. I kept parameters like &lt;code class="language-text"&gt;pressure&lt;/code&gt;, &lt;code class="language-text"&gt;temperature&lt;/code&gt;, &lt;code class="language-text"&gt;broadening_max_width&lt;/code&gt;, &lt;code class="language-text"&gt;wstep&lt;/code&gt;, etc constant to see the dependence of Legacy method on &lt;strong&gt;Spectral range&lt;/strong&gt;. &lt;br&gt;&lt;/p&gt;
&lt;p&gt;In order to get similar number of lines, I created a function which will take the &lt;strong&gt;Spectrum Factory&lt;/strong&gt; &lt;code class="language-text"&gt;dataframe&lt;/code&gt; and select the target number of lines. But the issue with Pandas dataframe is that when modify the dataframe there are chances that the metadata will get lost and we will no longer be able to do Spectrum calculation. To avoid this we have to drop the right number of lines with &lt;code class="language-text"&gt;inplace=True&lt;/code&gt;. So we will need to fix the number of lines and then we can proceed ahead with the benchmarking. Every parameter is the same except the Spectral Range.  Full code &lt;a href="https://gist.github.com/anandxkumar/cbe12f47170e1d71a82f4b246bd01dcc"&gt;here&lt;/a&gt;.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Earlier we assumed that the complexity of Legacy method is: &lt;br&gt;
&lt;strong&gt;&lt;code class="language-text"&gt;Voigt Broadening = Broadening_max_width * spectral_range/math.pow(wstep,2) * N&lt;/code&gt;&lt;/strong&gt; &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Thus I was expecting to have different calculation time for both benchmarks. But to my surprise the computational times were almost equivalent! I re-ran each benchmarks &lt;strong&gt;100 times&lt;/strong&gt; just to be sure and more precise about it. Following were the observations:&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Number of lines - &lt;b&gt;{‘OH’: 28143, ‘CO’: 26778}&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;Total Calculation time(Avg) -  &lt;b&gt;{‘OH’: 4.4087, ‘CO’: 3.8404000000000003}&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;Total Voigt_Broadening TIME(Avg) - &lt;b&gt;{‘OH’: 3.1428814244270327, ‘CO’: 3.081623389720917}&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;spectral_range - &lt;b&gt;{‘OH’: 38010, ‘CO’: 8010}&lt;/b&gt;&lt;/li&gt;
&lt;li&gt;Legacy_Scale - &lt;b&gt;{‘OH’: 4x10^14, ‘CO’: 8x10^13}&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are some inference we can make from the above observation:&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A)&lt;/strong&gt; The bottleneck step(Voigt Broadening) loosely depends on &lt;code class="language-text"&gt;Spectral Range&lt;/code&gt;.&lt;br&gt;
&lt;strong&gt;B)&lt;/strong&gt; The complexity of Voigt Broadening needs to be modified because there is a difference of order of &lt;strong&gt;~10&lt;/strong&gt; in the Legacy Scaled value of OH and CO2.&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;
&lt;span class="gatsby-resp-image-wrapper" style="display: block; margin-left: auto; margin-right: auto;"&gt;
&lt;a class="gatsby-resp-image-link" href="https://anandkumar-blog.netlify.app/static/d9b32b4e96e6cd9a91016a49ad940239/0b533/Blog2.png" rel="noopener" style="display: block;" target="_blank"&gt;
&lt;span class="gatsby-resp-image-background-image" style="padding-bottom: 100%; display: block;"&gt;&lt;/span&gt;
&lt;img alt="Blog2" class="gatsby-resp-image-image" src="https://anandkumar-blog.netlify.app/static/d9b32b4e96e6cd9a91016a49ad940239/0b533/Blog2.png" style="width: 100%; height: 100%; margin: 0; vertical-align: middle;" title="Blog2"&gt;
&lt;/a&gt;
&lt;/span&gt;&lt;br&gt;
&lt;b&gt;Credits - Me :p&lt;/b&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p&gt;So in order to do some analysis, we first need data of different steps in the broadening phase and conditions of various Spectrum which brings me to the &lt;strong&gt;Code&lt;/strong&gt; part in &lt;strong&gt;Coding Period.&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;
&lt;h3&gt;Profiler Class&lt;/h3&gt;
&lt;p&gt;The aim of this class is to replace all the print statements by a common &lt;code class="language-text"&gt;start&lt;/code&gt;, &lt;code class="language-text"&gt;stop&lt;/code&gt;, &lt;code class="language-text"&gt;_print&lt;/code&gt; method. Earlier each step computational time was done using &lt;code class="language-text"&gt;time()&lt;/code&gt; library. Now the whole codebase is being refactored with the Profiler class that will do all the work based on the &lt;code class="language-text"&gt;verbose&lt;/code&gt; level. In addition to this the biggest benefit is that each step will be stored in a dictionary with its computational time that will help me gather data to find which step is in actual bottleneck and further which part of the function is the most expensive time wise. A simple example is below:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;if __debug__:
t0 = time()
..........
..........
if __debug__:
t1 = time()
.........
.........
if __debug__:
if self.verbose &amp;gt;= 3:
printg("... Initialized vectors in {0:.1f}s".format(t1 - t0))&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;self.profiler.start(
key="init_vectors", verbose=3, details="Initialized vectors"
)
.........
.........
self.profiler.stop("init_vectors")&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;So using a common key we can make it happen. This will be stored in the conditons of &lt;code class="language-text"&gt;Spectrum&lt;/code&gt; object in the &lt;code class="language-text"&gt;'profiler'&lt;/code&gt; key. All these Spectrums and their conditions can be exported using a &lt;a href="https://radis.readthedocs.io/en/latest/spectrum/spectrum.html#spectrum-database"&gt;SpecDatabase&lt;/a&gt;. This will create a csv file comprising of all the parameters of all Spectrums which will be useful in getting some insights.
-&amp;gt; &lt;a href="https://github.com/radis/radis/pull/286"&gt;PR LINK&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Digging in whiting_jit&lt;/h3&gt;
&lt;p&gt;Based on several benchmarks, it is estimated that around &lt;strong&gt;70-80%&lt;/strong&gt; time is spent on calculating the broadening. The broadening part has the following hierarchy:&lt;br&gt;
&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;_calc_broadening()
-&amp;gt; _calc_lineshape()
-&amp;gt; _voigt_broadening()
-&amp;gt; _voigt_lineshape()
-&amp;gt; whiting_jit()&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;On close inspection we observed that &lt;strong&gt;80-90%&lt;/strong&gt; time is spent on &lt;code class="language-text"&gt;whiting_jit&lt;/code&gt; process. Going further down in &lt;code class="language-text"&gt;whiting_jit&lt;/code&gt;, &lt;strong&gt;60-80%&lt;/strong&gt; time is spent on &lt;strong&gt;lineshape calculation.&lt;/strong&gt; Below is the formula:&lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;lineshape = (
(1 - wl_wv) * exp(-2.772 * w_wv_2)
+ wl_wv * 1 / (1 + 4 * w_wv_2)
# ... 2nd order correction
+ 0.016 * (1 - wl_wv) * wl_wv * (exp(-0.4 * w_wv_225) - 10 / (10 + w_wv_225))
)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The whole process can be divided into 4 parts:&lt;br&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;    part_1 =   (1 - wl_wv) * exp(-2.772 * w_wv_2)

part_2 =    wl_wv * 1 / (1 + 4 * w_wv_2)

# ... 2nd order correction
part_3 =  0.016 * (1 - wl_wv) * wl_wv * exp(-0.4 * w_wv_225)

part_4 =  - 10 / (10 + w_wv_225)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The complexity of each part comes out: &lt;br&gt;
&lt;b&gt;&lt;/b&gt;&lt;/p&gt;
&lt;div class="gatsby-highlight"&gt;&lt;pre class="language-text"&gt;&lt;code class="language-text"&gt;    o1 = broadening__max_width * n_lines / wstep

O(part_1) = n_lines * o1
O(part_2) = n_lines * 4 * o1
O(part_3) = (n_lines)**2 * o1
O(part_4) = o1 &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Running several benchmark showed us that &lt;strong&gt;part_3&lt;/strong&gt; takes the most time out of all steps. So clearly we can see that the complexity of Legacy method is not dependent on
Spectral Range but rather &lt;code class="language-text"&gt;Number of Calculated Lines&lt;/code&gt;,&lt;code class="language-text"&gt;broadening__max_width&lt;/code&gt; and &lt;code class="language-text"&gt;wstep&lt;/code&gt;. It may seem that the complexity of Legacy method is:&lt;br&gt;&lt;/p&gt;
&lt;p align="center"&gt;&lt;b&gt; n_lines^2 * broadening__max_width * n_lines / wstep&lt;/b&gt;&lt;/p&gt; &lt;br&gt;
&lt;p&gt;But inorder to prove this we need more benchmarks and evidence to verify this and it may involve normalization of all steps in lineshape calculation!&lt;br&gt; &lt;/p&gt;
&lt;p&gt;So the goal for the next 2 weeks is clear:&lt;br&gt;
&lt;b&gt;i)&lt;/b&gt; Refactor the entire codebase with Profiler.&lt;br&gt;
&lt;b&gt;ii)&lt;/b&gt; Find the complexity of &lt;strong&gt;Legacy Method&lt;/strong&gt; with the help of more benchmark and analysis.&lt;br&gt;
&lt;b&gt;iii)&lt;/b&gt; Do the same for &lt;strong&gt;LDM Method&lt;/strong&gt;!&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Ok I guess time’s up! See you after 2 weeks :)&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/06/20210621_2240_anandxkumar/</guid><pubDate>Mon, 21 Jun 2021 21:40:32 GMT</pubDate></item><item><title>Chapter 0: Prologue</title><link>http://openastronomy.org/Universe_OA/posts/2021/06/20210606_2240_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;Hi There and Namaste! This is going to be the second blog and first blog related to GSoC where I will be sharing my experience Community Bonding Period Experience with &lt;b&gt;Radis&lt;/b&gt;. Before moving ahead lets learn about GSoC and my perspective about it.&lt;/p&gt;
&lt;h3&gt;Google Summer of Code&lt;/h3&gt;
&lt;p&gt;GSoC or the way I like to say it &lt;strong&gt;(Great Summer Opportunity to Code ;)&lt;/strong&gt; is a program conducted and funded by Google to promote college students around the world to engage with Open Source Community and contribute to the organization for a tenure of 3 months. In the process, code is created and released for the world to see and use. But the main aim of GSoC is to promote students to stick to the organizations and help to grow the Open Source Community. This is a great initiative by Google that brings thousands of students every year and help them get an opportunity to peek into the world of open source development, learn new skills and also get compensated for the work, quite generously.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;I remember during second year of my college, it was around end of March and my roommate was applying for GSoC and I was like what is this program? There I got to know about it but since the deadline was near I was afraid of doing all the stuffs in a week of time, so I didn’t apply for it. Fast forwarding to next year, I was prepared enough this time and I feel priviledged to be a part of GSoC as part of OpenAstronomy. &lt;/p&gt;
&lt;h3&gt;My GSoC Project&lt;/h3&gt;
&lt;p&gt;I’m part of &lt;b&gt;&lt;a href="https://github.com/radis/radis"&gt;Radis&lt;/a&gt;&lt;/b&gt; organization which is a sub-org of &lt;a href="https://github.com/OpenAstronomy"&gt;OpenAstronomy&lt;/a&gt;. Radis is a fast line-by-line code used to synthesize high-resolution infrared molecular
spectra and a post-processing library to analyze spectral lines. It can synthesize absorption
and emission spectrum for multiple molecular species at both equilibrium and
non-equilibrium conditions.&lt;br&gt;
Radis computes every spectral line (absorption/emission) from the molecule considering
the effect of parameters like Temperature, Pressure. Due to these parameters, we don’t get
a discrete line but rather a shape with a width. This is called line broadening and for any spectral synthesis code, this is the bottleneck step. Ok let us C what my GSoC project is all about! &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Radis has 2 methods to calculate the lineshape of lines.&lt;br&gt;
● Legacy Method&lt;br&gt;
● DLM Method&lt;br&gt;&lt;/p&gt;
&lt;p&gt;The goal of this project is to derive an equation comprising all parameters that affect the
performance for calculating Voigt broadening by running several benchmarks for different
parameters involved in the calculation of lineshapes to check their significance in
computation time. Then we need to find the critical value for the derived equation (&lt;code class="language-text"&gt;Rc&lt;/code&gt;)
which will tell us which optimization technique to select based on the computed &lt;code class="language-text"&gt;R&lt;/code&gt; value in
&lt;b&gt;calc_spectrum()&lt;/b&gt;. An &lt;code class="language-text"&gt;optimization = "auto"&lt;/code&gt; will be added that will choose the best method based on the parameters provided.&lt;/p&gt;
&lt;h3&gt;Community Bonding Period&lt;/h3&gt;
&lt;p&gt;The first phase of GSoC is the &lt;b&gt;Community Bonding Period&lt;/b&gt; which is a 3 weeks long period. Its main aim is allow the student to get familiar with the community and the codebase. It serves as a warm-up period before the coding period. The first thing I did was that I went though the original Radis &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S0022407318305867?via%3Dihub"&gt;paper&lt;/a&gt; and also the DLM implementation &lt;a href="https://ui.adsabs.harvard.edu/abs/2021JQSRT.26107476V/abstract"&gt;paper&lt;/a&gt; because our project objective is based on these 2 implementations. It helped me understand the main purpose of RADIS, its architecture and the science behind different steps of both equilibrium and non-equilibrium spectrum, though I have to accept these papers are way too technical for me :p (Complex Spectroscopy related formulas).&lt;br&gt; I believed inorder to get myself ready for the coding period, I shall focus on solving some related issues to make me more familiar with the codebase.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;In order to compute any spectrum we need to determine several parameters like: minimum-maximum wavenumber, molecule, Temperature of gas, mole fraction, wstep, etc.&lt;br&gt;
&lt;code class="language-text"&gt;wstep&lt;/code&gt; determines the wavenumber grid’s resolution. Smaller the value, higher the resolution and vice-versa. By default radis uses &lt;code class="language-text"&gt;wstep=0.01&lt;/code&gt;. You can manually set the wstep value in &lt;b&gt;calc_spectrum()&lt;/b&gt; and &lt;strong&gt;SpectrumFactory&lt;/strong&gt;. To get more accurate result you can further reduce the value, and to increase the performance you can increase the value.&lt;/p&gt;
&lt;p&gt;Based on wstep, it will determine the number of gridpoints per linewidth. To make sure that there are enough gridpoints, Radis will raise an &lt;strong&gt;Accuracy Warning&lt;/strong&gt;. If number of gridpoints are less than &lt;code class="language-text"&gt;GRIDPOINTS_PER_LINEWIDTH_WARN_THRESHOLD&lt;/code&gt; and raises an &lt;strong&gt;Accuracy Error&lt;/strong&gt; if number of gridpoints are less than &lt;code class="language-text"&gt;GRIDPOINTS_PER_LINEWIDTH_ERROR_THRESHOLD&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So inorder to select the optimum value of &lt;code class="language-text"&gt;wstep&lt;/code&gt; I had to refactor the codebase such that we could compute the minimum FWHM (&lt;code class="language-text"&gt;min_width&lt;/code&gt;) value after calculating the HWHM of all lines and and set &lt;code class="language-text"&gt;wstep = min_width / GRIDPOINTS_PER_LINEWIDTH_WARN_THRESHOLD&lt;/code&gt;. All &lt;code class="language-text"&gt;wstep&lt;/code&gt; dependent parameters had to be refactored to make sure they are not being called before the calculating &lt;code class="language-text"&gt;min_width&lt;/code&gt;. At the end this feature was successfully merged in the develop branch of Radis and now users can use &lt;code class="language-text"&gt;wstep = "auto"&lt;/code&gt; to automatically get the optimal value of &lt;code class="language-text"&gt;wstep&lt;/code&gt;. This feature will be available from version &lt;b&gt;0.9.30&lt;/b&gt;. Here is the &lt;a href="https://github.com/radis/radis/pull/271"&gt;link&lt;/a&gt; of the merged PR.&lt;/p&gt;
&lt;p&gt;In short, the Community Bonding Period has been great and I have learned alot about Radis during this time. In the next 2 weeks I will be focussing on building a benchmarking framework and run various benchmarks for both Legacy and DLM method and determine the most influential paramters for performance.&lt;/p&gt;
&lt;p&gt;I’m very excited for the upcoming months. I know that this summer is going to be a life long experience and I’m really looking forward to do amazing things for the community and want to thank Google, OpenAstronomy, Radis and my mentors &lt;a href="https://github.com/erwanp"&gt;Erwan Pannier&lt;/a&gt;, &lt;a href="https://github.com/dcmvdbekerom"&gt;Dirk van den Bekerom&lt;/a&gt; and &lt;a href="https://github.com/pkj-m"&gt;Pankaj Mishra&lt;/a&gt; for this opportunity.
I’m ready for this amazing adventure.&lt;/p&gt;
&lt;p align="center"&gt;
&lt;b&gt;LETS DO THIS&lt;/b&gt;&lt;br&gt;
&lt;img src="https://anandkumar-blog.netlify.app/2b4e6a4b663f4bc49d559484b8dd37b1/Start.gif"&gt;&lt;br&gt;
ps: Am a huge Spiderman Fan :p
&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/06/20210606_2240_anandxkumar/</guid><pubDate>Sun, 06 Jun 2021 21:40:32 GMT</pubDate></item><item><title>print(" Hello World!!! ")</title><link>http://openastronomy.org/Universe_OA/posts/2021/05/20210518_2240_anandxkumar/</link><dc:creator>anandxkumar</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey everyone &lt;b&gt;Anand Kumar&lt;/b&gt; this side. This is going to be a series of blogs where I will cover my Summer Journey with &lt;b&gt;Radis&lt;/b&gt; organization as a part of Google Summer of Code. Welcome to my first blog where I will be introducing myself coz that is kind of necessary :p. I’m a Junior from National
Institute of Technology, Hamirpur, India currently pursuing my BTech in Computer Science and Engineering.&lt;br&gt;&lt;/p&gt;
&lt;p&gt;I am a geek. I love life, computers and everything in between!&lt;br&gt;
&lt;!-- TEASER_END --&gt;
I have been coding since my school days and soon realized that man this thing is so cool!
I am an A.I. enthusiast and have made various projects related to Data Analysis, Machine Learning, Deep Learning
and Web Development. Also I have completed a Data Analytics Internship at Pikkal &amp;amp; Co, Singapore and a
Deep Learning Internship at Mavoix Solutions Pvt Ltd, Bangalore.&lt;br&gt;
Currently I’m a Student Developer at OpenAstronomy organization as a part of Google Summer of Code 2021. &lt;br&gt;&lt;/p&gt;
&lt;p&gt;Wanna know a less known fact, I’m a huge hardcore video gamer! If I’m not coding, I will probably be killing some time
on my laptop or my Playstation console ;)&lt;/p&gt;
&lt;p&gt;Wanna know more about me and my work? Below are some links, do check out;)&lt;br&gt;
&lt;a href="https://www.linkedin.com/in/anand-kumar-83896717a/"&gt;LinkedIn&lt;/a&gt; | &lt;a href="https://github.com/anandxkumar"&gt;github&lt;/a&gt;
| &lt;a href="https://anandkumar.netlify.app/"&gt;Portfolio&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Also one huge shout out to the guys at &lt;b&gt;GatsbyJS&lt;/b&gt; for providing such an amazing blogging template(keep it simple and clean, they say!).
The biggest advantage of this template is that every blog is written in &lt;b&gt;Markdown&lt;/b&gt;. So its gives alot of flexibility and functionality
to the user to edit their texts. Plus their templates codebase is easy to understand so anyone can just clone and get started!&lt;/p&gt;
&lt;p&gt;Anyways I guess this should wrap up this blog. See you in the next one where I will be starting my GSoC journey and discuss my project ;)&lt;br&gt;
Till then take care and ba-bye :)&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2021/05/20210518_2240_anandxkumar/</guid><pubDate>Tue, 18 May 2021 21:40:32 GMT</pubDate></item></channel></rss>