<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy</title><link>http://openastronomy.org/Universe_OA/</link><description>This is an aggregator of openastronomy people</description><atom:link href="http://openastronomy.org/Universe_OA/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Fri, 17 Jul 2020 01:39:54 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Week 5 &amp; 6: Half-time</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200715_0456_sahilyadav27/</link><dc:creator>Sahil Yadav</dc:creator><description>&lt;div&gt;&lt;p&gt;The first evaluation is successfully complete!&lt;/p&gt;
&lt;p&gt;In the last blog post, I discussed adding a script to the DL1DataHandler to convert ROOT files to HDF5. But, in order to maintain symmetry with the current DL1DataWriter, we decided to instead create a MAGICEventSource from this root2hdf5 format that initializes the DL1 data container with ROOT data and then is sent to the CTAMLDataDumper to dump this data into an HDF5 file. This will be analogous to the SimTelEventSource that is currently being used for CTA data from simtel files.&lt;/p&gt;
&lt;p&gt;So, I have been working on creating this MAGICEventSource. The basic code for the class structure is complete, and the containers are initialized correctly. All that remains now is to add some code to the DL1DataWriter and CTAMLDataDumper to accept and recognize MAGIC data and use the MAGICEventSource instead of the SimTelEventSource.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*EOSlgwziXKXKk76EYbnN2A.png"&gt;&lt;/figure&gt;&lt;p&gt;In the meantime, I also adapted the generate_runlist script to create runlists specifically for MAGIC data, since the MAGICEventSource reads file masks instead of a couple of M1 and M2 files for each observation.&lt;/p&gt;
&lt;p&gt;Hence, both these changes will be pushed soon to the main repository and then we can start working on reading VERITAS data similarly as well as training MAGIC data using CTLearn models.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=e343ac6bd699" width="1" height="1"&gt;&lt;/div&gt;</description><category>CTLearn</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200715_0456_sahilyadav27/</guid><pubDate>Wed, 15 Jul 2020 03:56:26 GMT</pubDate></item><item><title>GSOC 2020: End of the First Half</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_2212_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/0*L9pxwg-v0q0SppOR.jpg"&gt;&lt;figcaption&gt;Comet C/2020 F3 (NEOWISE) will be visible in India for the next 20 days!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So now I’m halfway through the Summer of Code Journey. The last two weeks have been full of code reviews, code refactoring, and documenting stuff. I also helped new contributors to the SunPy to get them started. Thus I interacted more with the community this time.&lt;/p&gt;
&lt;h4&gt;Making HEC Fido Compatible&lt;/h4&gt;&lt;p&gt;HEC stands for &lt;strong&gt;Heliophysics Event Catalogue&lt;/strong&gt;. For your information, Heliophysics events are a large variety of phenomena that:&lt;/p&gt;
&lt;ul&gt;&lt;li&gt;originate or occur on the Sun.&lt;/li&gt;&lt;li&gt;Propagate through the interplanetary medium.&lt;/li&gt;&lt;li&gt;Interact with the geospace and planetary analogs.&lt;/li&gt;&lt;/ul&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/0*7_zVGR8NSlvJ4vOi.jpg"&gt;&lt;figcaption&gt;An illustration of an Heliophysics Event| Earth’s magnetic field shielding our planet from solar particles. Credit: NASA/GSFC/SVS&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;HEC allows complex searches for events stored in indexed catalogs. SunPy has a HECClient which allows you to interface with Helio web services.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;In &lt;a href="https://github.com/sunpy/sunpy/pull/4358"&gt;PR #4358&lt;/a&gt; to enable Helio metadata searches with Fido (Federated Internet Data Obtainer), I made it inherit ~sunpy.net.BaseClient and overwrote a few methods for the client. New hec-specific attrs like MaxRecords, TableName, and Catalogue were defined to make _can_handle_query() work.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/07/20200714_2212_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/8cebddc67806c7e7130b0e70722fa975/href"&gt;https://medium.com/media/8cebddc67806c7e7130b0e70722fa975/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;A new class HECResponse was added to contain the responses retrieved after the search is executed. This made helio queries possible through Fido, although there are yet a lot of things that can be improved.&lt;/p&gt;
&lt;h4&gt;Updated tests for client redesign!&lt;/h4&gt;&lt;p&gt;&lt;a href="https://github.com/sunpy/sunpy/pull/4321"&gt;PR #4321&lt;/a&gt; (nice number!) is a major refactoring pull request for sunpy’s dataretriever module. So far it has negative 1500 lines of code.&lt;/p&gt;
&lt;p&gt;Finally SUVIClient was generalized which was the toughest of its counterparts. It supports the highest number of attributes. These are `Time`, Source, Instrument, Phsyobs, Provider, Level, Wavelength, and SatelliteNumber.&lt;/p&gt;
&lt;p&gt;The row data for the response table can either be contained as a dictionary or as data members of a class. A small hack made me achieve both. QueryResponseBlock was re-welcomed to the client.py. It now inherits OrderedDict and has dict values as class data members too. Passed Ordered Dictionary was used to update its self.__dict__.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/07/20200714_2212_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/b8dae93e3cdf41797f7797b54de3573b/href"&gt;https://medium.com/media/b8dae93e3cdf41797f7797b54de3573b/href&lt;/a&gt;&lt;/iframe&gt;&lt;h4&gt;Other Stuff&lt;/h4&gt;&lt;p&gt;My mentor made a list of 38 issues in Sunpy that were related to the project. I went through all of them and labeled them based on the submodules they are concerned with, how much I understand them, and their relevance with the GSoC project. Some of them were overlapping with things in my mind, so existing discussions on them shall be really helpful for me.&lt;/p&gt;
&lt;p&gt;I also spent time on writing the guidelines to extend Fido and how to add new sources to it, based on the redesign.&lt;/p&gt;
&lt;p&gt;Looking forward to capturing the comet in the coming days and having an awesome second half!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CARPE NOCTEM!&lt;/strong&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=ec4589cc452f" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_2212_abhijeetmanhas/</guid><pubDate>Tue, 14 Jul 2020 21:12:28 GMT</pubDate></item><item><title>Detour: A Reflection</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_1950_raahul-singh/</link><dc:creator>Raahul Singh</dc:creator><description>&lt;div&gt;&lt;h5&gt;Look at where we are, look at where we started.&lt;/h5&gt;&lt;p&gt;This post marks the halfway point of the GSoC journey. Instead of my usual full blown update posts, I want to celebrate this milestone with just a small, solemn reflection on the work we have accomplished so far.&lt;/p&gt;
&lt;p&gt;We have the Search Events up and running that maps the Sunspotter observation to the &lt;a href="https://www.lmsal.com/hek/"&gt;Heliophysics Events Knowledgebase (HEK)&lt;/a&gt;. This has broadened our dataset and will allow us to do timeseries analysis in the near future.&lt;/p&gt;
&lt;p&gt;We also have a Sunspotter class that handles the various CSVs and the AR FITS files.&lt;br&gt;
&lt;!-- TEASER_END --&gt;
The Sunspotter class allows us to rotate each observation to the nearest midnight, and convert observations from theHelioprojective frame to HeliographicStonyHurst frame.&lt;/p&gt;
&lt;p&gt;We have a few Neural Nets showing good prediction results.&lt;/p&gt;
&lt;p&gt;But all of these are technical details.&lt;/p&gt;
&lt;p&gt;What really has been a strangely new experience for me is the sense of collaboration. My mentors do not treat this as a project that I have to do and they have to guide. I’ve interacted with a lot of students from a lot of different orgs in the past few two and a half months. OpenAstronomy is different and unique in its sense of prioritising community.&lt;br&gt;
I know it’s a running theme, but I can’t find the words to describe how grateful I am, how exciting and fun this project has been because of my mentors and the SunPy community at large.&lt;br&gt;
Looking forward to the next half of the journey! :)&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=6da1c0609462" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200714_1950_raahul-singh/</guid><pubDate>Tue, 14 Jul 2020 18:50:42 GMT</pubDate></item><item><title>1.5 months later</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200713_1527_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;p&gt;Time flies. &lt;br&gt;
It feels like yesterday that I joined DiRAC virtually and now that I look back, already a month and a half!&lt;/p&gt;
&lt;p&gt;It has been a really amazing journey so far and I have learned a lot, wrote a lot of code and have worked with some really nice people.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;The most challenging aspect was connecting everything and putting everything together.&lt;/p&gt;
&lt;p&gt;I was working on an Ipython kernel extension, a Jupyter Notebook Front end extension, and on a python backend extension.&lt;/p&gt;
&lt;p&gt;I had to integrate REST APIs to connect the Front end with the backend and create socket communications to connect the front end with the ipython kernel.&lt;/p&gt;
&lt;p&gt;It was fun and challenging.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The features I added this week are:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Saving the state of the extension across multiple devices&lt;/li&gt;&lt;li&gt;Customizing the cluster config from the front end&lt;/li&gt;&lt;/ol&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=7bfd02021440" width="1" height="1"&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200713_1527_techguybiswa/</guid><pubDate>Mon, 13 Jul 2020 14:27:50 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 2.1</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200712_2340_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;The second coding period is now officially halfway through. Since the end of the first coding period, I have been working on both the &lt;a href="https://github.com/glue-viz/glue/pull/2156"&gt;1D Profile viewer&lt;/a&gt; and &lt;a href="https://github.com/glue-viz/glue/pull/2161"&gt;WCS autolinking&lt;/a&gt;. Since much has been discussed about the 1D Profile viewer of glue and now that it is finally working, let me take the opportunity to talk about the wcs-autolinking PR.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Problem statement&lt;/strong&gt;: Originally the wcs-autolinking only worked for some cases, for example for the spatial axes but not for the temporal and wavelength axes in the scenario where the dimensions of the two wcs objects of the data cubes being matched up do not match. This is highly undesirable and needs generalizing while conforming to &lt;a href="https://github.com/astropy/astropy-APEs/blob/master/APE14.rst"&gt;APE 14&lt;/a&gt;, where the issue of a shared Python interface for World Coordinate Systems is discussed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The solution&lt;/strong&gt;: So we rewrote the code. Most of the celestial code has been retained, with some new additions to add linking for the other dimensions. The code rewritten is as follows:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;pre&gt;# Case for when the axes don't exactly match up&lt;br&gt;
if not forwards or not backwards:&lt;/pre&gt;&lt;pre&gt;    # A generalized APE 14-compatible way&lt;br&gt;
# Handle also the extra-spatial axes such as those of the time and wavelength dimensions&lt;/pre&gt;&lt;pre&gt;    if not wcs1.has_celestial or not wcs2.has_celestial:&lt;br&gt;
raise IncompatibleWCS("Can't create WCS link between {0} and {1}".format(data1.label, data2.label))&lt;/pre&gt;&lt;pre&gt;    try:&lt;br&gt;
wcs1_celestial = wcs1.celestial&lt;br&gt;
wcs2_celestial = wcs2.celestial&lt;br&gt;
wcs1_celestial_axis_physical_types = wcs1.celestial.world_axis_physical_types&lt;br&gt;
wcs2_celestial_axis_physical_types = wcs2.celestial.world_axis_physical_types&lt;br&gt;
print('wcs1.celestial.world_axis_physical_types', wcs1_celestial_axis_physical_types)&lt;br&gt;
print('wcs2.celestial.world_axis_physical_types', wcs2_celestial_axis_physical_types)&lt;br&gt;
except Exception:&lt;br&gt;
raise IncompatibleWCS("Can't create WCS link between {0} and {1}".format(data1.label, data2.label))&lt;/pre&gt;&lt;pre&gt;    cids1 = data1.pixel_component_ids&lt;br&gt;
cids1_celestial = [cids1[wcs1.wcs.naxis - wcs1.wcs.lng - 1],&lt;br&gt;
cids1[wcs1.wcs.naxis - wcs1.wcs.lat - 1]]&lt;br&gt;
slicing_axes_celestial1 = [cids1_celestial[0].axis, cids1_celestial[1].axis]&lt;br&gt;
slicing_axes_celestial1 = sorted(slicing_axes_celestial1, key=str, reverse=False)&lt;br&gt;
print('slicing_axes_celestial1', slicing_axes_celestial1)&lt;/pre&gt;&lt;pre&gt;    if wcs1_celestial.wcs.lng &amp;gt; wcs1_celestial.wcs.lat:&lt;br&gt;
cids1_celestial = cids1_celestial[::-1]&lt;/pre&gt;&lt;pre&gt;    cids2 = data2.pixel_component_ids&lt;br&gt;
cids2_celestial = [cids2[wcs2.wcs.naxis - wcs2.wcs.lng - 1],&lt;br&gt;
cids2[wcs2.wcs.naxis - wcs2.wcs.lat - 1]]&lt;br&gt;
slicing_axes_celestial2 = [cids2_celestial[0].axis, cids2_celestial[1].axis]&lt;br&gt;
slicing_axes_celestial2 = sorted(slicing_axes_celestial2, key=str, reverse=False)&lt;br&gt;
print('slicing_axes_celestial2', slicing_axes_celestial2)&lt;/pre&gt;&lt;pre&gt;    if wcs2_celestial.wcs.lng &amp;gt; wcs2_celestial.wcs.lat:&lt;br&gt;
cids2_celestial = cids2_celestial[::-1]&lt;/pre&gt;&lt;pre&gt;    # Collect all apparently matching axes in two lists for the two wcs objects being linked up&lt;br&gt;
wcs1_sliced_physical_types = wcs1_celestial_axis_physical_types&lt;br&gt;
slicing_axes1 = slicing_axes_celestial1&lt;br&gt;
wcs2_sliced_physical_types = wcs2_celestial_axis_physical_types&lt;br&gt;
slicing_axes2 = slicing_axes_celestial2&lt;br&gt;
for i, physical_type1 in enumerate(wcs1.world_axis_physical_types):&lt;br&gt;
for j, physical_type2 in enumerate(wcs2.world_axis_physical_types):&lt;br&gt;
if physical_type1 == physical_type2:&lt;br&gt;
if physical_type1 not in wcs1_sliced_physical_types:&lt;br&gt;
slicing_axes1.append(wcs1.world_n_dim - i - 1)&lt;br&gt;
wcs1_sliced_physical_types.append(physical_type1)&lt;br&gt;
if physical_type2 not in wcs2_sliced_physical_types:&lt;br&gt;
slicing_axes2.append(wcs2.world_n_dim - j - 1)&lt;br&gt;
wcs2_sliced_physical_types.append(physical_type2)&lt;/pre&gt;&lt;pre&gt;    slicing_axes1 = sorted(slicing_axes1, key=str, reverse=True)&lt;br&gt;
slicing_axes2 = sorted(slicing_axes2, key=str, reverse=True)&lt;/pre&gt;&lt;pre&gt;    print('slicing_axes1', slicing_axes1)&lt;br&gt;
print('slicing_axes2', slicing_axes2)&lt;/pre&gt;&lt;pre&gt;    print('wcs1_sliced_physical_types', wcs1_sliced_physical_types)&lt;br&gt;
print('wcs2_sliced_physical_types', wcs2_sliced_physical_types)&lt;/pre&gt;&lt;pre&gt;    # Generate slices for the wcs slicing&lt;br&gt;
slices1 = (slice(None),) * wcs1.world_n_dim&lt;br&gt;
slices2 = (slice(None),) * wcs2.world_n_dim&lt;/pre&gt;&lt;pre&gt;    slices1 = sorted(list(slices1))&lt;br&gt;
slices2 = sorted(list(slices2))&lt;/pre&gt;&lt;pre&gt;    for i in range(wcs1.world_n_dim):&lt;br&gt;
if i in slicing_axes1:&lt;br&gt;
pass&lt;br&gt;
else:&lt;br&gt;
slices1[i] = 0&lt;/pre&gt;&lt;pre&gt;    for i in range(wcs2.world_n_dim):&lt;br&gt;
if i in slicing_axes2:&lt;br&gt;
pass&lt;br&gt;
else:&lt;br&gt;
slices2[i] = 0&lt;/pre&gt;&lt;pre&gt;    wcs1_sliced = wcs1[tuple(slices1)]&lt;br&gt;
wcs2_sliced = wcs2[tuple(slices2)]&lt;/pre&gt;&lt;pre&gt;    cids1 = data1.pixel_component_ids&lt;br&gt;
cids1_sliced = [cids1[x] for x in slicing_axes1]&lt;br&gt;
cids1_sliced = sorted(cids1_sliced, key=str, reverse=True)&lt;/pre&gt;&lt;pre&gt;    cids2 = data2.pixel_component_ids&lt;br&gt;
cids2_sliced = [cids2[x] for x in slicing_axes2]&lt;br&gt;
cids2_sliced = sorted(cids2_sliced, key=str, reverse=True)&lt;/pre&gt;&lt;pre&gt;    pixel_cids1, pixel_cids2, forwards, backwards = get_cids_and_functions(&lt;br&gt;
wcs1_sliced, wcs2_sliced, cids1_sliced, cids2_sliced)&lt;/pre&gt;&lt;pre&gt;    self._physical_types_1 = wcs1_sliced_physical_types&lt;br&gt;
self._physical_types_2 = wcs2_sliced_physical_types&lt;/pre&gt;&lt;pre&gt;    if pixel_cids1 is None:&lt;br&gt;
raise IncompatibleWCS("Can't create WCS link between {0} and {1}".format(data1.label, data2.label))&lt;/pre&gt;&lt;p&gt;After checking with the tests written previously the code was modified before it is confirmed with pytest that all CI tests are now passing.&lt;/p&gt;
&lt;p&gt;Now we can link up wcs axes of the same physical types of two data cubes having different dimensions with no problems, illustrated as follows:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Ffgo6t1M0ah9UcCyeLVdfg.png"&gt;&lt;/figure&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=620347ad3f8d" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200712_2340_kakirastern/</guid><pubDate>Sun, 12 Jul 2020 22:40:22 GMT</pubDate></item><item><title>GSoC 2020: Blog 2 - Parameters and incompatible units</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/</link><dc:creator>Jyotirmaya Shivottam</dc:creator><description>&lt;div&gt;&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#progress-so-far" class="anchor"&gt;
&lt;/a&gt;
&lt;!-- TEASER_END --&gt;
Progress so far...
&lt;/h3&gt;

&lt;p&gt;Over the last two weeks, PR &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/512"&gt;#512&lt;/a&gt; was finalized and merged into EinsteinPy. With it, the big refactor of the &lt;code&gt;metric&lt;/code&gt; module is over. As I had mentioned in my last blog, this PR adds a core structure to the &lt;code&gt;metric&lt;/code&gt; module, with the &lt;code&gt;metric.BaseMetric&lt;/code&gt; class, and adds some new functionalities, like support for Kerr-Schild Perturbations. Also, 7 issues, big and small, were fixed in this PR, ranging from purely semantic issues to mathematical inaccuracies. One of the important ones was Issue &lt;a href="https://github.com/einsteinpy/einsteinpy/issues/514"&gt;#514&lt;/a&gt;, the distinction between Rotational Length Parameter,

&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and Dimensionless Spin Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, which has had a cascade effect across the codebase. It is worth a discussion, as it has led to many changes across the numerical side of EinsteinPy.&lt;/p&gt;




&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#whats-all-the-fuss-about" class="anchor"&gt;
&lt;/a&gt;
What's all the fuss about?
&lt;/h3&gt;

&lt;p&gt;The expressions for the Rotational Length Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, and Spin Parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, are as follows:&lt;br&gt;

&lt;/p&gt;
&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=JMc
\alpha = \frac{J}{Mc}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;

&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;a=JJMax=JcGM2
a = \frac{J}{J_{Max}} = \frac{Jc}{GM^2}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;a&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;x&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;
which give us:&lt;br&gt;

&lt;div class="katex-element"&gt;
&lt;span class="katex-display"&gt;&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=GMc2a
\boxed{
\alpha = \frac{GM}{c^2}a
}
&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="boxpad"&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="stretchy fbox"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/div&gt;
&lt;br&gt;
Here,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;J,MJ, M &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
denote the angular momentum and mass of the gravitating body (for example, black holes), respectively, while
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;G,cG, c &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mpunct"&gt;,&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
denote the Gravitational Constant and speed of light in vacuum, respectively. As the expression for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
tells us, it is a constraint on the body's angular momentum. It might seem arbitrary at first, as in classical physics, we do not bother with such constraints and
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;JJ &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
is not limited. However, in General Relativity, especially in the context of how black holes are formed, or more appropriately, how we hypothesize their formation, we find that, for certain solutions to the Einstein Field Equations, like the Kerr solutions (rotating black hole), a maximum limit needs to be placed on the black hole angular momentum. This is a direct consequence of the efforts to contain the causality-breaking nature of black hole singularities, especially a naked singularity. As the name suggests, naked singularities are not covered by an Event Horizon and so, they would be observable from outside the black hole. This breaks the framework of GR, as no deterministic predictions about the future evolution of spacetime can be made near a singularity. Note that, GR breaks for covered singularities as well, but causality remains intact, because the spacetime within the event horizon is not viewable or approachable from outside. To complicate things further, GR, as is, does not preclude the existence of naked singularities. All of this led to much deliberation on this issue and ultimately, in 1969, Sir Roger Penrose postulated the (Weak) Cosmic Censorship Hypothesis. This hypothesis aims to alleviate the issue with physical singularities by claiming that naked or observable singularities cannot exist in the universe, as the deterministic nature of general relativity will fall apart otherwise. It is worth mentioning that, while this is still a conjecture, we are yet to detect naked singularities through astronomical observations. Also, in order to work in the theoretical framework of GR and make physical predictions using GR, one needs to circumvent the problem of naked singularities and this is where
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
comes in for rotating black holes, like in the Kerr solution. To ensure that, the black hole singularity has an event horizon, we must constrain
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;JJ &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and this is done by the spin parameter,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. Here, for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;∣J∣≤GM2c|J| \leq \frac{GM^2}{c} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;≤&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;G&lt;/span&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size3 size1 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, the solution has an event horizon, while for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;∣J∣&amp;gt;GM2c|J| &amp;gt; \frac{GM^2}{c} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mord mathdefault"&gt;J&lt;/span&gt;&lt;span class="mord"&gt;∣&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;&amp;gt;&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;c&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;G&lt;/span&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size3 size1 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, the solution possesses naked singularities, which we must exclude, due to reasons discussed above. This condition is obtained by solving for singularities in the Kerr solutions.

&lt;p&gt;As for
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, it is a convenient length parameter, that helps in making equations shorter to write.&lt;/p&gt;

&lt;p&gt;Physics aside, the issue, as mentioned in &lt;a href="https://github.com/einsteinpy/einsteinpy/issues/514"&gt;#514&lt;/a&gt;, was that the modules in EinsteinPy do not differentiate between
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
and
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. This is due to the intermixing of Geometrized quantities with that in SI units. In geometrized units,
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;G=c=1G = c = 1 &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;G&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;c&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;1&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
, making
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α=a=JM\alpha = a = \frac{J}{M} &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;J&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
. However, in SI, this is not the case. EinsteinPy works purely in SI and this issue is an artifact from the changes around unit conversions. This issue has been fixed now, after &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/512"&gt;#512&lt;/a&gt;, with
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
being one of the defining parameters in rotating spacetimes, while
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;α\alpha &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;α&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
is calculated using
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;aa &lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord mathdefault"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
.&lt;/p&gt;

&lt;p&gt;As I mentioned earlier, this issue has caused a ripple effect across the numerical side of EinsteinPy. It has highlighted some problems, around systems of unit, in the definition of a few core methods in the &lt;code&gt;metric&lt;/code&gt; classes, as well as the &lt;code&gt;coordinates&lt;/code&gt; module.&lt;/p&gt;

&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/#until-next-time" class="anchor"&gt;
&lt;/a&gt;
Until next time...
&lt;/h3&gt;

&lt;p&gt;I am currently working on fixing the aforementioned issues, as well as refactoring the &lt;code&gt;coordinates&lt;/code&gt; module. To be specific, I am working on adding support for 4-Vector calculations and Kerr-Schild coordinates to the &lt;code&gt;coordinates&lt;/code&gt; module. The latter would make use of the Kerr-Schild perturbation functionality of the &lt;code&gt;metric&lt;/code&gt; module and help in modularizing the definition of new metric classes. I will discuss Kerr-Schild perturbations and the so-called Kerr-Schild form of the metric tensor in my next blog. &lt;/p&gt;




&lt;p&gt;In the meantime, here's a piece of trivia, related to the Cosmic Censorship Hypothesis.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In 1991, John Preskill and Kip Thorne bet against Stephen Hawking that the hypothesis was false. Hawking conceded the bet in 1997, due to the discovery of some special situations, that violated the hypothesis, which he characterized as "technicalities". Hawking later reformulated the bet to exclude those technicalities. The revised bet is still open, with the prize being "clothing to cover the winner's nakedness".&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The description of the original bet can be found &lt;a href="http://www.theory.caltech.edu/people/preskill/old_naked_bet.html"&gt;here&lt;/a&gt;, while that of the new bet can be found &lt;a href="http://www.theory.caltech.edu/people/preskill/new_naked_bet.html"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/div&gt;</description><category>EinsteinPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200630_0954_jes24/</guid><pubDate>Tue, 30 Jun 2020 08:54:19 GMT</pubDate></item><item><title>Google Summer of Code - Blog #2!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hello! This blog marks the end of the first phase of Google Summer of Code. The journey so far has been challenging but also extremely rewarding. The knowledge gained as a by-product of the work I’ve been doing on my project so far is unbelievable, but more importantly has been a better, more pleasant experience compared to the traditional system of gaining knowledge by reading books and tutorials. In this blog, I will be summarising the work that I’ve been doing for the past 2 weeks, update the readers on my current position and give an idea of what lies ahead.&lt;/p&gt;

&lt;p&gt;As I discussed in my previous blog, the work for the first two weeks mostly involved using Cython to translate the host code into something which could be compiled to provide better performance. More importantly, apart from the Cython part, I had to also start working on porting the kernels from their pure CUDA C form into something which Python/Cython could also understand. While the actual work to do so did not take long or came across as very challenging, the most difficult part in the whole process, undeniably, was to get the two, Cython and CuPy to talk to one another.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;When I finished writing the previous blog, I was still left with quite a large volume of host code which was waiting to be converted to the Cython equivalent. Going through the previous blog, I’d like to make one correction in the part where I said I found Cython quite confusing. Infact, calling it a correction would not be correct. Instead, I should say that Cython isn’t actually all that difficult as I might have made it look like in the last blog. After a fair amount of reading and writing code in Cython, I think the developers of Cython have actually done an excellent job. After the initial barrier is crossed (and it happens fairly naturally), writing Cython code feels just as normal and second nature as pure Python code. Infact, I’d go so far as to claim that Cython feels more natural to me now than Python itself because of my previous experience in C++. This newly found familiarity allowed me to proceed quite quickly with this part of the project. The only problems that I encountered were: (1) the inter-conversion between arrays/vectors and pointers that we are used to in C++ is not possible in case of Cython, and this resulted in me being forced to make some slight changes in the host code, and (2) using structs in Cython isn’t as direct and straighforward as in C/C++. The reason behind this is the fact that Cython tries to estabilish relationships between C-type data structures and Python objects. While this is quite trivial for objects of types int, float, char, and even arrays to some extent, in case of structs this is nowhere near as easy. While I am sure there must have been some hacky way around this problem too, me and my mentors decided it is not something worth wasting time on, and thus we decided to bypass all structs and directly used each of their attributes as variables with the struct name attached as prefix, so &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.shared_size&lt;/code&gt; became &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h_shared_size&lt;/code&gt;. While not the exact same thing, it allowed us to achieve the same objective without a lot of modifications to the code, either in terms of declaration or syntax. The only downside to this whole approach was that it made the code quite verbose, as instead of passing a single struct with 10 fields inside it, we were forced to pass 10 variables for each struct. This unique problem was further aggravated as we were using global variables instead of passing them around as arguments, and as every Python user would know, this meant adding the line &lt;code class="language-plaintext highlighter-rouge"&gt;global &amp;lt;varname&amp;gt;&lt;/code&gt; before every function body, which when done for every method and every variable, meant a lot of lines which could have been avoided. Apart from these two major issues and couple of minor problems here and there, the whole process was fairly straight forward. At the end of this step, I was left with a Cython file which compiled just fine, but didn’t really accomplish much. The key ingredient that was missing, was the very the heart of the project: the kernels.&lt;/p&gt;

&lt;p&gt;Kernel is actually nothing but a fancy word for the part of the code which actually executes on the GPU. Given the project title, it’d be fairly obvious that in our project, the kernels are actually where the magic happens. While this is not meant to discount the importance of the host (or the CPU code), the kernels are ulimately the part of the program which are responsible for the performance boosts that we observe. Kernels, atleast those which are meant to be executed on Nvidia’s GPUs, are usually written in a language known as CUDA C. This is a special language that is written on top of the original C language, but with extra set of features, classes and methods which provide us an abstracted interface to control various aspects of the program and the way it is implemented on the GPU, more so than a conventional serial algorithm meant to be implemented on the GPU. While using CUDA C is quite straightforward, especially with the large community support and well-written documentation, we unfortunately could not make use of that as we wanted something that was written and compatible with Python and things written on top of Python. Thus, after a lot of deliberation and discussion, my mentors and I agreed to use something known as CuPy to handle the CUDA C part of our code.  CuPy is an incredibly well-written module with neat documentation and decent community support, which made things a lot simple for us. However, more than anything, the biggest advantage of using CuPy was its RawModule method. The idea behind RawModule was to allow users who already have a CUDA C file written to do some specific task (us!) could simply re-use their code and get away with the whole problem of running kernels in Python very, very easily. Let me demonstrate it using an example and that would perhaps make things even more clear:&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;
&lt;span class="n"&gt;loaded_from_source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r'''
extern "C"{
...
__global__ void test_sum(const float* x1, const float* x2, float* y, \
unsigned int N)
{
unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;
if (tid &amp;lt; N)
{
y[tid] = x1[tid] + x2[tid];
}
}
}'''&lt;/span&gt;

&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RawModule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loaded_from_source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'test_sum'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# y = x1 + x2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the code looks fairly self-explanatory, I’ll give a quick runthrough anyway. The idea behind CuPy’s RawModule method, true to it’s name, is to allow the raw CUDA source to work with Python, which in our case is the string named &lt;code class="language-plaintext highlighter-rouge"&gt;loaded_from_source&lt;/code&gt;. Using RawModule, we process the string as a CUDA C source file, extract the relevant kernels from the file, &lt;code class="language-plaintext highlighter-rouge"&gt;test_sum&lt;/code&gt; in our case, and we’re done! The function is stored as &lt;code class="language-plaintext highlighter-rouge"&gt;ker_sum&lt;/code&gt; in Python, and is ready for use just like any other Python method. In order to keep the look and feel of the module as close to the original CUDA C source codes, even the way kernels are called is quite similar to how they’re called in C. The first two parameters, are the grid and block dimensions, and finally we follow through with the actual parameters to the kernel. Clearly, this allowed us to fast-track a lot of the kernel porting work, and quickly develop a Python version of our original proof-of-concept code.
However, like everything else, even this wasn’t going to work as easily as we’d initially expected. Instead, I faced a new challenge, which was the use of a struct written in the CUDA library, used for fast fourier trasforms, known as &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt;. Like I explained in the previous paragraph, this problem was quite similar in nature to the whole Python object to C object transformation and vice versa. If anything, this probably felt more explicit in nature since we could clearly see the actual C code written (as the RawModule’s string). The problem was that the structs are very specific to their definition, and it is simply not possible to pass anything to the RawModule and expect it to process it as a struct. Even though a numpy array of datatype complex64 might be storing the exact same data as an array of &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt;, the two cannnot be interconverted like vectors of integers and other primitive types can be. This again posed a challenge as it would mean a deviation from the original code. Finally, after reading a lot of stackoverflow and still not being satisfied with any of the answers, I let my mentors help me out with the code. The final solution that came out did a couple of things: first we got rid of the &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt; structs, and instead introduced the other, C datatype, serving the same purpose, a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt;. This amazing datatype did the exact same thing, except we could pass a numpy (or cupy) array of type complex64 and it would automatically read it as a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt; array! It quite literally solved the whole problem in an instant, and the only modifications we had to make were change how the real and imaginary parts of the complex numbers were being handled. While the struct definition required us to handle both separately, the new format made things even simpler by letting us perform calculations on both the real and imaginary parts simultaneously (basically how you’d expect to work with a complex number anyway!). With this, and again a few minor changes here and there to ensure the data transfer between Cython and CuPy wasn’t throwing errors, I was done! However, by now I had a Cython file with 1300+ lines with a &lt;em&gt;lot&lt;/em&gt; of room for bugs and unexpected errors and behavior.&lt;/p&gt;

&lt;p&gt;This brings us to the current time. The current objective for me is to get the file to work properly and produce the right about, so basically debugging. However, unlike smaller programs and files which are debugged with usually a single method in focus, I have to constantly let the whole chain of methods to execute even if I know that the bug is in some specific method, simply because its impossible to recreate the testing environment otherwise. For instance, I have been debugging the code since yesterday, and except one time where I got a segmentation fault, every time the program crashes, I am being forced to restart my computer just to start the debugging process again. Reason you ask? The program is working on a small subset of an already trimmed dataset, occupying around 3 GB of space. However, whenever I execute the program and try to run it, it is loading all that data first in the RAM (which slows the computer to a crawl almost instantly due to the limited 8GB RAM), and subsequently to the GPU (where it takes up 3/4 GB VRAM present). On force closing the program, while the RAM does free up after some time to a state where I can start using the computer again, the GPU does not!! I am yet to read into the nitty-gritty of this, but from what I understood, we need to explicitly clear the VRAM occupied by CuPy using methods given in the documentation. However, when the program does not work as expected (which is currently 100 percent of the times I have run it), the program simply crashes before executing the lines which free up the memory. The result? A GPU which is loaded up and unable to free its VRAM. Resetting seems to not work for some reason, and the only option I have found so far (admittedly I havent researched well enough but its only been 24 hours since I reached this stage) which does work is restarting my computer. This, as I am sure you can already feel, is a very frustrating way to debug things, but I am happy to say that I am still making progress, albeit a little slowly than I would have liked to.&lt;/p&gt;

&lt;p&gt;That pretty much sums up everything that I have been upto for the past 2 weeks. The progress is a little on the slower side, as I expected to have the demo working &lt;em&gt;and&lt;/em&gt; producing the correct output by now, but unfortunately the code still needs debugging. Hopefully this should be over soon, and we can then move to integrating it with RADIS and making changes that should allow the user to make use of our program. After that, we would be focussing on implementing other methods of calculating spectra, and possibly also methods which support non-equilibria conditions. Hopefully I should have a lot more to tell you guys 2 weeks from now! Till then, adios! And thanks for making it this far (if you actually did so :P) Cheers.&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</guid><pubDate>Mon, 29 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Launching Version 1 of Start Spark</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</link><dc:creator>Biswarup Banerjee</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*GKZekrHbmzNBggdsyVxSSA.jpeg"&gt;&lt;figcaption&gt;Even my workstation is excited for the product demo!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;So after 4 weeks of planning and coding and debugging, the day came when I had to launch version 1.0 of the product!&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*JGcxp4eCl8d7t0omgPAFIQ.png"&gt;&lt;figcaption&gt;My extension “Start Spark” deployed at the prod servers&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The extension I built is now deployed in the DiRAC Jupyter Hub and is currently getting used by the astronomy community at DiRAC!&lt;/p&gt;
&lt;p&gt;What you can do with my extension:&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;ol&gt;&lt;li&gt;Create a PySpark cluster on the click of a single button. Creating a PySpark cluster would have otherwise taken writing multiple lines of cumbersome codes.&lt;/li&gt;&lt;li&gt;Get the link where you can access the PySpark web UI and see all the executors, jobs, and the environment.&lt;/li&gt;&lt;li&gt;The “spark” variable is automatically injected into the kernel and hence users can use it as they like.&lt;/li&gt;&lt;/ol&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*qUI3KU07owQgFF6x35_V4Q.png"&gt;&lt;figcaption&gt;Get access to the PySpark Web UI&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*shTWfgSYlHyTD-KkB7w2mw.png"&gt;&lt;figcaption&gt;“spark” variable is injected in the kernel&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;How does it work?&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/976/1*sV-BVWeI7hPzr1ZyYFGmKA.png"&gt;&lt;figcaption&gt;Workflow&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Step 1: The extension gets loaded.&lt;br&gt;
Step 2: While it loads it automatically calls an API/serverextension handler /all-config and that API gives all the list of the available configs.&lt;br&gt;
Step 3: We can see that list of all available configs in the dropdown.&lt;br&gt;
Step 4: We can select any config that we want and click on “Start Spark” Button&lt;br&gt;
Step 5 : When we click Start Spark Button, the front end detects which config we have selected and then tells the serverextension about the selected config via REST API.&lt;br&gt;
Step 6: The serverextension fetches all the config details of the config that is selected in the frontend from the config dir located at home dir.&lt;br&gt;
Step 7: Then once it has the required config fetched from the config dir it converts it into a Jinja Template and sends the jinja template to the front end via API&lt;br&gt;
Step 8: Once the front end receives the Jinja template of the required config it sends the Jinja Template to the Kernel Extension via Sockets&lt;br&gt;
Step 9: The kernel extension executes the jinja template to start the spark cluster that it receives from the Jupyter front end.&lt;/p&gt;
&lt;blockquote&gt;Select Config -&amp;gt; Click the Start Spark Button -&amp;gt; Config Data fetched in backend -&amp;gt; Config data converted to Jinja Template in Backend -&amp;gt; Jinja Template Sent from backend to front end -&amp;gt; Jinja sent from front end to Kernel → Jinja template gets executed in Kernel to start the cluster!&lt;/blockquote&gt;&lt;p&gt;&lt;strong&gt;Video Reference Link&lt;/strong&gt;: &lt;a href="https://slack-redir.net/link?url=https%3A%2F%2Fwww.loom.com%2Fshare%2Fdc18b670e08a47c6a96db3176f3be9ef"&gt;https://www.loom.com/share/dc18b670e08a47c6a96db3176f3be9ef&lt;/a&gt; (PS: Watch it in 1.5x speed)&lt;/p&gt;
&lt;p&gt;I am super excited to see how the astronomy community feels about it and gives their feedback.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=b16c4e9516fb" width="1" height="1"&gt;&lt;/div&gt;</description><category>astronomy-commons</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2034_techguybiswa/</guid><pubDate>Mon, 29 Jun 2020 19:34:53 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 1.2</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;It has been a month since GSoC’s coding period started early in June 2020. Much has happened since then in the glue-solar project, and to sum it up I have been pretty much spending all my GSoC time working on a WCSAxes-enabled version the 1D Profile viewer for extracting 1D spectrum from data cubes using the pixel extracted in a 2D Image viewer. To be honest it has been very effort-intensive, though not necessarily time-intensive as I have previously feared. But the journey has been fun given my very supportive and friendly project mentors. To the layman and non-specialist what I have related regarding the project details probably sounds esoteric, which it is. With this realization I will split this and remaining GSoC blog posts into two halves: one pertaining to my personal struggles, and the other pertaining to the technical aspect of the work carried out thus far, in that order, so that that latter part can be conveniently skipped over (but I do encourage you to do read both sections in tandem so get a better understanding of the project :-p) Anyway, let me begin…&lt;/p&gt;
&lt;h4&gt;Part 1: Personal struggles&lt;/h4&gt;&lt;p&gt;One personal “secret” I wish to reveal is that this is my last year as a PhD Candidate in Astrophysics at the University of Hong Kong (HKU). Not only that, since my Postgraduate Scholarship officially ran out in October 2019 and no other funding options are available, I have been holding down a job as a front-end developer for some parts of the weekdays to support my PhD studies. So far I have been trying to manage my time wisely and balancing my various duties and obligations as best as possible, but it has been a genuine struggle, especially in me trying to find enough time to sleep. To make matters worse I have a tendency to drift towards writing code than writing my thesis, though I am making progress in both. So I did hesitated to apply for GSoC for a 2nd time this year and was originally against the idea. But when I saw the project ideas available I changed my mind. Glue-solar is actually like a godsend for me; the project enabled me to not only further develop my self-discipline as a person, it also allowed me to learn from experts in the field working on open-source data visualization, and to grow from the experience. I thoroughly enjoyed interacted with my mentors, who have been very patient and helpful in offering me guidance (as well as friendship) throughout. If I have any advice I am allowed to offer anyone wanting to try out open-source software development through GSoC, and if GSoC does continue in the near future, I would recommend them to try out any of the OpenAstronomy projects. This is because OpenAstronomy is one (relatively) small but vibrant community of dedicated programmers, many of which scientists, that is welcoming to newcomers coming from a diverse background. And also, simply put, ASTRONOMY IS FUN! This is especially true for SunPy. I remember I started to contribute to open-source software as a relative novice with some bookish knowledge but not a lot of real-world experience back in around January 2019. My first contributions were to SunPy and Astropy. I remember I have read an article about how to get into GSoC in 2018 to learn about the program, though was not all that keen in getting into it at first. My first motivation to contribute was to give back to the community, because I had been using Python-based astronomy packages like Astropy for my PhD research. But at the urge of a mentor active in the Astropy community, I did apply. The GSoC project I worked on last year in 2019 was &lt;a href="https://summerofcode.withgoogle.com/archive/2019/projects/6094580905148416/"&gt;IRISpy&lt;/a&gt;, and my mentors were &lt;strong&gt;Dan Ryan&lt;/strong&gt; and &lt;strong&gt;Laura Hayes&lt;/strong&gt;. They were amazing as mentors, and were instrumental in my being able to complete the project successfully in the end of the program. I still miss my time spent with them on that project. IRISpy has officially changed its name to sunraster, which I was fortunate enough to help launch earlier this year in 2020. Basically when I was working on it as a GSoC project it was to provide additional functionalities for the analysis of observations from NASA’s Interface Region Imaging Spectrograph (IRIS) satellite which looks at UV emission from the solar chromosphere in particular. Now that scope has been extended to not just IRIS data, but data collected with similar instruments. This year I am using a lot of the code I have written for the IRISpy project for the current glue-solar project, which is kind of cool. As an icing to the cake, I get to work on data cubes for glue-solar, which is one of my favorite things in this world, a passion I have gained through my PhD research into integral field spectroscopy (IFS). For the present GSoC work I even get to work on &lt;strong&gt;4D data cubes (ones with an extra &lt;em&gt;time&lt;/em&gt; dimension)&lt;/strong&gt;, which has one more dimension than the IFS cubes I am so familiar with! So far it has been another incredible GSoC experience for me. All in all I have a feeling it will be a good one, and also a fruitful one.&lt;/p&gt;
&lt;h4&gt;Part 2: Technical aspect of progress made in glue-solar&lt;/h4&gt;&lt;p&gt;So we (me and my mentors) have ventured away from focusing on glue-solar and have entered the glue “proper” territory as we put more time and effort towards modifying the 1D Profile viewer. By this I mean we have begun work on glue instead of glue-solar as was the case as described in &lt;a href="https://medium.com/@krisastern/gsoc-2020-glue-solar-project-1-1-c2151e535e0c"&gt;my previous article&lt;/a&gt; where we have built a “SunPy Map” viewer. So I am well on my way to complete the task “modifying the existing glue 1D Profile viewer to provide sliders for extra dimensions (currently collapses)” soon, which is a significant part of the glue-solar project. Personally, I am really looking forward to working on the “adding support for pre-computed statistics in datasets / viewers” task, which I will surely make time to complete before end of August.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Let me demonstrate how far we have come with the modification of the 1D Profile viewer. So ordinarily it is hard to get 4D data cubes with a time dimension. This can be fixed by stacking sequential (IRIS) raster scans/cubes. After firing up glue from the terminal by the magic command “glue”, and importing some if not all raster scans from the same observation using the IRIS OBS directory importer, and choosing to “Stack the sequential raster scans” , we see some data points appearing in the Data field of the GUI. This is illustrated by the sequence of images to follow:&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*5te3r5u7q5pxeWhiBv4x9Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 1.&lt;/strong&gt; Loading an multi-scan IRIS Observation and choosing to stack the sequential raster scans / cubes.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*DvJ0gwjAKMjdGefNeggEpA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 2.&lt;/strong&gt; Stacked datasets which are essentially 4D data cubes appear in the Data field of the glue-solar GUI.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*c1fcKBkCGbcibrc2nfU93w.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 3.&lt;/strong&gt; As per usual, choosing the 2D Viewer option will enable us to inspect the different sides of the N-dimensional or ND data cube.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*A_dQDmastlGwmif17b7J2Q.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 4.&lt;/strong&gt; Choosing the right (N-1) slices for the slicing to obtain the 1D profile (which I have learned in a hard way is not always the same as a 1D spectrum coding-wise) using some pre-defined logic that warrants some explanation, though should be intuitive to some.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Qq70FXHsyObzBniXG35BOQ.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 5.&lt;/strong&gt; Using the 1D Profile tool, as opposed to the red 1D spectrum button in the 2D Image viewer, to generate the desired profile, which may or may not be a 1D spectrum.&lt;/figcaption&gt;&lt;/figure&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FuXVHmy-MOFS-ELa6gFSUw.png"&gt;&lt;figcaption&gt;&lt;strong&gt;Figure 6.&lt;/strong&gt; Plotting of the uncollapsed version of the 1D profile by choosing the newly added “Slice” function which does nothing statistical to the data like the other functions such as “Maximum”, “Median”, and “Sum” that can be chosen as alternatives. (The default is “Maximum”).&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As we can see in Figure 6, all 4 dimensions are represented in the 1D Profile viewer either as the x-axis or as a slider quantity. In this example, the x-axis is indeed wavelength (which yields a 1D spectrum by definition), the other dimensions are time, longitude (HPLN), and latitude (HPLT). Even though for now the sliders are still not yet functional and will need some tender loving care to make them work in tandem with the reference data as inherited or passed from the 2D Image viewer, which may take a few more days to complete, I believe this is truly a milestone in this GSoC project. If we can control the sliders to change the coordinate values, that would be a very useful tool in data exploration. I will spare the perhaps rather dry details regarding the reasoning through the whole thinking process that leads to this check point. However, I would like to explain the logic used in the slicing. What I have done is to introduced a SlicedData class, much like the existing IndexedData class that is used for pixel extraction with a tool my mentor &lt;strong&gt;Stuart Mumford&lt;/strong&gt; originally wrote for glue-solar (currently in a draft PR to be upstreamed to glue). First to pick a spatial coordinate, we choose in the 2D Image viewer the spatial axes for the image axes, selecting a point in the image shown on screen with the pixel selection tool, and then tweak the slider we would like its corresponding axis to be used as the x-axis in the 1D Profile viewer. Then we drag the same dataset to the viewing area and view using the 1D Profile viewer, in order to generate a profile for the slicing we have chosen. So this has been the work completed thus far. What is yet to be completed is to enable the manipulating of the 4D or higher dimensional data cube using the sliders for the same x-axis. So in the end regardless of the starting point, we could potentially use the 1D profile viewer to inspect the 4D or ND data cube in ways previously impossible before, at least to me.&lt;/p&gt;
&lt;p&gt;Again, I would like to thank my mentors for their guidance and support which enabled the progress I have made to happen. Much work will need to be done in order for the PRs to be polished up and merged later on in the summer. I really enjoy my glue-solar work for GSoC this summer. I hope you enjoyed reading this article as much as I had fun writing it too!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=65ef40ba2b71" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1911_kakirastern/</guid><pubDate>Mon, 29 Jun 2020 18:11:30 GMT</pubDate></item><item><title>GSoC 2020: Generalization of Clients</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/0*EsjuLxEt1BrtrdCG"&gt;&lt;figcaption&gt;Solar Eclipse 2020 in Vadodara, Gujarat (Lucky Enough to witness it this year!)&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;This fortnight, I worked around iterating over different designs for redesigning the Dataretriever Clients so that its implementation can be simpler and more general. Generalization here means the ability to inherit most of the methods from the base class itself; therefore minimizing a number of similar methods in the subclasses.&lt;/p&gt;
&lt;h5&gt;Show Method for QueryResponse&lt;/h5&gt;&lt;p&gt;I got&lt;a href="https://github.com/sunpy/sunpy/pull/4309"&gt; PR #4309&lt;/a&gt; merged which solved an old &lt;a href="https://github.com/sunpy/sunpy/issues/556"&gt;Issue #556&lt;/a&gt;. A simple show() function in ~sunpy.net.base_client.BaseQueryResponse enabled QueryResponse objects for Dataretriever, VSO, and JSOC clients to specify the columns to be shown in the result.&lt;/p&gt;
&lt;p&gt;This returns an ~astropy.table.Table instance, so table operations can also be easily performed on the result.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href"&gt;https://medium.com/media/10fce45866473f2eb6ad74e7f98000eb/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;_extract_files_meta method in Scraper&lt;/h5&gt;&lt;p&gt;&lt;a href="https://github.com/sunpy/sunpy/pull/4313"&gt;PR #4313&lt;/a&gt; was merged in sunpy:master that allows the scraper to extract the metadata stored in the file URLs. This function will prove very useful for refactoring the whole ~sunpy.net.dataretriever submodule.&lt;/p&gt;
&lt;p&gt;A new module parse was added in ~sunpy.extern which allowed to specify the extractor which will parse the file URL and return a dict containing the value of attrs like Wavelength, Time, Level, etc. Even the URL is returned by the method, which ensures no changes are to be made in fetch() methods for clients.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/da15de642196febf9eab940219efac0f/href"&gt;https://medium.com/media/da15de642196febf9eab940219efac0f/href&lt;/a&gt;&lt;/iframe&gt;&lt;h5&gt;Playing with post filters&lt;/h5&gt;&lt;p&gt;Last fortnight I was working with post filters and concatenation of responses for VSO. Last week I dabbled a bit with post-filters for attrs used in all net clients. Using single_dispatch decorator over filter_results enabled post-filtering in dataretriver and VSO. It is pretty similar to the way it is done for ~sunpy.net.vso.attrs.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/274b4e0b885d17b391589d15c593f046/href"&gt;https://medium.com/media/274b4e0b885d17b391589d15c593f046/href&lt;/a&gt;&lt;/iframe&gt;&lt;h4&gt;Redesigning GenericClient&lt;/h4&gt;&lt;p&gt;So there is a draft &lt;a href="https://github.com/sunpy/sunpy/pull/4321"&gt;PR #4321&lt;/a&gt; where work is in progress for the new implementation for the generalization. QueryResponeBlock is removed from the client.py since by few changes in the QueryResponse enables us to do it all using a dictionary. Similarly &lt;a href="https://github.com/sunpy/sunpy/pull/4321/files"&gt;a lot of methods were removed or changed&lt;/a&gt; under the aim to simplify the two Generic Classes.&lt;/p&gt;
&lt;p&gt;Not only the base class, even the client class were made simple. For simple clients, we are supposed to only define required attrs, optional attrs, a baseurl, and an extractor which makes the search working.&lt;/p&gt;
&lt;p&gt;After this refactoring, the example dataretriever source client class would look something like this:&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href"&gt;https://medium.com/media/759cceb1f744c525c6a55e80b8f9ecb9/href&lt;/a&gt;&lt;/iframe&gt;&lt;p&gt;Only a class method and few class attributes are sufficient for defining a simple DR client!&lt;/p&gt;
&lt;h5&gt;Hooks for translating attrs&lt;/h5&gt;&lt;p&gt;There are some clients which deviate from generalization. For those clients, it was discussed in a meeting with mentors that post-hooks and pre-hooks for scraper are to be designed which shall perform a translation of attrs provided in the search to their representation in the url. While working around it, I discovered few bugs in fermi_gbm and other clients to be addressed in scraper hooks. Responses for Detector numbers 10 and 11 were never returned because in the url they were represented by na and nb respectively. They will be fixed by translators as a part of pre-hook before passing it to the scraper.&lt;/p&gt;
&lt;h5&gt;Moving Rhessi out from Generic&lt;/h5&gt;&lt;p&gt;Since rhessi didn’t follow the Generalization as the metadata can’t just be extracted from the file URL, so it is being implemented as subclass of base_client.&lt;/p&gt;
&lt;p&gt;Every week we move closer and closer to Generalization :). Enjoying the meetings where I and my mentors discuss the pros and cons of different designs of GenericClient!&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=1879f5dfe436" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_1813_abhijeetmanhas/</guid><pubDate>Mon, 29 Jun 2020 17:13:52 GMT</pubDate></item></channel></rss>