<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy</title><link>http://openastronomy.org/Universe_OA/</link><description>This is an aggregator of openastronomy people</description><atom:link href="http://openastronomy.org/Universe_OA/rss.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Mon, 24 Aug 2020 02:00:38 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>GSoC 2020: glue-solar project 3.2</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200823_0807_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;It is finally nearing the end of the project for me, as far as coding is concerned. Over the past few weeks I have spent some time on some last-ditch effort to debug with my mentors and to squeeze as much as I possibly could given the time constraint I have been under. These include but not limited to sorting out some generalisation issues that previously prevented glue &lt;a href="https://github.com/glue-viz/glue/pull/2167"&gt;PR #2167&lt;/a&gt; from being usable for general FITS files, some type as well as wcs linkages issues in glue &lt;a href="https://github.com/glue-viz/glue/pull/2161"&gt;PR #2161&lt;/a&gt; that cropped up after applying changes suggested in code review that have not been properly checked on my part. The pull requests started or completed for the project include but are not limited to the following list:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;glue &lt;a href="https://github.com/glue-viz/glue/pull/2167"&gt;PR #2167&lt;/a&gt; for updating 1D Profile viewer to use wcsaxes for plotting and add sliders&lt;/li&gt;&lt;li&gt;glue &lt;a href="https://github.com/glue-viz/glue/pull/2161"&gt;PR #2161&lt;/a&gt; for updating ‘wcs_autolinking’ code to handle N-D cases using a generalised approach conforming to &lt;a href="https://docs.astropy.org/en/stable/wcs/wcsapi.html"&gt;APE 14: Shared Python interface for World Coordinate Systems&lt;/a&gt;&lt;/li&gt;&lt;li&gt;glue &lt;a href="https://github.com/glue-viz/glue/pull/2164"&gt;PR #2164&lt;/a&gt; for adding support to NDData for astropy package&lt;/li&gt;&lt;li&gt;glue &lt;a href="https://github.com/glue-viz/glue/pull/2131"&gt;PR #2131&lt;/a&gt; for adding a preferred_cmap attribute to introduce a color coding scheme for different glue-solar data types (for example to distinguish the IRIS raster data cubes from its companion IRIS SJI data cubes&lt;/li&gt;&lt;li&gt;glue-solar &lt;a href="https://github.com/glue-viz/glue-solar/pull/15"&gt;PR #15&lt;/a&gt; for adding to open with “SunPy Map” GUI option&lt;/li&gt;&lt;li&gt;glue-solar &lt;a href="https://github.com/glue-viz/glue-solar/pull/17"&gt;PR #17&lt;/a&gt; for adding “Loading and Overplotting AIA and HMI files as SunPy Maps” docs as a user guide&lt;/li&gt;&lt;li&gt;glue-solar &lt;a href="https://github.com/glue-viz/glue-solar/pull/18"&gt;PR #18&lt;/a&gt; for adding “loading IRIS level 2 raster and sji data together docs” as a user guide&lt;/li&gt;&lt;li&gt;glue-solar &lt;a href="https://github.com/glue-viz/glue-solar/pull/23"&gt;PR #23&lt;/a&gt; for updating IRIS data labels with OBSIDs for filtering&lt;/li&gt;&lt;li&gt;glue-solar &lt;a href="https://github.com/glue-viz/glue-solar/pull/28"&gt;PR #28&lt;/a&gt;, &lt;a href="https://github.com/glue-viz/glue-solar/pull/29"&gt;PR #29&lt;/a&gt; as core glue-solar documentation&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I have actually been using our work on the glue 1D profile tool for my current doctoral studies on studies of planetary nebulae using integral field spectroscopy (IFS) involving the handling of a large number of data cubes from some Australian telescopes (data collected by my PhD supervisor Prof. Quentin Parker). Turned out this tool made the process of investigating the different spectra, which could run up to hundreds in number per data cube or observation, as it allows me to load in my data cube only once, and then to inspect the variation across spatial dimensions to see if the signal-to-noise of a particular observation is too high, or if the opposite is true so that the spectra will then be further processed into full-optical integrated spectra with flux calibration or de-reddening as necessary.&lt;/p&gt;
&lt;p&gt;I am grateful for Google, my mentors, other org members as well as my GSoC peers to make this a particular fun-filled and memorable project! I have learned so much from the experience that even money cannot buy in terms of programming and soft skills. I wish Google will continue this program or initiate some similar program to continue cultivating new generations of open-source software developers / development enthusiasts to further our aim to make open-source approachable and usable for all.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=eb6b2bccce85" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200823_0807_kakirastern/</guid><pubDate>Sun, 23 Aug 2020 07:07:23 GMT</pubDate></item><item><title>Looking for the answers!</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200820_1000_meuge/</link><dc:creator>Meuge</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey, folks! The last weeks were really exciting getting done an algorithm for ground-track orbit. After long days trying to find the perfect approach for Poliastro, we decided to give it a go bringing to life this &lt;a href="http://openastronomy.org/Universe_OA/posts/2020/08/20200820_1000_meuge/%5Bhttps:/www.researchgate.net/publication/287869810_Daily_repeat-groundtrack_Mars_orbits"&gt;paper&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="wow" src="https://media.giphy.com/media/gZBYbXHtVcYKs/giphy.gif"&gt;&lt;/p&gt;
&lt;h2&gt;But everything it's not what it seems&lt;/h2&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Well, we thought it will be quite straightforward but much too learn still I have , right Master Yoda?  &lt;/p&gt;
&lt;p&gt;&lt;img alt="do-or-do-not" src="https://media.giphy.com/media/pvDp7Ewpzt0o8/giphy.gif"&gt;&lt;/p&gt;
&lt;p&gt;So I am not gonna lie to you folks, it wasn't that easy, but as Rocky says, "Every champion was once a contender who refused to give up". So now you are gonna know how we solve it. Game on!  First things first, we needed to apply numerical analysis in order to obtain the roots of the equation, because given the complexity of the function, there was no other way around. &lt;/p&gt;
&lt;p&gt;&lt;img alt="oh-no" src="https://media.giphy.com/media/xT5LMLMPdRh2VRNVLi/giphy.gif"&gt;&lt;/p&gt;
&lt;p&gt;So we had to come up …&lt;/p&gt;&lt;/div&gt;</description><category>poliastro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200820_1000_meuge/</guid><pubDate>Thu, 20 Aug 2020 09:00:00 GMT</pubDate></item><item><title>Week 9 &amp; 10: Beginning of the last month!</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200818_1113_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;h3 id="hey-sid-lets-get-to-the-point-directly-did-your-previous-pr-get-merged"&gt;&lt;em&gt;Hey Sid! Let’s get to the point directly, did your previous PR get merged?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Yes! The PR which involved creation of new data structure for &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;s got merged, the code is up and running now!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="great-tell-us-whats-the-next-pr-all-about"&gt;&lt;em&gt;Great, tell us what’s the next PR all about&lt;/em&gt;?&lt;/h3&gt;

&lt;p&gt;After creating the data structure &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt; and making it compatible with all methods in &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/pull/31"&gt;#31&lt;/a&gt;, I went back to my closed PR &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/pull/30"&gt;#30&lt;/a&gt; to take the code and make it compatible with &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt;. &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/pull/30"&gt;#30&lt;/a&gt; consists of code that enables a user to apply function on a collection of &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;s and then save them in new &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files. Now, the new PR &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/pull/33"&gt;#33&lt;/a&gt; enables the same functionalities but with &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt;s. This PR is in it’s last stages of review and will get merged soon!&lt;/p&gt;

&lt;h3 id="hmmm-that-sounds-interesting-have-you-prepared-some-examples-to-show-the-code-in-action"&gt;&lt;em&gt;Hmmm, that sounds interesting, have you prepared some examples to show the code in action?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Not yet, but don’t worry, I have started working on proper usage guidelines and examples, will put it up soon!&lt;/p&gt;

&lt;h3 id="cool-tell-us-about-your-future-plans"&gt;&lt;em&gt;Cool! Tell us about your future plans?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Currently, my primary goal is to get PR &lt;a href="https://github.com/JuliaAstro/CCDReduction.jl/pull/33"&gt;#33&lt;/a&gt; merged, after this I will put up some basic examples for complete reduction process. Following all this, I will push a new release and keep working on stretch goals!&lt;/p&gt;

&lt;p&gt;Stay tuned to know more!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200818_1113_siddharthlal25/</guid><pubDate>Tue, 18 Aug 2020 10:13:56 GMT</pubDate></item><item><title>GSOC 2020: New additions to old PRs</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200811_1829_abhijeetmanhas/</link><dc:creator>Abhijeet Manhas</dc:creator><description>&lt;div&gt;&lt;h4&gt;GSOC 2020: Polishing my code&lt;/h4&gt;&lt;p&gt;I spent last most of the previous two weeks on resolving reviews on my old PRs and improving gallery examples.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/852/0*fsXbXhCmI6jKwUv6.jpg"&gt;&lt;figcaption&gt;Heavy rains begins in Vadodara&lt;/figcaption&gt;&lt;/figure&gt;&lt;h4&gt;Knowing time intervals from URL patterns&lt;/h4&gt;&lt;p&gt;I created &lt;a href="https://github.com/sunpy/sunpy/pull/4419"&gt;PR #4419&lt;/a&gt; that allows getting file time-ranges from the URL using the scraper. The URL patterns from most of the archives have start time in them. Either the end time was usually hardcoded for all clients or we only used start time to validate the file URLs against a time interval.&lt;/p&gt;
&lt;p&gt;In my Clients Generalization, to escape this repetitiveness the code in post_search_hook() was somewhat less generalized. It was assumed that all files are day-long. Thus I generalized it and moved it to the scraper. From the base URL pattern, we can now the precision of time supported by the archive directories, and then using them we can find the end times. Say there are yearly files in an archive. Then we can default the end time to the end of that year. Moreover, if this time range overlaps with the searched time interval, the file is valid. We check it using _check_timerange().&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;h4&gt;Removed optional from class attributes&lt;/h4&gt;&lt;p&gt;We now need to register all ‘attrs’ supported by the client in PR #4321. This helped me to escape from defining optional attrs. We use register_values() only to know whether the client can serve the query or not.&lt;/p&gt;
&lt;h4&gt;Fido metadata queries Gallery Example&lt;/h4&gt;&lt;p&gt;I have added a new gallery example in &lt;a href="https://github.com/sunpy/sunpy/pull/4358"&gt;PR #4358&lt;/a&gt; which summarizes what we can do after the pull request is merged. We can make metadata queries and easily inspect them. A lot of minor improvements were also made in the PR.&lt;/p&gt;
&lt;iframe src="http://openastronomy.org/Universe_OA/posts/2020/08/20200811_1829_abhijeetmanhas/" width="0" height="0" frameborder="0" scrolling="no"&gt;&lt;a href="https://medium.com/media/0e1004e2649bfd262dda2f4e37fed4a8/href"&gt;https://medium.com/media/0e1004e2649bfd262dda2f4e37fed4a8/href&lt;/a&gt;&lt;/iframe&gt;&lt;h4&gt;Extracting client responses from Fido result&lt;/h4&gt;&lt;p&gt;Earlier we have to specify index as an argument to get_response() to do that. It required us to count the records to find the correct index. Now we can easily use the name of the client to retrieve QueryResponse instances for that client. If there are multiple such records, then a list of all matching records will be returned.&lt;/p&gt;
&lt;h4&gt;ToDos for the final two weeks&lt;/h4&gt;&lt;p&gt;I have to document how to write Fido clients and add tests to the Fido metadata compatibility. Let’s see what other issues I can tackle in these pull requests.&lt;/p&gt;
&lt;p&gt;Till then,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CAPRE NOCTEM!&lt;/strong&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=c2d1683fe428" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200811_1829_abhijeetmanhas/</guid><pubDate>Tue, 11 Aug 2020 17:29:54 GMT</pubDate></item><item><title>Week 8 &amp; 9: Buzzer Beater?</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200810_1708_sahilyadav27/</link><dc:creator>Sahil Yadav</dc:creator><description>&lt;div&gt;&lt;h4&gt;Week 9 &amp;amp; 10: Buzzer Beater?&lt;/h4&gt;&lt;p&gt;In the past two weeks, I worked on creating the MCHeader Container for MAGIC data. After discussing with people working at MAGIC, we used the RunHeaders TTree variables to create the Container.&lt;/p&gt;
&lt;p&gt;For the arrival direction and telescope pointing, we decided to use the MSrcPosCam variable from the ROOT file, which stores the shower direction relative to the telescope, i.e arrival direction-telescope pointing. Thus, we don’t need to think much about the Alt-Az transformations as well. And we don't have to create a separate column for telescope pointing in the HDF5 file. This saves computation time too.&lt;/p&gt;
&lt;p&gt;This solves two of the major issues we were having last time. Now, we will soon start training some MAGIC gamma data files from the two telescopes using the CTLearn deep learning models and get some benchmark results on the same.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*Ee0UeDUTC37W9_-ZioSEZQ.jpeg"&gt;&lt;figcaption&gt;Devin Booker hitting the buzzer-beater in Kawhi and PG’s face. Hoping this is how GSoC ends.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;We were also trying to create an event source for VERITAS data, but there were some issues with reading the data. We’ll see how this error progresses.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=80e03f9a5e1b" width="1" height="1"&gt;&lt;/div&gt;</description><category>CTLearn</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200810_1708_sahilyadav27/</guid><pubDate>Mon, 10 Aug 2020 16:08:08 GMT</pubDate></item><item><title>GSoC 2020: glue-solar project 3.1</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200809_2322_kakirastern/</link><dc:creator>Kris Stern</dc:creator><description>&lt;div&gt;&lt;p&gt;The 3rd coding period of GSoC 2020 will officially conclude in 2 weeks time. I would like to take this opportunity to review the progress made thus far, and to outline what other major feature can be added to glue-solar, perhaps over the remaining 2 weeks and beyond.&lt;/p&gt;
&lt;p&gt;We have finally resumed code reviews for the remaining PRs in the glue repo, and I am happy to report that the PR dealing with adding a preferred_cmap attribute to the visual module of glue/core has been merged four days ago from today. This is a very memorable milestone as this is my first contribution to the glue codebase. The remaining PRs which are being worked on include the 1D Profile PR (&lt;a href="https://github.com/glue-viz/glue/pull/2156"&gt;PR #2156&lt;/a&gt;) as well as the wcs auto-linking PR (&lt;a href="https://github.com/glue-viz/glue/pull/2161"&gt;PR #2161&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Regarding our work at the glue-solar repo, all of the PRs reviewed except the two experimental ones has been merged. A User’s Guide and a Developer’s Guide have been added to the &lt;a href="https://glue-solar.readthedocs.io/en/latest/"&gt;docs&lt;/a&gt;, while there is one open WIP PR which I am working on to add both a contributing document and the code references (or API) for the repo. Also some docs introducing users on how to start their own extensions in glue-solar for conducting solar physics has been planned.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;All of the above will form the bulk of work to be submitted for the GSoC project.&lt;/p&gt;
&lt;p&gt;More can be done for glue-solar, including but not limited to the following:&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;Add NDData support to glue via glue-solar&lt;/li&gt;&lt;li&gt;Add instrument loader code from sunkit-instruments to glue-solar&lt;/li&gt;&lt;li&gt;Enable image / Movie exports, both with axes and without axes via matplotlib&lt;/li&gt;&lt;li&gt;Add support for pre-computed statistics in datasets / viewers.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Hopefully with the support of the mentors much of what has been planned can be brought to fruition, so that this project will be a successful one.&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=4aebd6964154" width="1" height="1"&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200809_2322_kakirastern/</guid><pubDate>Sun, 09 Aug 2020 22:22:40 GMT</pubDate></item><item><title>GSoC 2020: Blog 4 - Update on Null Geodesics in Kerr Spacetime</title><link>http://openastronomy.org/Universe_OA/posts/2020/08/20200806_1009_jes24/</link><dc:creator>Jyotirmaya Shivottam</dc:creator><description>&lt;div&gt;&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/08/20200806_1009_jes24/#progress-so-far" class="anchor"&gt;
&lt;/a&gt;
&lt;!-- TEASER_END --&gt;
Progress so far...
&lt;/h3&gt;

&lt;p&gt;Support for calculation and graphing of Null Geodesics in Kerr (and by extension, Schwarzschild) spacetime is nearing completion (PR &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/527"&gt;#527&lt;/a&gt;). Last week, I hit a serious obstacle, related to maximum floating point precision and accumulation of numerical errors (which is also the reason for the delayed blog). Since the Geodesic Equations are stiff ODEs, small instabilities can wreak havoc on step-size control and completely destabilize the solution. I observed this happening with my code for Null Geodesics. As the light ray approaches the black hole, the integrator can no longer choose a proper step-size and the solution becomes inaccurate. In this blog, I will be discussing this issue and how we are approaching it with the new Null Geodesics module. I also present some of the null geodesic plots, created using this module.&lt;/p&gt;

&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/08/20200806_1009_jes24/#stiff-odes-are-evil" class="anchor"&gt;
&lt;/a&gt;
Stiff ODEs are evil!
&lt;/h3&gt;

&lt;p&gt;Stiff ODEs and Numerical Methods have always been at loggerheads. There is no precise definition for stiff ODEs, but an important feature is that, they are prone to become unstable. The usual solution is to choose a solver, that can accommodate very small step-sizes, while keeping overall error low. SciPy provides performant wrappers for LSODA/BDF methods, that are usually suitable for stiff systems, but in our case, these methods are unhelpful, as can be seen in the image below. For comparison, I have used Mathematica to obtain geodesics for the same conditions. The only major difference, here, is the solver. The plot on the left is Mathematica-generated, while the plot on the right was generated by Python. Note that, all the plots in this post have their axes normalized to the gravitational radius, or units of

&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;GMc2\frac{GM}{c^2}&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mopen nulldelimiter"&gt;&lt;/span&gt;&lt;span class="mfrac"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;c&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size3 size1 mtight"&gt;&lt;span class="mord mtight"&gt;2&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="frac-line"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;G&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;M&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mclose nulldelimiter"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--3K6LPGIe--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/4rrh7mkn6fgd46l61r5s.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--3K6LPGIe--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/4rrh7mkn6fgd46l61r5s.jpg" alt="Plot 1"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The initial conditions for the plots above are as follows. The timelike component of the initial velocity was calculated by setting
&lt;span class="katex-element"&gt;
&lt;span class="katex"&gt;&lt;span class="katex-mathml"&gt;gabuaub=0g_{ab}u^au^b = 0&lt;/span&gt;&lt;span class="katex-html"&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;g&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t vlist-t2"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;a&lt;/span&gt;&lt;span class="mord mathdefault mtight"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-s"&gt;​&lt;/span&gt;&lt;/span&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;u&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;a&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mord"&gt;&lt;span class="mord mathdefault"&gt;u&lt;/span&gt;&lt;span class="msupsub"&gt;&lt;span class="vlist-t"&gt;&lt;span class="vlist-r"&gt;&lt;span class="vlist"&gt;&lt;span&gt;&lt;span class="pstrut"&gt;&lt;/span&gt;&lt;span class="sizing reset-size6 size3 mtight"&gt;&lt;span class="mord mathdefault mtight"&gt;b&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;span class="mrel"&gt;=&lt;/span&gt;&lt;span class="mspace"&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="base"&gt;&lt;span class="strut"&gt;&lt;/span&gt;&lt;span class="mord"&gt;0&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;
&lt;/span&gt;
.&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;a = 0.9
end_lambda = 200
max_steps = 200
position = [0, 20., pi / 2, pi / 2]
velocity = [-0.2, 0., 0.002]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



&lt;p&gt;Other solvers (that are suited to non-stiff problems) become unstable long before the desired number of integration steps is reached. Given the lack of a proper solver, I wrote my own solver, using a step-size control scheme from the venerable Numerical Recipes (Press et al, 2007), fine-tuned to the problem. Sadly, this did not produce better results and it even failed for certain pathological higher-order orbits. Here, "high-order" implies "loopy" orbits, very close to the black hole, while "pathological" can encompass higher-order orbits to orbits, that are scattered at large angles (i.e., orbits, with sharp turning points, à la the plots above).&lt;/p&gt;

&lt;p&gt;Then, I set out to find the reason behind the instability. Based on my tests, the stiffness comes from the singular nature of the black hole horizon (in Boyer-Lindquist coordinates), which can force the solver to choose incredibly small step-sizes, which in turn leads to more and more floating point error and over large intervals, the obtained solution becomes completely unphysical. This is what, "unstable" means here. Apart from the graphical representation of the instability through the plots, we can also see the instability numerically, through the norm of 4-Velocity of the light ray, as it evolves:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--x773iglx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/unqkuukvuez64rw9sytu.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--x773iglx--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/unqkuukvuez64rw9sytu.jpg" alt="U1"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;All of these values should be ~0 and on comparing with the plot on the right, it is easy to see, that the norm becomes too high as the light ray gets closer to the black hole. This tells us, that a correlation exists between the initial conditions and the instability, which is expected.&lt;/p&gt;

&lt;p&gt;In discussions with my mentors, we explored a few solutions, such as, using another system of units or coordinate system. However, we are already using the most suitable unit and coordinate systems for numerical computation of geodesics - &lt;em&gt;M&lt;/em&gt;-Units and Boyer-Lindquist Coordinates. I should note here, that at slightly larger initial radial distances and speeds, the code provides a good approximation to the actual solution, as can be observed in the plot and table below.&lt;br&gt;
&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--MpWHMED6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/8jguox8rqj06yjwrrleo.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--MpWHMED6--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/8jguox8rqj06yjwrrleo.jpg" alt="Plot 2"&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://res.cloudinary.com/practicaldev/image/fetch/s--d97ENcX4--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/b7m73dy8glfgu6wyg78c.jpg" class="article-body-image-wrapper"&gt;&lt;img src="https://res.cloudinary.com/practicaldev/image/fetch/s--d97ENcX4--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/i/b7m73dy8glfgu6wyg78c.jpg" alt="U2"&gt;&lt;/a&gt;&lt;br&gt;
Clearly, the accumulated error over lambda is smaller in this plot.&lt;/p&gt;

&lt;p&gt;The initial conditions for the second set of plots are as follows:&lt;br&gt;
&lt;/p&gt;

&lt;div class="highlight"&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;a = 0.9
end_lambda = 200
max_steps = 200
position = [0, 30., pi / 2, pi / 2] # Only difference
velocity = [-0.2, 0., 0.002]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;



&lt;h3&gt;
&lt;a href="http://openastronomy.org/Universe_OA/posts/2020/08/20200806_1009_jes24/#until-next-time" class="anchor"&gt;
&lt;/a&gt;
Until next time...
&lt;/h3&gt;

&lt;p&gt;Initially, I had planned to develop the Null Geodesics module, such that simulating a photon sheet would be possible through this module itself. The purpose would be applications in radiative transfer calculations, which require simulation of pathological orbits for better approximations in the strong gravity regime. But the issue of error accumulation has made it difficult to continue with this strategy. We have decided to make the current code merge-ready, while keeping the PR open, mainly because, the code performs well at larger initial distances. I have already made relevant changes to ensure the code is merge-ready. The status of the PR can be viewed at &lt;a href="https://github.com/einsteinpy/einsteinpy/pull/527"&gt;PR #527&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I am currently mulling the option of implementing the code in some low level language and then, building a wrapper around it, goal being to achieve better error-control, which I have not been able to obtain with Python/SciPy. Another approach that I am considering, is to restrict integration near the event horizon, based on step-size changes. Since multiple options are being explored and this is the last coding period, I have decided to make these blogs weekly. So my next blog should be up, next Friday. Hopefully, I will have solved this by then.&lt;/p&gt;&lt;/div&gt;</description><category>EinsteinPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/08/20200806_1009_jes24/</guid><pubDate>Thu, 06 Aug 2020 09:09:20 GMT</pubDate></item><item><title>gsoc_journey.update({“Chapter 2”: [“First Evaluations”, “Google Foobar?”]})</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200729_1643_theand9/</link><dc:creator>Amogh Desai</dc:creator><description>&lt;div&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*wmLYBAA422_jyF9QSWqS6w.jpeg"&gt;&lt;figcaption&gt;The James Webb Space Telescope is the $10 Billion successor to the Hubble Space Telescope. It can peer back into primordial times to show images of how the universe looked like around a quarter of a billion years after the Big Bang when the first stars and galaxies started to form.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Evaluation, a dreaded 10-letter word(just counted the number of letters😅) that brings stress and anxiety in everyone from a small kid to a golden-ager(sounds so much better than ‘old-person’ doesn’t it!!). The Cambridge dictionary defines evaluation &lt;em&gt;(noun)&lt;/em&gt;, &lt;em&gt;ɪˌvæl.juˈeɪ.ʃən, &lt;/em&gt;as &lt;strong&gt;“ the process of judging or calculating the quality, importance, amount, or value of something”. &lt;br&gt;
&lt;/strong&gt;Evaluations bring the best or worst out of people. I work better under pressure, I am one of those guys who cannot work until the room is on fire😂(I have a better phrase but it doesn’t quite qualify as PG-13😜).&lt;/p&gt;
&lt;p&gt;Evaluations although simple(the procedure) in GSoC are a big deal as they determine if you get (cue the Heavenly choir sound effect) &lt;strong&gt;the monthly stipend&lt;/strong&gt;🤑, just kidding, they determine if the student will be allowed to continue their projects. There are three &lt;strong&gt;&lt;em&gt;main &lt;/em&gt;&lt;/strong&gt;evaluations, one after each month to quantify if the project achieves the goals that it intended to and if the time was utilized most efficiently for the greatest possible impact.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Now I understand procedural information is pretty boring so let’s directly jump to the fun stuff.&lt;/p&gt;
&lt;h4&gt;The Google FooBar Challenege&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*FvygSOchRZWfDLrq4QB9GQ.png"&gt;&lt;figcaption&gt;Looks like an invitation from a secret society!!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;It happened at around 9:00 am on 9th of June, I had pulled an all-nighter and was half-asleep, finding ways to optimize stingray, when on typing _________ my browser window pivoted, the above image unfolded, my eyes widened, heartbeat skyrocketed, I looked in awe at my screen and then blinked 100 times, washed my face to truly confirm what I was seeing was true. &lt;br&gt;
It was the GOOGLE FOOBAR CHALLENGE!&lt;/p&gt;
&lt;p&gt;The FooBar challenge is a coveted, hidden challenge, a special invitation that is only sent to a selected few(makes me feel like James Bond😜). FooBar is Google’s secret hiring challenge. Google uses this to hire some of the best developers around the globe which they think can be a good match for their organization. &lt;br&gt;
Google sends an invitation based on one’s search history and problem-solving related keyword searches. If hidden magic in the Google search algorithm chooses you, you may receive an invitation for Google Foobar(makes me feel like Harry Potter😂).&lt;/p&gt;
&lt;blockquote&gt;Curious developers are known to seek interesting problems. Solve one from Google?&lt;/blockquote&gt;&lt;p&gt;Without thinking twice I instantly clicked &lt;em&gt;‘I want to play’. &lt;/em&gt;A black screen with a command-line interface greeted me.&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*sxh-YA_0437rxf5lu4r8mA.png"&gt;&lt;figcaption&gt;&lt;strong&gt;&lt;em&gt;Objects we ardently pursue bring little happiness when gained; most of our pleasures come from unexpected sources.&lt;/em&gt;&lt;/strong&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The FooBar challenge is essentially an online, time-bound Competitive Programming(CP) challenge with 5 rounds of increasing difficulty, each round having a different number of questions. &lt;br&gt;
To spice things up (both in terms of interest and difficulty) Google has a storyline, progressing through the challenges you are asked for a friend who you’d like to refer for the challenge and eventually some personal details.&lt;/p&gt;
&lt;p&gt;FooBar proved to be a great learning experience for me as I’m not proficient in CP. I felt that the main aim was not to test the skills and knowledge of an individual but also how quickly they could learn and implement solutions.&lt;br&gt;
To learn more about FooBar you could read this &lt;a href="https://medium.com/plutonic-services/things-you-should-know-about-google-foobar-invitation-703a535bf30f"&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;First GSoC Evaluation&lt;/h4&gt;&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Vw7I5eOtqMVRWRRLQcJKiw.png"&gt;&lt;figcaption&gt;The Google Summer of Code Dashboard a friend who I only see once every month😂😂&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;The first evaluations were scheduled from the June 29, 2020 — July 3, 2020. My mentor Matteo and I had finalized on two main deliverables crucial for the foundations of the project. &lt;br&gt;
1. A &lt;a href="https://github.com/StingraySoftware/stingray/blob/9d7fa8a76d70df1eeb4501cb7ce701fb8e5bddf0/Benchmarks/Benchmark%20Analysis%20Report%202020%20-%20stingray.pdf"&gt;benchmark analysis report&lt;/a&gt; containing the time and memory benchmarks, profiling results for &lt;strong&gt;all the 31 functions&lt;/strong&gt;(3000+ lines of code)in the &lt;a href="https://github.com/StingraySoftware/stingray/blob/master/stingray/lightcurve.py"&gt;Lightcurve&lt;/a&gt;, &lt;a href="https://github.com/StingraySoftware/stingray/blob/master/stingray/powerspectrum.py"&gt;Powerspectrum&lt;/a&gt;, &lt;a href="https://github.com/StingraySoftware/stingray/blob/master/stingray/crossspectrum.py"&gt;Crossspectrum&lt;/a&gt;, AveragedPowerspectrum and AveragedCrossspectrum classes. &lt;br&gt;
2. Integrating &lt;a href="https://asv.readthedocs.io/en/stable/"&gt;airspeed velocity&lt;/a&gt;, a tool for benchmarking Python packages over their lifetime into stingray.&lt;/p&gt;
&lt;p&gt;The benchmark analysis report was a very time consuming yet possibly the most important step of the project. It singled out the functions that were causing the most delay and provided an overall estimate of the performance of stingray.&lt;/p&gt;
&lt;p&gt;Benchmarking was performed in jupyter-notebooks. Data points of sizes ranging from 1,000(1K) to 100,000,000(100M) were used for benchmarking. For basic benchmarking, the %timeit and %memit magic commands were used. Two profilers &lt;a href="http://joerick.me/posts/2017/12/15/pyinstrument-20/"&gt;Pyinstrument&lt;/a&gt; and &lt;a href="https://docs.python.org/3/library/profile.html#module-cProfile"&gt;CProfile&lt;/a&gt; were used to profile time and &lt;a href="https://pypi.org/project/filprofiler/"&gt;filprofiler&lt;/a&gt; was used to profile memory use. &lt;br&gt;
The results of the CProfile were saved as a &lt;em&gt;.pstats&lt;/em&gt; file which was then visualized using &lt;a href="https://jiffyclub.github.io/snakeviz/"&gt;Snakeviz&lt;/a&gt; and &lt;a href="https://github.com/jrfonseca/gprof2dot"&gt;gprof2dot&lt;/a&gt; in the form of a graphical viewer and call-graph respectively. &lt;br&gt;
The results of the Pyinstrument and filprofiler were saved as HTML files.&lt;br&gt;
The results of the &lt;em&gt;%timeit&lt;/em&gt; and &lt;em&gt;%memit&lt;/em&gt; magic commands was visualized in an interactive &lt;a href="https://plotly.com/"&gt;Plotly&lt;/a&gt; graph in the jupyter-notebook itself and also saved as an HTML file for easier access.&lt;/p&gt;
&lt;p&gt;The result of all of this was &lt;strong&gt;535 &lt;/strong&gt;files&lt;strong&gt; &lt;/strong&gt;ready for analysis, compiled into a &lt;strong&gt;74-page&lt;/strong&gt; &lt;a href="https://github.com/StingraySoftware/stingray/blob/9d7fa8a76d70df1eeb4501cb7ce701fb8e5bddf0/Benchmarks/Benchmark%20Analysis%20Report%202020%20-%20stingray.pdf"&gt;document&lt;/a&gt;, &lt;strong&gt;9 &lt;/strong&gt;new GitHub issues and &lt;strong&gt;3&lt;/strong&gt; new Pull Requests(for now, more to come soon).&lt;br&gt;
The functions causing the main slowdown i.e. &lt;em&gt;check_lightcurve, counts_err, cross_two_gtis, sort_counts, join, fourier_cross, rebin_data, rms_error, gti_border_bins, check_gtis, operation_with_other_lc and p_multitrial_from_single_trial &lt;/em&gt;were identified. These were further analyzed line-wise for deeper insights(also included in the document).&lt;/p&gt;
&lt;figure&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/1024/1*q3I5H5d6R8BEj73q7-YuAA.png"&gt;&lt;figcaption&gt;These look beautiful in the picture but analyzing 535 of these is super tedious!&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;airspeed velocity is a powerful tool that helps track the performance of a project over time, commit after commit. It is essentially a set of tests that can be run after every commit/change to check if the performance has been altered. It is used by numpy, scipy and astropy. The documentation is very well written(&lt;em&gt;sighs with relief&lt;/em&gt;). &lt;br&gt;
Thus, integrating airspeed velocity was &lt;em&gt;comparatively &lt;/em&gt;easier.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;A brief personal submission&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;
The thing I enjoy the most about GSoC is that just like most of you reading this article, I didn’t know, rather hadn’t even heard the names of all the tools I used and am probably adept at right now. &lt;br&gt;
I start working every day not knowing how to solve the task(often daunting) in front of me or what the day holds. But at the end of the day, I’m confident that I’ve learnt something new. &lt;br&gt;
This excites me and I look forward to every new day working on my GSoC project&lt;/p&gt;
&lt;p&gt;You can check out my repository for airspeed velocity below. There is a link on the right side that leads to a webpage which looks relatively empty at the moment, someday hopefully, it will look like &lt;a href="https://pv.github.io/numpy-bench/"&gt;numpy’s asv&lt;/a&gt; page.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/theand9/stingray-benchmarks"&gt;theand9/stingray-benchmarks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;You can also check the benchmarks I have performed below.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/StingraySoftware/stingray/pull/477"&gt;Benchmarking Stingray -&amp;gt; GSoC 2020 by theand9 · Pull Request #477 · StingraySoftware/stingray&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Thank you soo much for giving it a read. Please comment and leave a clap if you liked the article. Feel free to reach out to me on &lt;a href="https://www.linkedin.com/in/theand9/"&gt;Linkedin&lt;/a&gt;.&lt;br&gt;
Have an amazing day!! &lt;strong&gt;You are awesome!!!&lt;/strong&gt;&lt;/p&gt;
&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=d4a51e01685d" width="1" height="1"&gt;&lt;/div&gt;</description><category>stingray</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200729_1643_theand9/</guid><pubDate>Wed, 29 Jul 2020 15:43:01 GMT</pubDate></item><item><title>Week 7 &amp; 8: The end of second month!</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200729_1113_siddharthlal25/</link><dc:creator>siddharthlal25</dc:creator><description>&lt;div&gt;&lt;h3 id="hey-sid-how-was-the-second-month"&gt;&lt;em&gt;Hey Sid, how was the second month?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;Awesome, lot’s of new learning experiences!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;h3 id="so-tell-us-about-your-progress-in-the-last-two-weeks"&gt;&lt;em&gt;So, tell us about your progress in the last two weeks?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;These two weeks went on designing the new data structure &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt; for storing &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;, this was primarily done to make accessing data and header files easier, and secondly, to tackle the file closing issue that was encountered. Let me explain the file issue in brief:&lt;/p&gt;

&lt;p&gt;Suppose a user uses &lt;code class="language-plaintext highlighter-rouge"&gt;fitscollection&lt;/code&gt; at a location and gets a list of all &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; files, now by using the generator methods one can collect all &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt; listed in the data frame obtained from &lt;code class="language-plaintext highlighter-rouge"&gt;fitscollection&lt;/code&gt;, but once the generator is executed and used for collecting the &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;s, the generator closes the open file handles from which &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;s were accessed, this subsequently leads to error while accessing the collected &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt;s since its source &lt;code class="language-plaintext highlighter-rouge"&gt;FITS&lt;/code&gt; file were closed after the execution of generator. So, to tackle this we introduced &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt; which couples the data and header together in memory and can be accessed even if the filehandles get closed.&lt;/p&gt;

&lt;p&gt;The &lt;code class="language-plaintext highlighter-rouge"&gt;CCDData&lt;/code&gt; is based on &lt;code class="language-plaintext highlighter-rouge"&gt;AbstractArray&lt;/code&gt; interface which leads to a lot of code being reused with a bit of modification in the function signature.&lt;/p&gt;

&lt;h3 id="hmmm-so-what-next"&gt;&lt;em&gt;Hmmm, so what next?&lt;/em&gt;&lt;/h3&gt;

&lt;p&gt;I will be copying the saving versions of &lt;code class="language-plaintext highlighter-rouge"&gt;images&lt;/code&gt;, &lt;code class="language-plaintext highlighter-rouge"&gt;arrays&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;filenames&lt;/code&gt; from the previously closed PR, which would probably take a day or two. With some minor modifications, it would be good to go to the main code. After this, one can easily see the code in action! Next, I will also be implementing some macros for getting values from header of &lt;code class="language-plaintext highlighter-rouge"&gt;ImageHDU&lt;/code&gt; using keys directly in a method. After all this, we can bump up the version!&lt;/p&gt;

&lt;p&gt;Stay tuned to know more!&lt;/p&gt;

&lt;p&gt;-sl&lt;/p&gt;&lt;/div&gt;</description><category>JuliaAstro</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200729_1113_siddharthlal25/</guid><pubDate>Wed, 29 Jul 2020 10:13:56 GMT</pubDate></item><item><title>Chapter 3 : The Search Events Object</title><link>http://openastronomy.org/Universe_OA/posts/2020/07/20200728_1932_raahul-singh/</link><dc:creator>Raahul Singh</dc:creator><description>&lt;div&gt;&lt;h4&gt;Chapter 3 : The Search Events Object&lt;/h4&gt;&lt;img src="https://medium.com/_/stat?event=post.clientViewed&amp;amp;referrerSource=full_rss&amp;amp;postId=ec306bbf6e51" width="1" height="1"&gt;
&lt;!-- TEASER_END --&gt;&lt;/div&gt;</description><category>SunPy</category><guid>http://openastronomy.org/Universe_OA/posts/2020/07/20200728_1932_raahul-singh/</guid><pubDate>Tue, 28 Jul 2020 18:32:44 GMT</pubDate></item></channel></rss>