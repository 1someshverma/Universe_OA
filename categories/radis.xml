<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Universe OpenAstronomy (Posts about radis)</title><link>http://openastronomy.org/Universe_OA/</link><description></description><atom:link href="http://openastronomy.org/Universe_OA/categories/radis.xml" rel="self" type="application/rss+xml"></atom:link><language>en</language><lastBuildDate>Thu, 16 Jul 2020 01:39:30 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Google Summer of Code - Blog #2!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hello! This blog marks the end of the first phase of Google Summer of Code. The journey so far has been challenging but also extremely rewarding. The knowledge gained as a by-product of the work I’ve been doing on my project so far is unbelievable, but more importantly has been a better, more pleasant experience compared to the traditional system of gaining knowledge by reading books and tutorials. In this blog, I will be summarising the work that I’ve been doing for the past 2 weeks, update the readers on my current position and give an idea of what lies ahead.&lt;/p&gt;

&lt;p&gt;As I discussed in my previous blog, the work for the first two weeks mostly involved using Cython to translate the host code into something which could be compiled to provide better performance. More importantly, apart from the Cython part, I had to also start working on porting the kernels from their pure CUDA C form into something which Python/Cython could also understand. While the actual work to do so did not take long or came across as very challenging, the most difficult part in the whole process, undeniably, was to get the two, Cython and CuPy to talk to one another.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;When I finished writing the previous blog, I was still left with quite a large volume of host code which was waiting to be converted to the Cython equivalent. Going through the previous blog, I’d like to make one correction in the part where I said I found Cython quite confusing. Infact, calling it a correction would not be correct. Instead, I should say that Cython isn’t actually all that difficult as I might have made it look like in the last blog. After a fair amount of reading and writing code in Cython, I think the developers of Cython have actually done an excellent job. After the initial barrier is crossed (and it happens fairly naturally), writing Cython code feels just as normal and second nature as pure Python code. Infact, I’d go so far as to claim that Cython feels more natural to me now than Python itself because of my previous experience in C++. This newly found familiarity allowed me to proceed quite quickly with this part of the project. The only problems that I encountered were: (1) the inter-conversion between arrays/vectors and pointers that we are used to in C++ is not possible in case of Cython, and this resulted in me being forced to make some slight changes in the host code, and (2) using structs in Cython isn’t as direct and straighforward as in C/C++. The reason behind this is the fact that Cython tries to estabilish relationships between C-type data structures and Python objects. While this is quite trivial for objects of types int, float, char, and even arrays to some extent, in case of structs this is nowhere near as easy. While I am sure there must have been some hacky way around this problem too, me and my mentors decided it is not something worth wasting time on, and thus we decided to bypass all structs and directly used each of their attributes as variables with the struct name attached as prefix, so &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h.shared_size&lt;/code&gt; became &lt;code class="language-plaintext highlighter-rouge"&gt;host_params_h_shared_size&lt;/code&gt;. While not the exact same thing, it allowed us to achieve the same objective without a lot of modifications to the code, either in terms of declaration or syntax. The only downside to this whole approach was that it made the code quite verbose, as instead of passing a single struct with 10 fields inside it, we were forced to pass 10 variables for each struct. This unique problem was further aggravated as we were using global variables instead of passing them around as arguments, and as every Python user would know, this meant adding the line &lt;code class="language-plaintext highlighter-rouge"&gt;global &amp;lt;varname&amp;gt;&lt;/code&gt; before every function body, which when done for every method and every variable, meant a lot of lines which could have been avoided. Apart from these two major issues and couple of minor problems here and there, the whole process was fairly straight forward. At the end of this step, I was left with a Cython file which compiled just fine, but didn’t really accomplish much. The key ingredient that was missing, was the very the heart of the project: the kernels.&lt;/p&gt;

&lt;p&gt;Kernel is actually nothing but a fancy word for the part of the code which actually executes on the GPU. Given the project title, it’d be fairly obvious that in our project, the kernels are actually where the magic happens. While this is not meant to discount the importance of the host (or the CPU code), the kernels are ulimately the part of the program which are responsible for the performance boosts that we observe. Kernels, atleast those which are meant to be executed on Nvidia’s GPUs, are usually written in a language known as CUDA C. This is a special language that is written on top of the original C language, but with extra set of features, classes and methods which provide us an abstracted interface to control various aspects of the program and the way it is implemented on the GPU, more so than a conventional serial algorithm meant to be implemented on the GPU. While using CUDA C is quite straightforward, especially with the large community support and well-written documentation, we unfortunately could not make use of that as we wanted something that was written and compatible with Python and things written on top of Python. Thus, after a lot of deliberation and discussion, my mentors and I agreed to use something known as CuPy to handle the CUDA C part of our code.  CuPy is an incredibly well-written module with neat documentation and decent community support, which made things a lot simple for us. However, more than anything, the biggest advantage of using CuPy was its RawModule method. The idea behind RawModule was to allow users who already have a CUDA C file written to do some specific task (us!) could simply re-use their code and get away with the whole problem of running kernels in Python very, very easily. Let me demonstrate it using an example and that would perhaps make things even more clear:&lt;/p&gt;

&lt;div class="language-python highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;
&lt;span class="n"&gt;loaded_from_source&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;r'''
extern "C"{
...
__global__ void test_sum(const float* x1, const float* x2, float* y, \
unsigned int N)
{
unsigned int tid = blockDim.x * blockIdx.x + threadIdx.x;
if (tid &amp;lt; N)
{
y[tid] = x1[tid] + x2[tid];
}
}
}'''&lt;/span&gt;

&lt;span class="n"&gt;module&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;RawModule&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;loaded_from_source&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;module&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;'test_sum'&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;N&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;10&lt;/span&gt;
&lt;span class="n"&gt;x1&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;arange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="n"&gt;reshape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;x2&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ones&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;y&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zeros&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;dtype&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;cp&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="n"&gt;float32&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;ker_sum&lt;/span&gt;&lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="p"&gt;,),&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;x1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;x2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;y&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;N&lt;/span&gt;&lt;span class="o"&gt;**&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;   &lt;span class="c1"&gt;# y = x1 + x2
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While the code looks fairly self-explanatory, I’ll give a quick runthrough anyway. The idea behind CuPy’s RawModule method, true to it’s name, is to allow the raw CUDA source to work with Python, which in our case is the string named &lt;code class="language-plaintext highlighter-rouge"&gt;loaded_from_source&lt;/code&gt;. Using RawModule, we process the string as a CUDA C source file, extract the relevant kernels from the file, &lt;code class="language-plaintext highlighter-rouge"&gt;test_sum&lt;/code&gt; in our case, and we’re done! The function is stored as &lt;code class="language-plaintext highlighter-rouge"&gt;ker_sum&lt;/code&gt; in Python, and is ready for use just like any other Python method. In order to keep the look and feel of the module as close to the original CUDA C source codes, even the way kernels are called is quite similar to how they’re called in C. The first two parameters, are the grid and block dimensions, and finally we follow through with the actual parameters to the kernel. Clearly, this allowed us to fast-track a lot of the kernel porting work, and quickly develop a Python version of our original proof-of-concept code.
However, like everything else, even this wasn’t going to work as easily as we’d initially expected. Instead, I faced a new challenge, which was the use of a struct written in the CUDA library, used for fast fourier trasforms, known as &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt;. Like I explained in the previous paragraph, this problem was quite similar in nature to the whole Python object to C object transformation and vice versa. If anything, this probably felt more explicit in nature since we could clearly see the actual C code written (as the RawModule’s string). The problem was that the structs are very specific to their definition, and it is simply not possible to pass anything to the RawModule and expect it to process it as a struct. Even though a numpy array of datatype complex64 might be storing the exact same data as an array of &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt;, the two cannnot be interconverted like vectors of integers and other primitive types can be. This again posed a challenge as it would mean a deviation from the original code. Finally, after reading a lot of stackoverflow and still not being satisfied with any of the answers, I let my mentors help me out with the code. The final solution that came out did a couple of things: first we got rid of the &lt;code class="language-plaintext highlighter-rouge"&gt;cufftComplex&lt;/code&gt; and &lt;code class="language-plaintext highlighter-rouge"&gt;cufftReal&lt;/code&gt; structs, and instead introduced the other, C datatype, serving the same purpose, a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt;. This amazing datatype did the exact same thing, except we could pass a numpy (or cupy) array of type complex64 and it would automatically read it as a &lt;code class="language-plaintext highlighter-rouge"&gt;complex&amp;lt;float&amp;gt;&lt;/code&gt; array! It quite literally solved the whole problem in an instant, and the only modifications we had to make were change how the real and imaginary parts of the complex numbers were being handled. While the struct definition required us to handle both separately, the new format made things even simpler by letting us perform calculations on both the real and imaginary parts simultaneously (basically how you’d expect to work with a complex number anyway!). With this, and again a few minor changes here and there to ensure the data transfer between Cython and CuPy wasn’t throwing errors, I was done! However, by now I had a Cython file with 1300+ lines with a &lt;em&gt;lot&lt;/em&gt; of room for bugs and unexpected errors and behavior.&lt;/p&gt;

&lt;p&gt;This brings us to the current time. The current objective for me is to get the file to work properly and produce the right about, so basically debugging. However, unlike smaller programs and files which are debugged with usually a single method in focus, I have to constantly let the whole chain of methods to execute even if I know that the bug is in some specific method, simply because its impossible to recreate the testing environment otherwise. For instance, I have been debugging the code since yesterday, and except one time where I got a segmentation fault, every time the program crashes, I am being forced to restart my computer just to start the debugging process again. Reason you ask? The program is working on a small subset of an already trimmed dataset, occupying around 3 GB of space. However, whenever I execute the program and try to run it, it is loading all that data first in the RAM (which slows the computer to a crawl almost instantly due to the limited 8GB RAM), and subsequently to the GPU (where it takes up 3/4 GB VRAM present). On force closing the program, while the RAM does free up after some time to a state where I can start using the computer again, the GPU does not!! I am yet to read into the nitty-gritty of this, but from what I understood, we need to explicitly clear the VRAM occupied by CuPy using methods given in the documentation. However, when the program does not work as expected (which is currently 100 percent of the times I have run it), the program simply crashes before executing the lines which free up the memory. The result? A GPU which is loaded up and unable to free its VRAM. Resetting seems to not work for some reason, and the only option I have found so far (admittedly I havent researched well enough but its only been 24 hours since I reached this stage) which does work is restarting my computer. This, as I am sure you can already feel, is a very frustrating way to debug things, but I am happy to say that I am still making progress, albeit a little slowly than I would have liked to.&lt;/p&gt;

&lt;p&gt;That pretty much sums up everything that I have been upto for the past 2 weeks. The progress is a little on the slower side, as I expected to have the demo working &lt;em&gt;and&lt;/em&gt; producing the correct output by now, but unfortunately the code still needs debugging. Hopefully this should be over soon, and we can then move to integrating it with RADIS and making changes that should allow the user to make use of our program. After that, we would be focussing on implementing other methods of calculating spectra, and possibly also methods which support non-equilibria conditions. Hopefully I should have a lot more to tell you guys 2 weeks from now! Till then, adios! And thanks for making it this far (if you actually did so :P) Cheers.&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200629_2135_pkj-m/</guid><pubDate>Mon, 29 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #1!</title><link>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_2135_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey there, welcome to the second blog of the series, and the first one to document the coding period. The Community bonding period which I described in my previous blog ended on 31st May and paved the way for the official coding period of the Google Summer of Code. These past two weeks were my first where I spent most of my time working on the actual code that will be a part of my project. My primary objective over these two weeks was to study the proof of work code that implements the spectral matrix algorithm to compute the spectra and execute it on a GPU. This was followed by a period of studying the different mechanisms with which RADIS calculates the spectras, and to understand the differences between each of them. This was important as implementing GPU compatible methods for all these distinct pipelines is my final objective and it is essential for me to understand the differences between these methods at the very onset of my project. Finally, the remaining time was spent on back and forth discussions with my mentors on various languages and libraries that could have been possible choices for undertaking this project. Once we had made our decision, I spent the time going through the library’s documentation, source code and tutorials to familiarize myself with these tools.&lt;/p&gt;

&lt;p&gt;The first major objective for these two weeks focussed on studying and executing the proof of work code. This was a single CUDA C file which demonstrated the idea of using a spectral matrix to compute a spectra while making use of a GPU could offer performance boosts of multiple orders over the naive methods. I initially planned on executing the code and running it on my personal computer, but the idea was quickly dismissed because of reasons I already discussed in my previous blog. As a result, I ended up using Google Colab for this experimentation which came with its own fair share of discomforts. The first, and most significant of which, was the lack of persistent storage on Colab and thus being forced to resort to Google Drive for saving our database instead. This was costly in terms of both, the time it took to store the data on the cloud and also on the overall performance of the code as the time taken to load the data to memory increased significantly compared to a single CPU-GPU system like my personal laptop. This however, was not detrimental to the fundamental objective as the benchmarking could be done for each part of the code separately, and thus it did not influence or affect the execution of the device code or its perfomance in any way. Another task which popped up when using Colab to run CUDA was to setup the system so it could run native CUDA C files along with the Python code as well. This fortunately was not very difficult to solve and a couple of google searches gave us the list of all the necessary packages we needed to compile and execute C files on Colab. Once that was set up, the only thing that was left for me to do was transfer the data from my laptop to Google Drive. This once again posed a problem that I had not anticipated. Uploading 8GB of data takes &lt;em&gt;much&lt;/em&gt; longer than downloading the same amount of data! As soon as that realization hit me, I decided to adopt another approach. I copied the code that I used to download the data from the FTP server to my local storage and ran it on Google Colab! This allowed me to once again redownload the entire data (which in the raw format was ~ 30GB) directly on my Drive instead. The process was much faster than I had anticipated and I soon had the raw data on my Drive. After running another couple of scripts to format and repartition the data into separate numpy arrays, I was ready to go. Execution of the code went smoothly except for a few hiccups surrounding the matplotlibcpp library that was being used to plot the output spectra. I wasn’t able to solve this problem immediately like the others and talked to my mentors about it. They advised me to not worry too much about it right now as it really wasn’t the critical part of the project. The major part, the kernel that was supposed to run on the GPU ran as expected and the results we obtained by timing the kernel performance were very positive! Now that I had successfully executed the code, what followed was a series of different runs of the same code, only this time with a different aim to test how far we could take this GPU compatible code. To give some numbers here, the original proof of work code that crunched the 8GB processed database computed a total of 240 million lines in less than a second! To be more specific, it took 120 ms on average to achieve that number. To put that into perspective, a naive implementation of the same code, that does not make use of the optimizations we did here, would take 10,000x longer to produce the same results! That in itself makes the naive approach an impractical solution to the problem. Compared to the current RADIS implementation, the performance gain was still significant with upto 50x gain in terms of time spent for computing the spectra. In order to see how far we could take this code, we also tried it with it a bunch of different ranges from the same dataset. While the original code was tested on a range that spanned from 1750 to 2400 cm-1 wavenumber, we took it as far as 1250-3050 cm-1. Surprisingly, the code scaled pretty well with the increase in the number of lines being computed, going from the original 120 ms taken to compute 240M lines to ~ 220 ms to compute 330M lines. Testing such a wide range and getting such positive results was sufficient proof for us to pack up the analysis part and move on to the actual implementation.&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;In order to integrate the GPU compatible spectral matrix method with the RADIS code base, the first thing that needed to be worked on was the language itself. The proof of work had been written completely in CUDA C, while RADIS is pure-Python. In order to bridge this gap, we had multiple options. The first and most obvious was to simply rewrite the entire code using Python with the help of some CUDA library. This, however, meant a lot of work in re-implementing the multiple methods, and more importantly, did not allow us to reuse the code that already existed. Therefore, in order to maximize our efficiency and also get the best performance possible, we decided to use a new language, or more specifically – a language extension for Python, known as Cython. The idea behind Cython is to use Python with a static compiler, which allowed Python programs to be precompiled into binaries, which could then be imported to other Python programs and achieve performance on par with native C code, because that is the intermediary code Cython converts the Python code into! Thus, by extension, any code that was already written in C was directly compatible with Cython. The main task now was to get the C code we had with us to talk to Cython with as few modifications as possible. This infact, is something that is still ongoing and would be finished as a part of my first evaluation. The last few days of this period have mostly been spent on learning Cython and its nuances. While the idea of Cython is to provide a smooth experience for Python users to gain C-level performance, ironically I had the opposite experience with it. I found Cython quite confusing at the beginning, and while most resources and tutorials focussed on making Python code achieve C-level performance, I was genuinely surprised by the lack of documentation/tutorials explaining how to export C code that already exists to Python. The few examples that were mentioned on the website were very generic and did not help much in terms of my requirements, where I needed to use things like references of vectors, etc. However, with more research and googling, I was able to find a compromise solution that worked well and thus allowed me to execute the method in Cython with minimal modifications to the original code.&lt;/p&gt;

&lt;p&gt;Overall, I think its been a good two weeks with a lot of progress made on the knowledge front. Apart from the objectives mentioned above, I also went through the draft of the paper my mentors have been working on which goes into the mathematics of the method and explains how it works. While I wasn’t able to comprehend everything properly, it did give me a good high-level idea of what exactly we’re trying to accomplish with our kernels. With this, I think I’d like to conclude this blog. Over the next two weeks, the end of which will also mark the completion of my first evaluation, I’ll continue to work on Cython-izing our host code, and start looking into CuPy as an alternative to CUDA C for our project! More about that in the next blog! Thanks!&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/06/20200613_2135_pkj-m/</guid><pubDate>Sat, 13 Jun 2020 20:35:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #0!</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey there. Welcome to the first of what is going to be a series of blog posts chronicling my journey as I participate in the Google Summer of Code this year with RADIS (registered as a sub-org under OpenAstronomy). This particular blog post, as the title suggests, is meant to give a quick introduction to GSoC as well as my organization and the project.&lt;/p&gt;

&lt;h4 id="what-is-google-summer-of-code"&gt;What is Google Summer of Code?&lt;/h4&gt;
&lt;!-- TEASER_END --&gt;
&lt;p&gt;Borrowing straight from it’s landing page, Google Summer of Code is a global program focused on bringing more student developers into open source software development. Students work with an open source organization on a 3 month programming project during their break from school.
In other words, GSoC (as it is more commonly referred to) is a program sponsored by Google which aims to connect university students around the world with open source organizations in order to promote the open-source culture. The students get an opportunity to peek into the world of open source development, learn new skills and also get compensated for the work, quite generously. In turn, the organizations benefit from a few extra pairs of helping hands, using them for a wide array of issues, from refactoring code, to fixing existing bugs, and ofcourse, to add new features to the existing code base. It’s a great program and any college student interested in software development should definitely check it out. The website contains a lot more information &lt;a href="https://summerofcode.withgoogle.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now that’s clear, let me talk a little about the specific organization that I will be working with.&lt;/p&gt;

&lt;h4 id="radis--openastronomy"&gt;RADIS ∈ OpenAstronomy&lt;/h4&gt;

&lt;p&gt;While the most commmon way for organizations to participate in the program and request slots for GSoC is to register directly, many organizations, for various reasons, often come together under an umbrella organization and register for GSoC as one single unit. This bundling of organizations can happen on various basis, but the most common reason is that these organizations often work towards the same goal, or operate in the same domain. In my case, this is true as well. I applied for and got selected for GSoC with the OpenAstronomy organization, which as the name suggests is an umbrella organization meant to act as a central hub for all the great number of ‘sub-organizations’ that operate within it. You can read more about OpenAstronomy and what it does &lt;a href="https://openastronomy.org/"&gt;here&lt;/a&gt;. One such sub-organization, with which I shall be working, happens to be RADIS.&lt;/p&gt;

&lt;p&gt;RADIS is a radiation software, a fast line-by-line code for synthesizing and fitting infrared absorption and emission spectra such as encountered in laboratory plasmas or exoplanet atmospheres.&lt;/p&gt;

&lt;p&gt;While RADIS was written with performance in mind, and performance it delivers, it is still limited by factors such as the speed offered by Python, and using a single CPU to carry out all its calculations. While the problem with a programming language can be solved (not so) easily by switching to other languages, such as C++, we’re still limited to using a single processing unit to carry out all the computations. This is the exact problem that my project tries to solve. The title of my project, “Accelerate Synthetic Spectra Calculations using CUDA”, is all about removing the restriction of a single CPU and instead allow RADIS to perform much faster by utilising the power of a GPU instead. I will not be going into the detail of the project here/yet, but the general idea is to switch certain parts of the pipeline in RADIS’ execution which slow it down to the GPU, which as people familiar with GPUs would know, is adept at executing a large volume of simple tasks.&lt;/p&gt;

&lt;p&gt;The technicalities of the project, including how exactly the problem can be shifted to the GPU, how its being implemented on the GPU, or its integration with the RADIS will be discussed in the future blog posts. For now, I will like to keep this blog limited to the things that have already occured, as a part of the ‘Community Bonding Period’:&lt;/p&gt;

&lt;h4 id="the-community-bonding-period"&gt;The Community Bonding Period&lt;/h4&gt;

&lt;p&gt;The Community Bonding Period is an almost 30-days long period meant to serve as a warm-up or a buffer before the actual coding period begins. It can be used for a wide variety of purposes, such as getting a better understanding of the codebase, figuring out the intricacies of your project et al. As such, the greater part of my community bonding period went into understanding the exact details of what I will be doing over the coming months and how I will be doing it. While the pre-selection period did include a fair amount of contributions being made by me towards the organization, it was mainly an attempt to understand the general architecture and codebase of RADIS more thoroughly, and did not involve anything specific to the project I had applied for. Once the selected projects were made public on 4th May 2020, that is when the community bonding period officially started and I started to focus exclusively on my project as well. The seed idea that eventually led to my project started when my mentors decided to play around with the code, and instead of using pure Python for the processing, decided to precompile some of the slower parts of the code into a DLL and imported it to Python instead. The results of this experiment were incredible, and paved the way for my mentor, Dirk van den Bekerom to write the first proof-of-work code demonstrating the use of GPUs to calculate the spectras that were previously being done entirely on the CPU. Benchmarking showed performance boosts of upto 10,000x compared to the naive implementation of spectra calculations on Python and upto 50x from the current implementation of RADIS.&lt;/p&gt;

&lt;p&gt;After discussing with my mentors, the project timeline was decided and the work was done accordingly. Keeping in mind my objectives for the coming month, as a part of the first evaluation, I decided to spend a lot of time on understanding the existing code base of RADIS &lt;em&gt;which focuses on the spectra calculations&lt;/em&gt;. Note that this is completely different from the code that I worked on earlier, which focussed on issues completely different from this, and mostly revolved around the post-processing of spectra instead of calculating it. This included a light reading of the original RADIS paper which talked about the general idea and logic behind RADIS. In addition to that, I also spent time on setting up the right environment for the development work that was to come.
Since the project is about GPUs and CUDA, I had to ensure that CUDA was properly installed and running on my system. While this might seem like a trivial task, it can easily get very messy when working on a linux distribution. Fortunately, I already had a working installation of CUDA on my system so I didn’t have to spend much time on it except for testing and tuning it. Another major issue that this project entailed was the handling of vast amounts of data.&lt;/p&gt;

&lt;p&gt;To keep it simple, in order to calculate the spectra, RADIS requires some data. This data includes information on various parameters such as positions, intensities, air- and self-broadened half-widths, et cetera for different molecules. For my project, for the time being, I was using the CDSD-4000 database, which is a high-temperature databank for CO2 molecule. The major issue this databank presented was the vast size of it. While the complete databank would have been incredibly huge (but fortunately not needed) the portion of the databank that we did focus on was not a small package either, occupying 30GB space unprocessed. Further processing of this data reduced it down to 8GB. While that might seem like a manageable size, the issue was that in order to compute the spectra efficiently and reduce the latency in loading the data, all of it had to be stored on the device RAM. This requirement was simply not possible for me to satisfy with just my personal computer which has a NVidia GTX 1650 with only 4GB of VRAM. Thus, I was left with two options. To either trim the database further and then work on it, or find another machine with specifications high enough to crunch the numbers without trimming it down. After discussing with my mentors and weighing the pros and cons, I decided to try out both.
We used Google Colab with its free GPU access to process the entire 8GB data in one go. The major problem we faced with this method was loading the data onto the colab server. Since even the processed files were 8GB, and Colab did not offer persistent storage, we would have to upload 8GB of data every time we wanted to test the code out, which ofcourse would not have been practical. This was solved by using Google Drive, which can be mounted in colab and work as a persistent storage setup. So far, I have thoroughly enjoyed the convenience and power offered by Colab, and that too for no charge, and hope it continues to perform so wonderfully. In addition, I also trimmed the original database down to smaller sizes and tried to process them on my personal machine, which it did without any hassles.&lt;/p&gt;

&lt;p&gt;Another interesting question that we faced was the tools to use. While it might seem like a no-brainer to use C with CUDA, it unfortunately was not an option as RADIS was written in Python. Therefore, we had to spend a fair amount of time trying to figure out additions to Python in the form of libraries which allow CUDA access. A few of the many different options that are available for such purposes include using Cython, PyCUDA, Cupy, Numba, PyOpenCL and many more. The decision to pick one over the other is a very subjective one, and the answer mostly depends on the kind of application you’re trying to produce. For our particular project, the only requirement was to have access to constant memory on the device which can be achieved using Cython or PyCUDA. While I personally enjoyed PyCUDA due to its extensive documentation and support from NVidia, my mentor seems to prefer Cython so the final decision is still not here!&lt;/p&gt;

&lt;p&gt;Apart from all this, I also spent a good amount of time studying the proof-of-work code that already exists. That included the differences from pure CPU code, the division of work between host and the device, and way the the actual calculations are being done in order to compute the spectra. Finally, I also spent a fair amount of time on revising my CUDA concepts in order to ensure there were no knowledge gaps.&lt;/p&gt;

&lt;p&gt;That pretty much sums up my community bonding period! Over the coming 4 weeks, my objectives include reproducing the proof of work, and figure out the implementation details with my mentors. That will be followed by implementing one of the broadening steps in Python and integrating it with the RADIS.&lt;/p&gt;

&lt;p&gt;I am quite excited about the upcoming months and my journey with RADIS. I believe it will be a great learning experience and I would like to thank Google, OpenAstronomy, RADIS, but most importantly, my incredibly helpful and fun mentors Erwan Pannier, Dirk van den Bekerom and Minesi N for giving me this wonderful opportunity!&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200530_1804_pkj-m/</guid><pubDate>Sat, 30 May 2020 17:04:56 GMT</pubDate></item><item><title>Google Summer of Code - Blog #0!</title><link>http://openastronomy.org/Universe_OA/posts/2020/05/20200514_1804_pkj-m/</link><dc:creator>pkj-m</dc:creator><description>&lt;div&gt;&lt;p&gt;Hey there. Welcome to my first blog of an upcoming series of blogs where I will be trying to chronicle my journey this year as an open source contributor to RADIS under the Google Summer of Code program!&lt;/p&gt;

&lt;p&gt;Stay tuned!&lt;/p&gt;
&lt;!-- TEASER_END --&gt;

&lt;p&gt;-p&lt;/p&gt;&lt;/div&gt;</description><category>radis</category><guid>http://openastronomy.org/Universe_OA/posts/2020/05/20200514_1804_pkj-m/</guid><pubDate>Thu, 14 May 2020 17:04:56 GMT</pubDate></item></channel></rss>